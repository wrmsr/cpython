diff --git a/Include/abstract.h b/Include/abstract.h
index 4ff79f2928..a9ffb369cd 100644
--- a/Include/abstract.h
+++ b/Include/abstract.h
@@ -503,15 +503,17 @@ xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx*/
                                             void **buffer,
                                             Py_ssize_t *buffer_len);
 
-       /*
-      Takes an arbitrary object which must support the (writable,
-      single segment) buffer interface and returns a pointer to a
-      writable memory location in buffer of size buffer_len.
+     /*
+     Lock or unlock an object.  Locking and unlocking always succeeds.
 
-      0 is returned on success.  buffer and buffer_len are only
-      set in case no error occurs. Otherwise, -1 is returned and
-      an exception set.
-       */
+     If the object does not support locking no exception is set.
+     */
+
+     PyAPI_FUNC(void) PyObject_Lock(PyObject *obj);
+     PyAPI_FUNC(void) PyObject_Unlock(PyObject *obj);
+     /* Locks two objects, using a predictable ordering to avoid deadlocks. */
+     PyAPI_FUNC(void) PyObject_Lock2(PyObject *o1, PyObject *o2);
+     PyAPI_FUNC(void) PyObject_Unlock2(PyObject *o1, PyObject *o2);
 
     /* new buffer API */
 
diff --git a/Include/dictobject.h b/Include/dictobject.h
index ba90aaf676..4018901e0b 100644
--- a/Include/dictobject.h
+++ b/Include/dictobject.h
@@ -23,6 +23,7 @@ typedef struct _dictkeysobject PyDictKeysObject;
 typedef struct {
     PyObject_HEAD
     Py_ssize_t ma_used;
+    py_recursivelock_t ma_lock;
     PyDictKeysObject *ma_keys;
     PyObject **ma_values;
 } PyDictObject;
diff --git a/Include/frameobject.h b/Include/frameobject.h
index 966ff1f6e6..4e8b797a95 100644
--- a/Include/frameobject.h
+++ b/Include/frameobject.h
@@ -39,6 +39,8 @@ typedef struct _frame {
     /* Borrowed reference to a generator, or NULL */
     PyObject *f_gen;
 
+    PyThreadState *f_tstate;
+
     int f_lasti;                /* Last instruction if called */
     /* Call PyFrame_GetLineNumber() instead of reading this field
        directly.  As of 2.3 f_lineno is only valid when tracing is
diff --git a/Include/listobject.h b/Include/listobject.h
index daa513f151..9e3cbd6601 100644
--- a/Include/listobject.h
+++ b/Include/listobject.h
@@ -37,6 +37,7 @@ typedef struct {
      * the list is not yet visible outside the function that builds it.
      */
     Py_ssize_t allocated;
+    py_recursivelock_t lock;
 } PyListObject;
 #endif
 
diff --git a/Include/lock.h b/Include/lock.h
new file mode 100644
index 0000000000..12e609e480
--- /dev/null
+++ b/Include/lock.h
@@ -0,0 +1,261 @@
+#ifndef __PY_LOCK_H
+#define __PY_LOCK_H
+
+// First, bring in platform specific locking support.  Platforms need to define the following:
+//
+//  ATOMIC_PRE_ADD_SSIZE_T(x) - atomically increments an ssize_t value and returns the new value
+//  ATOMIC_PRE_SUB_SSIZE_T(x) - atomically decrements an ssize_t value and returns the new value
+//
+//  cycle_count_get() - return some cheap high-precision clock (e.g. RDTSCP)
+//  cycle_count_to_seconds() - convert cycle count to floating-point seconds
+//  cycle counts should always be type uint64_t.
+//
+//	threadid_t - the handle type for unique thread identifiers
+//  CURRENT_THREAD_ID - a macro used for getting the current thread ID
+//  ARE_THREADS_EQUAL - a macro used for comparing two thread IDs
+//
+//  PY_NATIVELOCK_T - the cheapest native lock available
+//             doesn't have to be recursive
+//             doesn't need to support multiple readers
+//             this should be a #define
+//  PY_NATIVELOCK_STATIC_INIT() - statically initalizes a PY_NATIVELOCK_T
+//  void py_nativelock_init(PY_NATIVELOCK_T *) - dynamically initializes a native lock
+//  void py_nativelock_lock(PY_NATIVELOCK_T *) - locks a native lock
+//  void py_nativelock_unlock(PY_NATIVELOCK_T *) - unlocks a native lock
+//  (we always allocate the nativelock, we always pass a pointer to the nativelock to you)
+//
+// We then define for you:
+//
+//	py_lock_t	 - the actual basic lock we use
+//             built on top of py_nativelock_t
+//             adds statistics
+//  PY_LOCK_STATIC_INIT(description) - statically initalizes a py_lock with a description
+//
+//
+//  py_recursive_lock_t - a recursive lock probably built on top of py_lock_t
+
+#if 0 /* ACTIVATE STATS */
+	/* Turn on statistics tracking for locks. Expensive and slow! */
+    #define PY_TIME_REFCOUNTS
+    #define PY_LOCK_WANT_STATS
+    #define PY_RECURSIVE_LOCK_WANT_STATS
+    #define GC_TRACK_STATS
+#endif /* ACTIVATE STATS */
+
+
+Py_LOCAL_INLINE(uint64_t) cycle_count_get(void);
+Py_LOCAL_INLINE(double)   cycle_count_to_seconds(uint64_t cycles);
+
+#define ATOMIC_INC(refcnt) ATOMIC_PRE_ADD_SSIZE_T((refcnt), 1)
+#define ATOMIC_DEC(refcnt) ATOMIC_PRE_SUB_SSIZE_T((refcnt), 1)
+
+#if defined(PY_LOCK_WANT_STATS) || defined(PY_RECURSIVE_LOCK_WANT_STATS)
+#define PyMAX(a, b) ((a)>(b)?(a):(b))
+#define PyMIN(a, b) ((a)<(b)?(a):(b))
+#endif /* PY_LOCK_WANT_STATS || PY_RECURSIVE_LOCK_WANT_STATS */
+
+#ifdef PY_LOCK_WANT_STATS
+#define PY_LOCK_STATS_STATIC_INIT , 0, 0, 0, 0
+#else
+#define PY_LOCK_STATS_STATIC_INIT
+#endif
+
+#if defined(WIN32) || defined(WIN64)
+#include "lock_win.h"
+#elif defined(__APPLE__)
+#include "lock_pthreads.h"
+#else
+#include "lock_linux.h"
+#endif
+
+Py_LOCAL_INLINE(void) py_nativelock_init  (PY_NATIVELOCK_T *nativelock);
+Py_LOCAL_INLINE(void) py_nativelock_lock  (PY_NATIVELOCK_T *nativelock);
+Py_LOCAL_INLINE(void) py_nativelock_unlock(PY_NATIVELOCK_T *nativelock);
+
+
+typedef struct {
+	Py_ssize_t total_refcount_time;
+	Py_ssize_t total_refcounts;
+} py_time_refcounts_t;
+
+extern py_time_refcounts_t py_time_refcounts;
+
+void py_time_refcounts_setzero(py_time_refcounts_t *t);
+void py_time_refcounts_persist(py_time_refcounts_t *t);
+
+#ifndef PY_TIME_FETCH_AND_ADD
+#define PY_TIME_FETCH_AND_ADD(t, fieldname, delta) \
+	do { \
+	    if (t) \
+	    	t->fieldname += delta; \
+	    else { \
+	    	ATOMIC_PRE_ADD_SSIZE_T(&(py_time_refcounts.fieldname), delta); \
+	    } \
+    } while (0) \
+
+#endif
+
+
+
+typedef struct {
+	PY_NATIVELOCK_T nativelock;
+	const char *description;
+	const char *file;
+	int line;
+#ifdef PY_LOCK_WANT_STATS
+	uint64_t no_contention_count;
+	uint64_t contention_count;
+	uint64_t contention_total_delay;
+	uint64_t contention_max_delta;
+#endif
+} py_lock_t;
+
+Py_LOCAL_INLINE(void) py_lock_init(py_lock_t *lock, const char *description) {
+	memset(lock, 0, sizeof(*lock));
+	py_nativelock_init(&(lock->nativelock));
+	lock->description = description;
+}
+
+#define PY_LOCK_STATIC_INIT(description) \
+	{ PY_NATIVELOCK_STATIC_INIT(), description, NULL, 0 PY_LOCK_STATS_STATIC_INIT }
+
+
+#define py_lock_lock(lock) (_py_lock_lock((lock), __FILE__, __LINE__))
+
+Py_LOCAL_INLINE(void) _py_lock_lock(py_lock_t *lock, const char *file, int line) {
+
+#ifdef PY_LOCK_WANT_STATS
+	uint64_t start = cycle_count_get();
+	uint64_t delta;
+#endif /* PY_LOCK_WANT_STATS */
+
+	py_nativelock_lock(&(lock->nativelock));
+	lock->file = file;
+	lock->line = line;
+
+#ifdef PY_LOCK_WANT_STATS
+	delta = cycle_count_get() - start;
+	if (delta <= 250)
+		lock->no_contention_count++;
+	else {
+		lock->contention_count++;
+		lock->contention_total_delay += delta;
+		lock->contention_max_delta = PyMAX(lock->contention_max_delta, delta);
+	}
+#endif /* PY_LOCK_WANT_STATS */
+}
+
+Py_LOCAL_INLINE(void) py_lock_unlock(py_lock_t *lock) {
+	/* negative number means unlocked! */
+	lock->line = -lock->line;
+	py_nativelock_unlock(&(lock->nativelock));
+}
+
+Py_LOCAL_INLINE(void) py_lock_reset_stats(py_lock_t *lock) {
+#ifdef PY_LOCK_WANT_STATS
+	lock->no_contention_count =
+		lock->contention_total_delay =
+		lock->contention_max_delta =
+		lock->contention_count = 0;
+#else
+	(void)lock;
+#endif /* PY_LOCK_WANT_STATS */
+}
+
+
+/*
+** py_recursive_lock_t
+**
+** recursive lock
+**
+*/
+typedef struct {
+	py_lock_t lock;
+	int count;
+	threadid_t tid;
+	const char *description;
+	const char *file;
+	int line;
+#ifdef FURTEX_WANT_STATS
+	uint64_t no_contention_count;
+	uint64_t contention_count;
+	uint64_t contention_total_delay;
+	uint64_t contention_max_delta;
+#define PY_RECURSIVELOCK_STATS_STATIC_INIT , 0, 0, 0, 0
+#else
+#define PY_RECURSIVELOCK_STATS_STATIC_INIT
+#endif /* PY_RECURSIVELOCK_WANT_STATS */
+} py_recursivelock_t;
+
+#define PY_RECURSIVELOCK_STATIC_INIT(description) \
+	{ PY_LOCK_STATIC_INIT(description), 0, 0, description, NULL, 0 PY_RECURSIVELOCK_STATS_STATIC_INIT }
+
+Py_LOCAL_INLINE(void) py_recursivelock_init(py_recursivelock_t *f, const char *description) {
+	memset(f, 0, sizeof(*f));
+	py_lock_init(&(f->lock), description);
+}
+
+
+#define py_recursivelock_lock(recursivelock) \
+	(_py_recursivelock_lock(recursivelock, __FILE__, __LINE__))
+
+Py_LOCAL_INLINE(void) _py_recursivelock_lock(py_recursivelock_t *recursivelock, const char *file, int line) {
+	threadid_t tid = CURRENT_THREAD_ID;
+
+#ifdef FURTEX_WANT_STATS
+	uint64_t start = cycle_count_get();
+	uint64_t delta;
+#endif /* PY_RECURSIVELOCK_WANT_STATS */
+
+	if (recursivelock->count && ARE_THREADS_EQUAL(recursivelock->tid, tid)) {
+		recursivelock->count++;
+		assert(recursivelock->count > 1);
+		return;
+	}
+
+	_py_lock_lock(&(recursivelock->lock), file, line);
+
+#ifdef PY_RECURSIVELOCK_WANT_STATS
+	delta = cycle_count_get() - start;
+	if (delta <= 250)
+		recursivelock->no_contention_count++;
+	else {
+		recursivelock->contention_count++;
+		recursivelock->contention_total_delay += delta;
+		recursivelock->contention_max_delta = PyMAX(recursivelock->contention_max_delta, delta);
+	}
+#endif /* PY_RECURSIVELOCK_WANT_STATS */
+
+	recursivelock->file = file;
+	recursivelock->line = line;
+	recursivelock->tid = tid;
+	assert(recursivelock->count == 0);
+	recursivelock->count = 1;
+}
+
+Py_LOCAL_INLINE(void) py_recursivelock_unlock(py_recursivelock_t *recursivelock) {
+	/* this function assumes we own the lock! */
+	assert(recursivelock->count > 0);
+	if (--recursivelock->count)
+		return;
+	/* negative number means unlocked! */
+	recursivelock->line = -recursivelock->line;
+	py_lock_unlock(&(recursivelock->lock));
+}
+
+Py_LOCAL_INLINE(void) py_recursivelock_reset_stats(py_recursivelock_t *recursivelock) {
+#ifdef PY_RECURSIVELOCK_WANT_STATS
+	recursivelock->no_contention_count =
+		recursivelock->contention_total_delay =
+		recursivelock->contention_max_delta =
+		recursivelock->contention_count = 0;
+#else
+	(void)recursivelock;
+#endif /* PY_RECURSIVELOCK_WANT_STATS */
+}
+
+void py_lock_stats(py_lock_t *lock);
+void py_recursivelock_stats(py_recursivelock_t *recursivelock);
+
+
+#endif /* __PY_LOCK_H */
diff --git a/Include/lock_linux.h b/Include/lock_linux.h
new file mode 100644
index 0000000000..abc128b039
--- /dev/null
+++ b/Include/lock_linux.h
@@ -0,0 +1,79 @@
+#ifndef Py_LOCK_LINUX_H
+#define Py_LOCK_LINUX_H
+
+#include <linux/futex.h>
+#include <assert.h>
+#include <pthread.h>
+#include <string.h>
+#include <sys/mman.h>
+#include <sys/syscall.h>
+#include <sys/time.h>
+#include <sys/wait.h>
+#include <unistd.h>
+#include <x86intrin.h>
+
+
+typedef pthread_t threadid_t;
+#define CURRENT_THREAD_ID pthread_self()
+#define ARE_THREADS_EQUAL(x, y) (pthread_equal((x), (y)))
+#define ATOMIC_PRE_ADD_SSIZE_T(x, y)  __sync_add_and_fetch((x), (y))
+#define ATOMIC_PRE_SUB_SSIZE_T(x, y)  __sync_sub_and_fetch((x), (y))
+
+
+Py_LOCAL_INLINE(int) syscall_futex(int *futex, int operation, int value) {
+    return syscall(SYS_futex, futex, operation, value, NULL, NULL, NULL);
+}
+
+#define futex_wait(futex, value) \
+    (syscall_futex(futex, FUTEX_WAIT_PRIVATE, value))
+
+#define futex_wake(futex, value) \
+    (syscall_futex(futex, FUTEX_WAKE_PRIVATE, value))
+
+
+#define PY_NATIVELOCK_T int
+
+#define F_UNLOCKED           (0)
+#define F_LOCKED             (1)
+#define F_LOCKED_CONTENTION  (2)
+
+
+
+#define PY_NATIVELOCK_STATIC_INIT() F_UNLOCKED
+
+Py_LOCAL_INLINE(void) py_nativelock_init(PY_NATIVELOCK_T *nativelock) {
+	*nativelock = F_UNLOCKED;
+}
+
+
+Py_LOCAL_INLINE(void) py_nativelock_lock(PY_NATIVELOCK_T *nativelock) {
+	int current = __sync_val_compare_and_swap(nativelock, F_UNLOCKED, F_LOCKED);
+	if (current == F_UNLOCKED)
+		return;
+	if (current != F_LOCKED_CONTENTION)
+		current = __sync_lock_test_and_set(nativelock, F_LOCKED_CONTENTION);
+	while (current != F_UNLOCKED) {
+		futex_wait(nativelock, F_LOCKED_CONTENTION);
+		current = __sync_lock_test_and_set(nativelock, F_LOCKED_CONTENTION);
+	}
+}
+
+Py_LOCAL_INLINE(void) py_nativelock_unlock(PY_NATIVELOCK_T *nativelock) {
+	if (__sync_fetch_and_sub(nativelock, 1) != F_LOCKED) {
+		*nativelock = F_UNLOCKED;
+		futex_wake(nativelock, 1);
+	}
+}
+
+Py_LOCAL_INLINE(uint64_t) cycle_count_get(void) {
+	unsigned int ignored;
+	return __rdtscp(&ignored);
+}
+
+#define CYCLES_PER_SEC 2600000000
+
+Py_LOCAL_INLINE(double) cycle_count_to_seconds(uint64_t cycles) {
+    return cycles / (double)CYCLES_PER_SEC;
+}
+
+#endif /* Py_LOCK_LINUX_H */
diff --git a/Include/lock_pthreads.h b/Include/lock_pthreads.h
new file mode 100644
index 0000000000..35569a41da
--- /dev/null
+++ b/Include/lock_pthreads.h
@@ -0,0 +1,67 @@
+#ifndef Py_LOCK_PTHREADS_H
+#define Py_LOCK_PTHREADS_H
+
+#if defined(__APPLE__)
+#import <mach/mach_time.h>
+#endif  /* __APPLE__ */
+#include <pthread.h>
+#include <x86intrin.h>
+
+
+typedef pthread_t threadid_t;
+#define CURRENT_THREAD_ID pthread_self()
+#define ARE_THREADS_EQUAL(x, y) (pthread_equal((x), (y)))
+#define ATOMIC_PRE_ADD_SSIZE_T(x, y)  __sync_add_and_fetch((x), (y))
+#define ATOMIC_PRE_SUB_SSIZE_T(x, y)  __sync_sub_and_fetch((x), (y))
+
+
+typedef struct py_nativelock_t {
+	pthread_mutex_t mutex;
+} py_nativelock_t;
+
+#define PY_NATIVELOCK_T py_nativelock_t
+
+#define PY_NATIVELOCK_STATIC_INIT() {PTHREAD_MUTEX_INITIALIZER}
+
+
+Py_LOCAL_INLINE(void) py_nativelock_init(PY_NATIVELOCK_T *nativelock) {
+	pthread_mutex_init(&(nativelock->mutex), NULL);
+}
+
+
+Py_LOCAL_INLINE(void) py_nativelock_lock(PY_NATIVELOCK_T *nativelock) {
+	int r;
+
+	r = pthread_mutex_lock(&(nativelock->mutex));
+	if (r != 0) {
+		fprintf(stderr, "py_nativelock_lock(): pthread_mutex_lock failed: %s\n", strerror(r));
+	}
+}
+
+
+Py_LOCAL_INLINE(void) py_nativelock_unlock(PY_NATIVELOCK_T *nativelock) {
+	int r = pthread_mutex_unlock(&(nativelock->mutex));
+	if (r != 0) {
+		fprintf(stderr, "py_nativelock_unlock(): pthread_mutex_unlock failed: %s\n", strerror(r));
+	}
+}
+
+
+Py_LOCAL_INLINE(uint64_t) cycle_count_get(void) {
+	return (uint64_t)mach_absolute_time();
+}
+
+
+Py_LOCAL_INLINE(double) cycle_count_to_seconds(uint64_t cycles) {
+	static double cycles_to_nanoseconds = -1;
+
+	if (cycles_to_nanoseconds == -1) {
+		mach_timebase_info_data_t sTimebaseInfo;
+		mach_timebase_info(&sTimebaseInfo);
+		cycles_to_nanoseconds = (double)sTimebaseInfo.numer / (double)sTimebaseInfo.denom;
+	}
+
+	return (cycles * cycles_to_nanoseconds) / 1000000000;
+}
+
+#endif /* Py_LOCK_PTHREADS_H */
diff --git a/Include/lock_win.h b/Include/lock_win.h
new file mode 100644
index 0000000000..fa410532ee
--- /dev/null
+++ b/Include/lock_win.h
@@ -0,0 +1,27 @@
+#ifndef Py_LOCK_WIN_H
+#define Py_LOCK_WIN_H
+
+#include <Python.h>
+#include <intrin.h>
+
+
+typedef unsigned long threadid_t;
+#define CURRENT_THREAD_ID win32_threadid
+#define ARE_THREADS_EQUAL(x, y) (pthread_equal((x), (y)))
+#define ATOMIC_PRE_ADD_SSIZE_T(x, y)  Py_AtomicAddSSize_t((x), (y))
+#define ATOMIC_PRE_SUB_SSIZE_T(x, y)  Py_AtomicSubSSize_t((x), (y))
+
+PyAPI_FUNC(Py_ssize_t) Py_AtomicAddSSize_t(Py_ssize_t *to, Py_ssize_t value);
+PyAPI_FUNC(Py_ssize_t) Py_AtomicSubSSize_t(Py_ssize_t *to, Py_ssize_t value);
+
+/* we just cast to SRWLOCK */
+#define PY_NATIVELOCK_T void *
+
+// SRWLOCK_INIT would be correct, but we don't want
+// to include windows.h here for some reason
+// #define PY_NATIVELOCK_STATIC_INIT() {SRWLOCK_INIT}
+#define PY_NATIVELOCK_STATIC_INIT() {0}
+
+unsigned long win32_threadid();
+
+#endif /* Py_LOCK_WIN_H */
diff --git a/Include/object.h b/Include/object.h
index eac9541b17..031edbb972 100644
--- a/Include/object.h
+++ b/Include/object.h
@@ -4,6 +4,11 @@
 extern "C" {
 #endif
 
+#include <inttypes.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <unistd.h>
+#include <pyport.h>
 
 /* Object and type object interface */
 
@@ -53,38 +58,38 @@ whose size is determined when the object is allocated.
 
 /* Py_DEBUG implies Py_TRACE_REFS. */
 #if defined(Py_DEBUG) && !defined(Py_TRACE_REFS)
-#define Py_TRACE_REFS
+    #define Py_TRACE_REFS
 #endif
 
 /* Py_TRACE_REFS implies Py_REF_DEBUG. */
 #if defined(Py_TRACE_REFS) && !defined(Py_REF_DEBUG)
-#define Py_REF_DEBUG
+    #define Py_REF_DEBUG
 #endif
 
 #if defined(Py_LIMITED_API) && defined(Py_REF_DEBUG)
-#error Py_LIMITED_API is incompatible with Py_DEBUG, Py_TRACE_REFS, and Py_REF_DEBUG
+    #error Py_LIMITED_API is incompatible with Py_DEBUG, Py_TRACE_REFS, and Py_REF_DEBUG
 #endif
 
 
 #ifdef Py_TRACE_REFS
 /* Define pointers to support a doubly-linked list of all live heap objects. */
-#define _PyObject_HEAD_EXTRA            \
-    struct _object *_ob_next;           \
-    struct _object *_ob_prev;
-
-#define _PyObject_EXTRA_INIT 0, 0,
-
+    #define _PyObject_HEAD_EXTRA            \
+        struct _object *_ob_next;           \
+        struct _object *_ob_prev;
+    #define _PyObject_EXTRA_INIT 0, 0,
 #else
-#define _PyObject_HEAD_EXTRA
-#define _PyObject_EXTRA_INIT
+    #define _PyObject_HEAD_EXTRA
+    #define _PyObject_EXTRA_INIT
 #endif
 
 /* PyObject_HEAD defines the initial segment of every PyObject. */
 #define PyObject_HEAD                   PyObject ob_base;
 
+#define _PyObject_REFCNT_INIT(value) { value }
+
 #define PyObject_HEAD_INIT(type)        \
     { _PyObject_EXTRA_INIT              \
-    1, type },
+    _PyObject_REFCNT_INIT(1), type },
 
 #define PyVarObject_HEAD_INIT(type, size)       \
     { PyObject_HEAD_INIT(type) size },
@@ -98,6 +103,14 @@ whose size is determined when the object is allocated.
 #define PyObject_VAR_HEAD      PyVarObject ob_base;
 #define Py_INVALID_SIZE (Py_ssize_t)-1
 
+typedef struct {
+    Py_ssize_t shared_refcnt;
+} ob_refcnt_t;
+
+/********************* Locking and RefCnt *************************************/
+/* Locking is in separate files */
+#include "lock.h"
+
 /* Nothing is actually declared to be a PyObject, but every pointer to
  * a Python object can be cast to a PyObject*.  This is inheritance built
  * by hand.  Similarly every pointer to a variable-size Python object can,
@@ -105,7 +118,7 @@ whose size is determined when the object is allocated.
  */
 typedef struct _object {
     _PyObject_HEAD_EXTRA
-    Py_ssize_t ob_refcnt;
+    ob_refcnt_t ob_refcnt;
     struct _typeobject *ob_type;
 } PyObject;
 
@@ -114,7 +127,15 @@ typedef struct {
     Py_ssize_t ob_size; /* Number of items in variable part */
 } PyVarObject;
 
-#define Py_REFCNT(ob)           (((PyObject*)(ob))->ob_refcnt)
+Py_LOCAL_INLINE(void) Py_REFCNT_Initialize(PyObject* ob, int value) {
+    ob->ob_refcnt.shared_refcnt = value;
+}
+
+Py_LOCAL_INLINE(Py_ssize_t) Py_REFCNT(PyObject* ob) {
+    /* Warning - this may be slow in future */
+    return ob->ob_refcnt.shared_refcnt;
+}
+
 #define Py_TYPE(ob)             (((PyObject*)(ob))->ob_type)
 #define Py_SIZE(ob)             (((PyVarObject*)(ob))->ob_size)
 
@@ -173,6 +194,7 @@ typedef PyObject *(*ssizessizeargfunc)(PyObject *, Py_ssize_t, Py_ssize_t);
 typedef int(*ssizeobjargproc)(PyObject *, Py_ssize_t, PyObject *);
 typedef int(*ssizessizeobjargproc)(PyObject *, Py_ssize_t, Py_ssize_t, PyObject *);
 typedef int(*objobjargproc)(PyObject *, PyObject *, PyObject *);
+typedef void (*lockfunc)(PyObject *);
 
 #ifndef Py_LIMITED_API
 /* buffer interface */
@@ -421,6 +443,9 @@ typedef struct _typeobject {
 
     destructor tp_finalize;
 
+    lockfunc tp_lock;
+    lockfunc tp_unlock;
+
 #ifdef COUNT_ALLOCS
     /* these must be last and never explicitly initialized */
     Py_ssize_t tp_allocs;
@@ -714,7 +739,7 @@ PyAPI_FUNC(Py_ssize_t) _Py_GetRefTotal(void);
 #define _Py_DEC_REFTOTAL        _Py_RefTotal--
 #define _Py_REF_DEBUG_COMMA     ,
 #define _Py_CHECK_REFCNT(OP)                                    \
-{       if (((PyObject*)OP)->ob_refcnt < 0)                             \
+{       if (Py_REFCNT(OP) < 0)                                  \
                 _Py_NegativeRefcount(__FILE__, __LINE__,        \
                                      (PyObject *)(OP));         \
 }
@@ -761,7 +786,7 @@ PyAPI_FUNC(void) _Py_AddToAllObjects(PyObject *, int force);
 #define _Py_NewReference(op) (                          \
     _Py_INC_TPALLOCS(op) _Py_COUNT_ALLOCS_COMMA         \
     _Py_INC_REFTOTAL  _Py_REF_DEBUG_COMMA               \
-    Py_REFCNT(op) = 1)
+    Py_REFCNT_Initialize(op, 1))
 
 #define _Py_ForgetReference(op) _Py_INC_TPFREES(op)
 
@@ -774,20 +799,35 @@ PyAPI_FUNC(void) _Py_Dealloc(PyObject *);
 #endif
 #endif /* !Py_TRACE_REFS */
 
+#ifdef PY_TIME_REFCOUNTS
+
+int __py_incref__(PyObject *o);
+void __py_decref__(PyObject *o);
+
+#define Py_INCREF(op)                                   \
+    (__py_incref__((PyObject *)(op)))
+
+#define Py_DECREF(op)                                   \
+    __py_decref__((PyObject *)(op))
+
+#else
+
 #define Py_INCREF(op) (                         \
     _Py_INC_REFTOTAL  _Py_REF_DEBUG_COMMA       \
-    ((PyObject *)(op))->ob_refcnt++)
+    ATOMIC_INC(&(((PyObject *)(op))->ob_refcnt.shared_refcnt)) )
 
 #define Py_DECREF(op)                                   \
     do {                                                \
         PyObject *_py_decref_tmp = (PyObject *)(op);    \
         if (_Py_DEC_REFTOTAL  _Py_REF_DEBUG_COMMA       \
-        --(_py_decref_tmp)->ob_refcnt != 0)             \
+        ATOMIC_DEC(&(_py_decref_tmp->ob_refcnt.shared_refcnt)) != 0)  \
             _Py_CHECK_REFCNT(_py_decref_tmp)            \
         else                                            \
-        _Py_Dealloc(_py_decref_tmp);                    \
+            _Py_Dealloc(_py_decref_tmp);                \
     } while (0)
 
+#endif /* PY_TIME_REFCOUNTS */
+
 /* Safely decref `op` and set `op` to NULL, especially useful in tp_clear
  * and tp_dealloc implementations.
  *
diff --git a/Include/objimpl.h b/Include/objimpl.h
index 65b6d91c36..fe0d7dec2b 100644
--- a/Include/objimpl.h
+++ b/Include/objimpl.h
@@ -143,6 +143,10 @@ PyAPI_FUNC(PyVarObject *) _PyObject_NewVar(PyTypeObject *, Py_ssize_t);
 
 #define _PyObject_SIZE(typeobj) ( (typeobj)->tp_basicsize )
 
+#ifndef Py_LIMITED_API
+PyAPI_FUNC(void) _Py_ObMalloc_Init(void);
+#endif
+
 /* _PyObject_VAR_SIZE returns the number of bytes (as size_t) allocated for a
    vrbl-size object with nitems items, exclusive of gc overhead (if any).  The
    value is rounded up to the closest multiple of sizeof(void *), in order to
@@ -253,6 +257,11 @@ typedef union _gc_head {
     double dummy;  /* force worst-case alignment */
 } PyGC_Head;
 
+#define gc_lock() (_gc_lock(__FILE__, __LINE__))
+PyAPI_FUNC(void) _gc_lock(const char *file, int line);
+#define gc_lock2(f) (_gc_lock2((f), __FILE__, __LINE__))
+PyAPI_FUNC(void) _gc_lock2(py_recursivelock_t *, const char *file, int line);
+PyAPI_FUNC(void) gc_unlock(void);
 extern PyGC_Head *_PyGC_generation0;
 
 #define _Py_AS_GC(o) ((PyGC_Head *)(o)-1)
@@ -287,8 +296,10 @@ extern PyGC_Head *_PyGC_generation0;
 
 /* Tell the GC to track this object.  NB: While the object is tracked the
  * collector it must be safe to call the ob_traverse method. */
+#if 0
 #define _PyObject_GC_TRACK(o) do { \
     PyGC_Head *g = _Py_AS_GC(o); \
+    gc_lock(); \
     if (_PyGCHead_REFS(g) != _PyGC_REFS_UNTRACKED) \
         Py_FatalError("GC object already tracked"); \
     _PyGCHead_SET_REFS(g, _PyGC_REFS_REACHABLE); \
@@ -296,6 +307,7 @@ extern PyGC_Head *_PyGC_generation0;
     g->gc.gc_prev = _PyGC_generation0->gc.gc_prev; \
     g->gc.gc_prev->gc.gc_next = g; \
     _PyGC_generation0->gc.gc_prev = g; \
+    gc_unlock(); \
     } while (0);
 
 /* Tell the GC to stop tracking this object.
@@ -304,13 +316,23 @@ extern PyGC_Head *_PyGC_generation0;
  */
 #define _PyObject_GC_UNTRACK(o) do { \
     PyGC_Head *g = _Py_AS_GC(o); \
+    gc_lock(); \
     assert(_PyGCHead_REFS(g) != _PyGC_REFS_UNTRACKED); \
     _PyGCHead_SET_REFS(g, _PyGC_REFS_UNTRACKED); \
     g->gc.gc_prev->gc.gc_next = g->gc.gc_next; \
     g->gc.gc_next->gc.gc_prev = g->gc.gc_prev; \
     g->gc.gc_next = NULL; \
+    gc_unlock(); \
     } while (0);
 
+#else
+
+#define _PyObject_GC_TRACK(o)
+    
+#define _PyObject_GC_UNTRACK(o)
+
+#endif
+
 /* True if the object is currently tracked by the GC. */
 #define _PyObject_GC_IS_TRACKED(o) \
     (_PyGC_REFS(o) != _PyGC_REFS_UNTRACKED)
@@ -320,6 +342,7 @@ extern PyGC_Head *_PyGC_generation0;
 #define _PyObject_GC_MAY_BE_TRACKED(obj) \
     (PyObject_IS_GC(obj) && \
         (!PyTuple_CheckExact(obj) || _PyObject_GC_IS_TRACKED(obj)))
+
 #endif /* Py_LIMITED_API */
 
 PyAPI_FUNC(PyObject *) _PyObject_GC_Malloc(size_t size);
diff --git a/Include/pylifecycle.h b/Include/pylifecycle.h
index e96eb70ff7..4ce8ee0089 100644
--- a/Include/pylifecycle.h
+++ b/Include/pylifecycle.h
@@ -86,6 +86,7 @@ PyAPI_FUNC(int) _PyFloat_Init(void);
 PyAPI_FUNC(int) PyByteArray_Init(void);
 PyAPI_FUNC(void) _PyRandom_Init(void);
 #endif
+PyAPI_FUNC(int) _PySet_Init(void);
 
 /* Various internal finalizers */
 #ifndef Py_LIMITED_API
diff --git a/Include/pymem.h b/Include/pymem.h
index 043db64deb..f63cb1fc80 100644
--- a/Include/pymem.h
+++ b/Include/pymem.h
@@ -16,8 +16,8 @@ PyAPI_FUNC(void *) PyMem_RawMalloc(size_t size);
 PyAPI_FUNC(void *) PyMem_RawCalloc(size_t nelem, size_t elsize);
 PyAPI_FUNC(void *) PyMem_RawRealloc(void *ptr, size_t new_size);
 PyAPI_FUNC(void) PyMem_RawFree(void *ptr);
-#endif
 
+#endif
 
 /* BEWARE:
 
@@ -181,6 +181,11 @@ PyAPI_FUNC(void) PyMem_SetAllocator(PyMemAllocatorDomain domain,
 PyAPI_FUNC(void) PyMem_SetupDebugHooks(void);
 #endif
 
+PyAPI_FUNC(Py_ssize_t) Py_AtomicInc(Py_ssize_t* value);
+PyAPI_FUNC(Py_ssize_t) Py_AtomicDec(Py_ssize_t* value);
+PyAPI_FUNC(Py_ssize_t) Py_AtomicAdd(Py_ssize_t* to, Py_ssize_t value);
+
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/Include/pystate.h b/Include/pystate.h
index b50b16b39c..cf6896942e 100644
--- a/Include/pystate.h
+++ b/Include/pystate.h
@@ -85,6 +85,9 @@ typedef struct _ts {
     int tracing;
     int use_tracing;
 
+    /* Track to what extent parallelism is hurting refcounting */
+    py_time_refcounts_t py_time_refcounts;
+
     Py_tracefunc c_profilefunc;
     Py_tracefunc c_tracefunc;
     PyObject *c_profileobj;
@@ -108,6 +111,10 @@ typedef struct _ts {
     int trash_delete_nesting;
     PyObject *trash_delete_later;
 
+    #define PyFrame_MAXFREELIST 100 /* per thread */
+    struct _frame *frame_freelist;
+    int frame_freelist_count;
+
     /* Called when a thread state is deleted normally, but not when it
      * is destroyed after fork().
      * Pain:  to prevent rare but fatal shutdown errors (issue 18808),
@@ -168,6 +175,10 @@ PyAPI_FUNC(void) PyThreadState_DeleteCurrent(void);
 PyAPI_FUNC(void) _PyGILState_Reinit(void);
 #endif
 
+PyAPI_FUNC(struct _frame *) PyThreadState_FrameFreeListAlloc(PyThreadState *tstate);
+PyAPI_FUNC(void) PyThreadState_FrameFreeListFree(PyThreadState *tstate, struct _frame *o);
+PyAPI_FUNC(void) PyThreadState_FrameFreeListClear(PyThreadState *tstate);
+
 /* Return the current thread state. The global interpreter lock must be held.
  * When the current thread state is NULL, this issues a fatal error (so that
  * the caller needn't check for NULL). */
@@ -189,9 +200,7 @@ PyAPI_FUNC(int) PyThreadState_SetAsyncExc(long, PyObject *);
 /* Assuming the current thread holds the GIL, this is the
    PyThreadState for the current thread. */
 #ifdef Py_BUILD_CORE
-PyAPI_DATA(_Py_atomic_address) _PyThreadState_Current;
-#  define PyThreadState_GET() \
-             ((PyThreadState*)_Py_atomic_load_relaxed(&_PyThreadState_Current))
+#  define PyThreadState_GET() PyGILState_GetThisThreadState()
 #else
 #  define PyThreadState_GET() PyThreadState_Get()
 #endif
@@ -275,6 +284,8 @@ typedef struct _frame *(*PyThreadFrameGetter)(PyThreadState *self_);
 PyAPI_DATA(PyThreadFrameGetter) _PyThreadState_GetFrame;
 #endif
 
+PyAPI_FUNC(py_time_refcounts_t *) PyState_GetThisThreadPyTimeRefcounts(void);
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/Include/setobject.h b/Include/setobject.h
index 87ec1c8afc..9ef939d5f7 100644
--- a/Include/setobject.h
+++ b/Include/setobject.h
@@ -62,6 +62,7 @@ typedef struct {
 
     setentry smalltable[PySet_MINSIZE];
     PyObject *weakreflist;      /* List of weak references */
+    py_recursivelock_t lock;
 } PySetObject;
 
 #define PySet_GET_SIZE(so) (((PySetObject *)(so))->used)
diff --git a/Lib/test/test_ordered_dict.py b/Lib/test/test_ordered_dict.py
index 633e90919b..0391b6b95e 100644
--- a/Lib/test/test_ordered_dict.py
+++ b/Lib/test/test_ordered_dict.py
@@ -627,7 +627,7 @@ class CPythonOrderedDictTests(OrderedDictTests, unittest.TestCase):
         size = support.calcobjsize
         check = self.check_sizeof
 
-        basicsize = size('n2P' + '3PnPn2P') + calcsize('2nPn')
+        basicsize = size('n2PiiL' + '3PnPn2P') + calcsize('2nPn')
         entrysize = calcsize('n2P') + calcsize('P')
         nodesize = calcsize('Pn2P')
 
diff --git a/Lib/test/test_sys.py b/Lib/test/test_sys.py
index 6046671c9c..6bea838587 100644
--- a/Lib/test/test_sys.py
+++ b/Lib/test/test_sys.py
@@ -916,9 +916,9 @@ class SizeofTest(unittest.TestCase):
         # method-wrapper (descriptor object)
         check({}.__iter__, size('2P'))
         # dict
-        check({}, size('n2P') + calcsize('2nPn') + 8*calcsize('n2P'))
+        check({}, size('n2PiiL') + calcsize('2nPn') + 8*calcsize('n2P'))
         longdict = {1:1, 2:2, 3:3, 4:4, 5:5, 6:6, 7:7, 8:8}
-        check(longdict, size('n2P') + calcsize('2nPn') + 16*calcsize('n2P'))
+        check(longdict, size('n2PiiL') + calcsize('2nPn') + 16*calcsize('n2P'))
         # dictionary-keyview
         check({}.keys(), size('P'))
         # dictionary-valueview
@@ -1064,7 +1064,7 @@ class SizeofTest(unittest.TestCase):
         check((1,2,3), vsize('') + 3*self.P)
         # type
         # static type: PyTypeObject
-        s = vsize('P2n15Pl4Pn9Pn11PIP')
+        s = vsize('P2n15Pl4Pn9Pn11PIPPPPP')
         check(int, s)
         s = vsize('P2n15Pl4Pn9Pn11PIP'  # PyTypeObject
                   '3P'                  # PyAsyncMethods
@@ -1072,14 +1072,14 @@ class SizeofTest(unittest.TestCase):
                   '3P'                  # PyMappingMethods
                   '10P'                 # PySequenceMethods
                   '2P'                  # PyBufferProcs
-                  '4P')
+                  '4PPPPP')
         # Separate block for PyDictKeysObject with 4 entries
         s += calcsize("2nPn") + 4*calcsize("n2P")
         # class
         class newstyleclass(object): pass
         check(newstyleclass, s)
         # dict with shared keys
-        check(newstyleclass().__dict__, size('n2P' + '2nPn'))
+        check(newstyleclass().__dict__, size('n2PiiL' + '2nPn'))
         # unicode
         # each tuple contains a string and its expected character size
         # don't put any static strings here, as they may contain
diff --git a/Makefile.pre.in b/Makefile.pre.in
index 57167e61d3..411f359637 100644
--- a/Makefile.pre.in
+++ b/Makefile.pre.in
@@ -315,6 +315,7 @@ PGSRCS=		\
 
 PGOBJS=		\
 		Objects/obmalloc.o \
+		Objects/refcount.o \
 		Python/dynamic_annotations.o \
 		Python/mysnprintf.o \
 		Python/pyctype.o \
@@ -384,6 +385,7 @@ PYTHON_OBJS=	\
 		Python/graminit.o \
 		Python/import.o \
 		Python/importdl.o \
+		Python/lock_linux.o \
 		Python/marshal.o \
 		Python/modsupport.o \
 		Python/mystrtoul.o \
@@ -450,6 +452,7 @@ OBJECT_OBJS=	\
 		Objects/obmalloc.o \
 		Objects/capsule.o \
 		Objects/rangeobject.o \
+		Objects/refcount.o \
 		Objects/setobject.o \
 		Objects/sliceobject.o \
 		Objects/structseq.o \
diff --git a/Modules/_collectionsmodule.c b/Modules/_collectionsmodule.c
index fbf07a87a5..181d7aa764 100644
--- a/Modules/_collectionsmodule.c
+++ b/Modules/_collectionsmodule.c
@@ -7,6 +7,13 @@
 #include <sys/types.h>          /* For size_t */
 #endif
 
+static py_recursivelock_t module_rlock = PY_RECURSIVELOCK_STATIC_INIT("collections module lock");
+#define module_lock() py_recursivelock_lock(&module_rlock)
+#define module_unlock() py_recursivelock_unlock(&module_rlock)
+void collectionsmodule_lock_stats(void) {
+    py_recursivelock_stats(&module_rlock);
+}
+
 /* collections module implementation of a deque() datatype
    Written and maintained by Raymond D. Hettinger <python@rcn.com>
 */
@@ -120,10 +127,14 @@ static block *freeblocks[MAXFREEBLOCKS];
 static block *
 newblock(void) {
     block *b;
+    module_lock();
     if (numfreeblocks) {
         numfreeblocks--;
-        return freeblocks[numfreeblocks];
+        b = freeblocks[numfreeblocks];
+        module_unlock();
+        return b;
     }
+    module_unlock();
     b = PyMem_Malloc(sizeof(block));
     if (b != NULL) {
         return b;
@@ -135,10 +146,13 @@ newblock(void) {
 static void
 freeblock(block *b)
 {
+    module_lock();
     if (numfreeblocks < MAXFREEBLOCKS) {
         freeblocks[numfreeblocks] = b;
         numfreeblocks++;
+        module_unlock();
     } else {
+        module_unlock();
         PyMem_Free(b);
     }
 }
diff --git a/Modules/_functoolsmodule.c b/Modules/_functoolsmodule.c
index 035d3d9c59..05e5d2bb1f 100644
--- a/Modules/_functoolsmodule.c
+++ b/Modules/_functoolsmodule.c
@@ -541,7 +541,7 @@ functools_reduce(PyObject *self, PyObject *args)
     for (;;) {
         PyObject *op2;
 
-        if (args->ob_refcnt > 1) {
+        if (Py_REFCNT(args) > 1) {
             Py_DECREF(args);
             if ((args = PyTuple_New(2)) == NULL)
                 goto Fail;
diff --git a/Modules/_testcapimodule.c b/Modules/_testcapimodule.c
index fbb4aa4674..2d5440befc 100644
--- a/Modules/_testcapimodule.c
+++ b/Modules/_testcapimodule.c
@@ -2710,8 +2710,8 @@ slot_tp_del(PyObject *self)
     PyObject *error_type, *error_value, *error_traceback;
 
     /* Temporarily resurrect the object. */
-    assert(self->ob_refcnt == 0);
-    self->ob_refcnt = 1;
+    assert(Py_REFCNT(self) == 0);
+    Py_REFCNT_Initialize(self, 1);
 
     /* Save the current exception, if any. */
     PyErr_Fetch(&error_type, &error_value, &error_traceback);
@@ -2733,17 +2733,18 @@ slot_tp_del(PyObject *self)
     /* Undo the temporary resurrection; can't use DECREF here, it would
      * cause a recursive call.
      */
-    assert(self->ob_refcnt > 0);
-    if (--self->ob_refcnt == 0)
+    assert(Py_REFCNT(self) > 0);
+    Py_DECREF(self);
+    if (Py_REFCNT(self) == 0)
         return;         /* this is the normal path out */
 
     /* __del__ resurrected it!  Make it look like the original Py_DECREF
      * never happened.
      */
     {
-        Py_ssize_t refcnt = self->ob_refcnt;
+        ob_refcnt_t refcnt = Py_REFCNT(self);
         _Py_NewReference(self);
-        self->ob_refcnt = refcnt;
+        Py_REFCNT_Initialize(self, refcnt);
     }
     assert(!PyType_IS_GC(Py_TYPE(self)) ||
            _Py_AS_GC(self)->gc.gc_refs != _PyGC_REFS_UNTRACKED);
diff --git a/Modules/_threadmodule.c b/Modules/_threadmodule.c
index bcb3aeeb22..018fd5a9d1 100644
--- a/Modules/_threadmodule.c
+++ b/Modules/_threadmodule.c
@@ -17,6 +17,13 @@ static PyObject *ThreadError;
 static long nb_threads = 0;
 static PyObject *str_dict;
 
+static py_recursivelock_t module_rlock = PY_RECURSIVELOCK_STATIC_INIT("_threadmodule lock");
+#define module_lock() py_recursivelock_lock(&module_rlock)
+#define module_unlock() py_recursivelock_unlock(&module_rlock)
+void threadmodule_lock_stats(void) {
+    py_recursivelock_stats(&module_rlock);
+}
+
 _Py_IDENTIFIER(stderr);
 
 /* Lock objects */
@@ -178,8 +185,8 @@ lock_PyThread_release_lock(lockobject *self)
         return NULL;
     }
 
-    PyThread_release_lock(self->lock_lock);
     self->locked = 0;
+    PyThread_release_lock(self->lock_lock);
     Py_INCREF(Py_None);
     return Py_None;
 }
@@ -994,7 +1001,9 @@ t_bootstrap(void *boot_raw)
     tstate->thread_id = PyThread_get_thread_ident();
     _PyThreadState_Init(tstate);
     PyEval_AcquireThread(tstate);
+    module_lock();
     nb_threads++;
+    module_unlock();
     res = PyEval_CallObjectWithKeywords(
         boot->func, boot->args, boot->keyw);
     if (res == NULL) {
@@ -1022,7 +1031,9 @@ t_bootstrap(void *boot_raw)
     Py_DECREF(boot->args);
     Py_XDECREF(boot->keyw);
     PyMem_DEL(boot_raw);
+    module_lock();
     nb_threads--;
+    module_unlock();
     PyThreadState_Clear(tstate);
     PyThreadState_DeleteCurrent();
     PyThread_exit_thread();
@@ -1162,7 +1173,11 @@ A thread's identity may be reused for another thread after it exits.");
 static PyObject *
 thread__count(PyObject *self)
 {
-    return PyLong_FromLong(nb_threads);
+    PyObject* result = NULL;
+    module_lock();
+    result = PyLong_FromLong(nb_threads);
+    module_unlock();
+    return result;
 }
 
 PyDoc_STRVAR(_count_doc,
diff --git a/Modules/gcmodule.c b/Modules/gcmodule.c
index 0c6f4448f0..fbc76fd905 100644
--- a/Modules/gcmodule.c
+++ b/Modules/gcmodule.c
@@ -912,6 +912,17 @@ collect(int generation, Py_ssize_t *n_collected, Py_ssize_t *n_uncollectable,
 
     struct gc_generation_stats *stats = &generation_stats[generation];
 
+    if (n_uncollectable) {
+        *n_uncollectable = 0;  /* Never otherwise assigned */
+    }
+    if (n_collected) {
+        *n_collected = 0;  /* Never otherwise assigned */
+    }
+
+    /* GILECTOMY: disable GC for now */
+    return 0;
+
+    gc_lock();
     if (debug & DEBUG_STATS) {
         PySys_WriteStderr("gc: collecting generation %d...\n",
                           generation);
@@ -1068,6 +1079,7 @@ collect(int generation, Py_ssize_t *n_collected, Py_ssize_t *n_uncollectable,
     stats->collections++;
     stats->collected += m;
     stats->uncollectable += n;
+    gc_unlock();
     return n+m;
 }
 
@@ -1082,8 +1094,11 @@ invoke_gc_callback(const char *phase, int generation,
     PyObject *info = NULL;
 
     /* we may get called very early */
-    if (callbacks == NULL)
+    gc_lock();
+    if (callbacks == NULL) {
+        gc_unlock();
         return;
+    }
     /* The local variable cannot be rebound, check it for sanity */
     assert(callbacks != NULL && PyList_CheckExact(callbacks));
     if (PyList_GET_SIZE(callbacks) != 0) {
@@ -1093,6 +1108,7 @@ invoke_gc_callback(const char *phase, int generation,
             "uncollectable", uncollectable);
         if (info == NULL) {
             PyErr_WriteUnraisable(NULL);
+            gc_unlock();
             return;
         }
     }
@@ -1106,6 +1122,7 @@ invoke_gc_callback(const char *phase, int generation,
         Py_DECREF(cb);
     }
     Py_XDECREF(info);
+    gc_unlock();
 }
 
 /* Perform garbage collection of a generation and invoke
@@ -1114,10 +1131,12 @@ invoke_gc_callback(const char *phase, int generation,
 static Py_ssize_t
 collect_with_callback(int generation)
 {
-    Py_ssize_t result, collected, uncollectable;
+    Py_ssize_t result = 0, collected = 0, uncollectable = 0;
+    gc_lock();
     invoke_gc_callback("start", generation, 0, 0);
     result = collect(generation, &collected, &uncollectable, 0);
     invoke_gc_callback("stop", generation, collected, uncollectable);
+    gc_unlock();
     return result;
 }
 
@@ -1127,6 +1146,7 @@ collect_generations(void)
     int i;
     Py_ssize_t n = 0;
 
+    gc_lock();
     /* Find the oldest generation (highest numbered) where the count
      * exceeds the threshold.  Objects in the that generation and
      * generations younger than it will be collected. */
@@ -1143,6 +1163,7 @@ collect_generations(void)
             break;
         }
     }
+    gc_unlock();
     return n;
 }
 
@@ -1206,6 +1227,7 @@ gc_collect(PyObject *self, PyObject *args, PyObject *kws)
         return NULL;
     }
 
+    gc_lock();
     if (collecting)
         n = 0; /* already collecting, don't do anything */
     else {
@@ -1213,6 +1235,7 @@ gc_collect(PyObject *self, PyObject *args, PyObject *kws)
         n = collect_with_callback(genarg);
         collecting = 0;
     }
+    gc_unlock();
 
     return PyLong_FromSsize_t(n);
 }
@@ -1234,7 +1257,12 @@ PyDoc_STRVAR(gc_set_debug__doc__,
 static PyObject *
 gc_set_debug(PyObject *self, PyObject *args)
 {
-    if (!PyArg_ParseTuple(args, "i:set_debug", &debug))
+    int status;
+    gc_lock();
+    status = PyArg_ParseTuple(args, "i:set_debug", &debug);
+    gc_unlock();
+
+    if (!status)
         return NULL;
 
     Py_INCREF(Py_None);
@@ -1249,7 +1277,11 @@ PyDoc_STRVAR(gc_get_debug__doc__,
 static PyObject *
 gc_get_debug(PyObject *self, PyObject *noargs)
 {
-    return Py_BuildValue("i", debug);
+    PyObject *result;
+    gc_lock();
+    result = Py_BuildValue("i", debug);
+    gc_unlock();
+    return result;
 }
 
 PyDoc_STRVAR(gc_set_thresh__doc__,
@@ -1262,16 +1294,20 @@ static PyObject *
 gc_set_thresh(PyObject *self, PyObject *args)
 {
     int i;
+    gc_lock();
     if (!PyArg_ParseTuple(args, "i|ii:set_threshold",
                           &generations[0].threshold,
                           &generations[1].threshold,
-                          &generations[2].threshold))
+                          &generations[2].threshold)) {
+        gc_unlock();
         return NULL;
+    }
     for (i = 2; i < NUM_GENERATIONS; i++) {
         /* generations higher than 2 get the same threshold */
         generations[i].threshold = generations[2].threshold;
     }
 
+    gc_unlock();
     Py_INCREF(Py_None);
     return Py_None;
 }
@@ -1284,10 +1320,14 @@ PyDoc_STRVAR(gc_get_thresh__doc__,
 static PyObject *
 gc_get_thresh(PyObject *self, PyObject *noargs)
 {
-    return Py_BuildValue("(iii)",
+    PyObject *result;
+    gc_lock();
+    result = Py_BuildValue("(iii)",
                          generations[0].threshold,
                          generations[1].threshold,
                          generations[2].threshold);
+    gc_unlock();
+    return result;
 }
 
 PyDoc_STRVAR(gc_get_count__doc__,
@@ -1298,10 +1338,14 @@ PyDoc_STRVAR(gc_get_count__doc__,
 static PyObject *
 gc_get_count(PyObject *self, PyObject *noargs)
 {
-    return Py_BuildValue("(iii)",
+    PyObject *result;
+    gc_lock();
+    result = Py_BuildValue("(iii)",
                          generations[0].count,
                          generations[1].count,
                          generations[2].count);
+    gc_unlock();
+    return result;
 }
 
 static int
@@ -1344,12 +1388,15 @@ gc_get_referrers(PyObject *self, PyObject *args)
     PyObject *result = PyList_New(0);
     if (!result) return NULL;
 
+    gc_lock();
     for (i = 0; i < NUM_GENERATIONS; i++) {
         if (!(gc_referrers_for(args, GEN_HEAD(i), result))) {
             Py_DECREF(result);
+            gc_unlock();
             return NULL;
         }
     }
+    gc_unlock();
     return result;
 }
 
@@ -1373,6 +1420,7 @@ gc_get_referents(PyObject *self, PyObject *args)
     if (result == NULL)
         return NULL;
 
+    gc_lock();
     for (i = 0; i < PyTuple_GET_SIZE(args); i++) {
         traverseproc traverse;
         PyObject *obj = PyTuple_GET_ITEM(args, i);
@@ -1384,9 +1432,11 @@ gc_get_referents(PyObject *self, PyObject *args)
             continue;
         if (traverse(obj, (visitproc)referentsvisit, result)) {
             Py_DECREF(result);
+            gc_unlock();
             return NULL;
         }
     }
+    gc_unlock();
     return result;
 }
 
@@ -1405,12 +1455,15 @@ gc_get_objects(PyObject *self, PyObject *noargs)
     result = PyList_New(0);
     if (result == NULL)
         return NULL;
+    gc_lock();
     for (i = 0; i < NUM_GENERATIONS; i++) {
         if (append_objects(result, GEN_HEAD(i))) {
             Py_DECREF(result);
+            gc_unlock();
             return NULL;
         }
     }
+    gc_unlock();
     return result;
 }
 
@@ -1426,6 +1479,7 @@ gc_get_stats(PyObject *self, PyObject *noargs)
     PyObject *result;
     struct gc_generation_stats stats[NUM_GENERATIONS], *st;
 
+    gc_lock();
     /* To get consistent values despite allocations while constructing
        the result list, we use a snapshot of the running stats. */
     for (i = 0; i < NUM_GENERATIONS; i++) {
@@ -1433,8 +1487,10 @@ gc_get_stats(PyObject *self, PyObject *noargs)
     }
 
     result = PyList_New(0);
-    if (result == NULL)
+    if (result == NULL) {
+        gc_unlock();
         return NULL;
+    }
 
     for (i = 0; i < NUM_GENERATIONS; i++) {
         PyObject *dict;
@@ -1452,9 +1508,11 @@ gc_get_stats(PyObject *self, PyObject *noargs)
         }
         Py_DECREF(dict);
     }
+    gc_unlock();
     return result;
 
 error:
+    gc_unlock();
     Py_XDECREF(result);
     return NULL;
 }
@@ -1472,10 +1530,12 @@ gc_is_tracked(PyObject *self, PyObject *obj)
 {
     PyObject *result;
 
+    gc_lock();
     if (PyObject_IS_GC(obj) && IS_TRACKED(obj))
         result = Py_True;
     else
         result = Py_False;
+    gc_unlock();
     Py_INCREF(result);
     return result;
 }
@@ -1532,33 +1592,70 @@ static struct PyModuleDef gcmodule = {
     NULL               /* m_free */
 };
 
+static py_recursivelock_t gc_rlock = PY_RECURSIVELOCK_STATIC_INIT("gc lock");
+
+void _gc_lock(const char *file, int line)
+{
+    _py_recursivelock_lock(&gc_rlock, file, line);
+}
+
+void _gc_lock2(py_recursivelock_t *f2, const char *file, int line)
+{
+    if (f2 && (f2 <= &gc_rlock))
+        _py_recursivelock_lock(f2, file, line);
+    _py_recursivelock_lock(&gc_rlock, file, line);
+    if (f2 > &gc_rlock)
+        _py_recursivelock_lock(f2, file, line);
+}
+
+void gc_unlock(void)
+{
+    py_recursivelock_unlock(&gc_rlock);
+}
+
 PyMODINIT_FUNC
 PyInit_gc(void)
 {
     PyObject *m;
 
+
     m = PyModule_Create(&gcmodule);
 
     if (m == NULL)
         return NULL;
 
+    gc_lock();
     if (garbage == NULL) {
         garbage = PyList_New(0);
-        if (garbage == NULL)
+        if (garbage == NULL) {
+            gc_unlock();
             return NULL;
+        }
     }
     Py_INCREF(garbage);
-    if (PyModule_AddObject(m, "garbage", garbage) < 0)
+    if (PyModule_AddObject(m, "garbage", garbage) < 0) {
+        gc_unlock();
         return NULL;
+    }
 
     if (callbacks == NULL) {
         callbacks = PyList_New(0);
-        if (callbacks == NULL)
+        if (callbacks == NULL) {
+            gc_unlock();
             return NULL;
+
+        }
     }
     Py_INCREF(callbacks);
-    if (PyModule_AddObject(m, "callbacks", callbacks) < 0)
+    if (PyModule_AddObject(m, "callbacks", callbacks) < 0) {
+        gc_unlock();
         return NULL;
+    }
+
+#ifdef GC_TRACK_STATS
+    printf("gc_rlock description %s\n", gc_rlock.description);
+    py_recursivelock_stats(&gc_rlock);
+#endif /* GC_TRACK_STATS */
 
 #define ADD_INT(NAME) if (PyModule_AddIntConstant(m, #NAME, NAME) < 0) return NULL
     ADD_INT(DEBUG_STATS);
@@ -1567,6 +1664,9 @@ PyInit_gc(void)
     ADD_INT(DEBUG_SAVEALL);
     ADD_INT(DEBUG_LEAK);
 #undef ADD_INT
+
+    gc_unlock();
+    
     return m;
 }
 
@@ -1576,6 +1676,7 @@ PyGC_Collect(void)
 {
     Py_ssize_t n;
 
+    gc_lock();
     if (collecting)
         n = 0; /* already collecting, don't do anything */
     else {
@@ -1583,6 +1684,7 @@ PyGC_Collect(void)
         n = collect_with_callback(NUM_GENERATIONS - 1);
         collecting = 0;
     }
+    gc_unlock();
 
     return n;
 }
@@ -1598,6 +1700,7 @@ _PyGC_CollectNoFail(void)
        during interpreter shutdown (and then never finish it).
        See http://bugs.python.org/issue8713#msg195178 for an example.
        */
+    gc_lock();
     if (collecting)
         n = 0;
     else {
@@ -1605,6 +1708,7 @@ _PyGC_CollectNoFail(void)
         n = collect(NUM_GENERATIONS - 1, NULL, NULL, 1);
         collecting = 0;
     }
+    gc_unlock();
     return n;
 }
 
@@ -1648,6 +1752,10 @@ void
 _PyGC_Fini(void)
 {
     Py_CLEAR(callbacks);
+#ifdef GC_TRACK_STATS
+    printf("gc_rlock description %s\n", gc_rlock.description);
+    py_recursivelock_stats(&gc_rlock);
+#endif /* GC_TRACK_STATS */
 }
 
 /* for debugging */
@@ -1698,6 +1806,7 @@ _PyObject_GC_Alloc(int use_calloc, size_t basicsize)
         return PyErr_NoMemory();
     g->gc.gc_refs = 0;
     _PyGCHead_SET_REFS(g, GC_UNTRACKED);
+    gc_lock();
     generations[0].count++; /* number of allocated GC objects */
     if (generations[0].count > generations[0].threshold &&
         enabled &&
@@ -1708,6 +1817,7 @@ _PyObject_GC_Alloc(int use_calloc, size_t basicsize)
         collect_generations();
         collecting = 0;
     }
+    gc_unlock();
     op = FROM_GC(g);
     return op;
 }
@@ -1769,10 +1879,12 @@ void
 PyObject_GC_Del(void *op)
 {
     PyGC_Head *g = AS_GC(op);
+    gc_lock();
     if (IS_TRACKED(op))
         gc_list_remove(g);
     if (generations[0].count > 0) {
         generations[0].count--;
     }
+    gc_unlock();
     PyObject_FREE(g);
 }
diff --git a/Modules/socketmodule.c b/Modules/socketmodule.c
index 7ab534e07a..326904a906 100644
--- a/Modules/socketmodule.c
+++ b/Modules/socketmodule.c
@@ -4145,8 +4145,8 @@ sock_dealloc(PySocketSockObject *s)
 {
     if (s->sock_fd != -1) {
         PyObject *exc, *val, *tb;
-        Py_ssize_t old_refcount = Py_REFCNT(s);
-        ++Py_REFCNT(s);
+        Py_ssize_t old_refcount = Py_REFCNT((PyObject *)s);
+        Py_INCREF((PyObject *)s);
         PyErr_Fetch(&exc, &val, &tb);
         if (PyErr_WarnFormat(PyExc_ResourceWarning, 1,
                              "unclosed %R", s))
@@ -4155,7 +4155,7 @@ sock_dealloc(PySocketSockObject *s)
                 PyErr_WriteUnraisable((PyObject *) s);
         PyErr_Restore(exc, val, tb);
         (void) SOCKETCLOSE(s->sock_fd);
-        Py_REFCNT(s) = old_refcount;
+        Py_REFCNT_Initialize((PyObject *)s, old_refcount);
     }
     Py_TYPE(s)->tp_free((PyObject *)s);
 }
diff --git a/Objects/bytes_methods.c b/Objects/bytes_methods.c
index d02535143e..50c45a465c 100644
--- a/Objects/bytes_methods.c
+++ b/Objects/bytes_methods.c
@@ -146,8 +146,9 @@ _Py_bytes_islower(const char *cptr, Py_ssize_t len)
     e = p + len;
     cased = 0;
     for (; p < e; p++) {
-        if (Py_ISUPPER(*p))
+        if (Py_ISUPPER(*p)) {
             Py_RETURN_FALSE;
+        }
         else if (!cased && Py_ISLOWER(*p))
             cased = 1;
     }
@@ -180,8 +181,9 @@ _Py_bytes_isupper(const char *cptr, Py_ssize_t len)
     e = p + len;
     cased = 0;
     for (; p < e; p++) {
-        if (Py_ISLOWER(*p))
+        if (Py_ISLOWER(*p)) {
             Py_RETURN_FALSE;
+        }
         else if (!cased && Py_ISUPPER(*p))
             cased = 1;
     }
diff --git a/Objects/classobject.c b/Objects/classobject.c
index 5e8ac59df2..1ad6ec1059 100644
--- a/Objects/classobject.c
+++ b/Objects/classobject.c
@@ -3,6 +3,13 @@
 #include "Python.h"
 #include "structmember.h"
 
+static py_recursivelock_t module_rlock = PY_RECURSIVELOCK_STATIC_INIT("class module lock");
+#define module_lock() py_recursivelock_lock(&module_rlock)
+#define module_unlock() py_recursivelock_unlock(&module_rlock)
+void classobject_lock_stats(void) {
+    py_recursivelock_stats(&module_rlock);
+}
+
 #define TP_DESCR_GET(t) ((t)->tp_descr_get)
 
 /* Free list for method objects to safe malloc/free overhead
@@ -50,13 +57,16 @@ PyMethod_New(PyObject *func, PyObject *self)
         PyErr_BadInternalCall();
         return NULL;
     }
+    module_lock();
     im = free_list;
     if (im != NULL) {
         free_list = (PyMethodObject *)(im->im_self);
-        (void)PyObject_INIT(im, &PyMethod_Type);
         numfree--;
+        module_unlock();
+        (void)PyObject_INIT(im, &PyMethod_Type);
     }
     else {
+        module_unlock();
         im = PyObject_GC_New(PyMethodObject, &PyMethod_Type);
         if (im == NULL)
             return NULL;
@@ -196,12 +206,15 @@ method_dealloc(PyMethodObject *im)
         PyObject_ClearWeakRefs((PyObject *)im);
     Py_DECREF(im->im_func);
     Py_XDECREF(im->im_self);
+    module_lock();
     if (numfree < PyMethod_MAXFREELIST) {
         im->im_self = (PyObject *)free_list;
         free_list = im;
         numfree++;
+        module_unlock();
     }
     else {
+        module_unlock();
         PyObject_GC_Del(im);
     }
 }
@@ -392,15 +405,19 @@ PyTypeObject PyMethod_Type = {
 int
 PyMethod_ClearFreeList(void)
 {
-    int freelist_size = numfree;
+    int freelist_size;
 
+    module_lock();
+    freelist_size = numfree;
     while (free_list) {
         PyMethodObject *im = free_list;
         free_list = (PyMethodObject *)(im->im_self);
+        module_unlock();
         PyObject_GC_Del(im);
-        numfree--;
+        module_lock();
     }
     assert(numfree == 0);
+    module_unlock();
     return freelist_size;
 }
 
@@ -414,9 +431,11 @@ PyMethod_Fini(void)
 void
 _PyMethod_DebugMallocStats(FILE *out)
 {
+    module_lock();
     _PyDebugAllocatorStats(out,
                            "free PyMethodObject",
                            numfree, sizeof(PyMethodObject));
+    module_unlock();
 }
 
 /* ------------------------------------------------------------------------
diff --git a/Objects/dictobject.c b/Objects/dictobject.c
index f6a98b4b02..3190b9a5f3 100644
--- a/Objects/dictobject.c
+++ b/Objects/dictobject.c
@@ -213,6 +213,14 @@ static int dictresize(PyDictObject *mp, Py_ssize_t minused);
 #ifndef PyDict_MAXFREELIST
 #define PyDict_MAXFREELIST 80
 #endif
+
+static py_recursivelock_t module_rlock = PY_RECURSIVELOCK_STATIC_INIT("dict module lock");
+#define module_lock() py_recursivelock_lock(&module_rlock)
+#define module_unlock() py_recursivelock_unlock(&module_rlock)
+void dictobject_lock_stats(void) {
+    py_recursivelock_stats(&module_rlock);
+}
+
 static PyDictObject *free_list[PyDict_MAXFREELIST];
 static int numfree = 0;
 
@@ -222,9 +230,17 @@ int
 PyDict_ClearFreeList(void)
 {
     PyDictObject *op;
-    int ret = numfree;
-    while (numfree) {
+    int ret = 0;
+
+    for (;;) {
+        module_lock();
+        if (!numfree) {
+            module_unlock();
+            break;
+        }
+        ret++;
         op = free_list[--numfree];
+        module_unlock();
         assert(PyDict_CheckExact(op));
         PyObject_GC_Del(op);
     }
@@ -235,8 +251,10 @@ PyDict_ClearFreeList(void)
 void
 _PyDict_DebugMallocStats(FILE *out)
 {
+    module_lock();
     _PyDebugAllocatorStats(out,
                            "free PyDictObject", numfree, sizeof(PyDictObject));
+    module_unlock();
 }
 
 
@@ -249,8 +267,8 @@ PyDict_Fini(void)
 #define DK_DEBUG_INCREF _Py_INC_REFTOTAL _Py_REF_DEBUG_COMMA
 #define DK_DEBUG_DECREF _Py_DEC_REFTOTAL _Py_REF_DEBUG_COMMA
 
-#define DK_INCREF(dk) (DK_DEBUG_INCREF ++(dk)->dk_refcnt)
-#define DK_DECREF(dk) if (DK_DEBUG_DECREF (--(dk)->dk_refcnt) == 0) free_keys_object(dk)
+#define DK_INCREF(dk) (DK_DEBUG_INCREF ATOMIC_INC(&((dk)->dk_refcnt)))
+#define DK_DECREF(dk) if (DK_DEBUG_DECREF (ATOMIC_DEC(&((dk)->dk_refcnt)) == 0)) free_keys_object(dk)
 #define DK_SIZE(dk) ((dk)->dk_size)
 #define DK_MASK(dk) (((dk)->dk_size)-1)
 #define IS_POWER_OF_2(x) (((x) & (x-1)) == 0)
@@ -299,6 +317,57 @@ PyDict_Fini(void)
         (d)->ma_keys->dk_lookup = lookdict_unicode; \
     }
 
+
+Py_LOCAL_INLINE(void) dict_lock_new(PyDictObject *d)
+{
+    py_recursivelock_init(&d->ma_lock, "dict()");
+}
+
+Py_LOCAL_INLINE(void) dict_lock_dealloc(PyDictObject *d)
+{
+}
+
+void dict_lock(PyDictObject *d)
+{
+    // printf("%5d: locking %p\n", getpid(), d);
+    py_recursivelock_lock(&(d->ma_lock));
+    // futex_lock(&(d->ob_base.ob_lock.futex));
+    // printf("%5d:  locked %p\n", getpid(), d);
+}
+
+void dict_unlock(PyDictObject *d)
+{
+    // printf("%5d:  unlock %p\n", getpid(), d);
+    py_recursivelock_unlock(&(d->ma_lock));
+    // futex_unlock(&(d->ob_base.ob_lock.futex));
+}
+
+Py_LOCAL_INLINE(void) dict_lock2(PyDictObject *o1, PyDictObject *o2)
+{
+    /*
+    if o1 == o2 we *do* want to lock twice,
+    because they're going to call unlock twice.
+
+    work correctly if either object is null.
+    */
+    if (o1 && (o1 <= o2))
+        dict_lock(o1);
+    if (o2)
+        dict_lock(o2);
+    if (o1 > o2)
+        dict_lock(o1);
+}
+
+Py_LOCAL_INLINE(void) dict_unlock2(PyDictObject *o1, PyDictObject *o2)
+{
+    if (o1)
+        dict_unlock(o1);
+    if (o2)
+        dict_unlock(o2);
+}
+
+
+
 /* This immutable, empty PyDictKeysObject is used for PyDict_Clear()
  * (which cannot fail and thus can do no allocation).
  */
@@ -366,13 +435,16 @@ new_dict(PyDictKeysObject *keys, PyObject **values)
 {
     PyDictObject *mp;
     assert(keys != NULL);
+    module_lock();
     if (numfree) {
         mp = free_list[--numfree];
+        module_unlock();
         assert (mp != NULL);
         assert (Py_TYPE(mp) == &PyDict_Type);
         _Py_NewReference((PyObject *)mp);
     }
     else {
+        module_unlock();
         mp = PyObject_GC_New(PyDictObject, &PyDict_Type);
         if (mp == NULL) {
             DK_DECREF(keys);
@@ -383,6 +455,7 @@ new_dict(PyDictKeysObject *keys, PyObject **values)
     mp->ma_keys = keys;
     mp->ma_values = values;
     mp->ma_used = 0;
+    dict_lock_new(mp);
     return (PyObject *)mp;
 }
 
@@ -685,14 +758,19 @@ _PyDict_HasOnlyStringKeys(PyObject *dict)
 {
     Py_ssize_t pos = 0;
     PyObject *key, *value;
+    int status = 1;
     assert(PyDict_Check(dict));
     /* Shortcut */
     if (((PyDictObject *)dict)->ma_keys->dk_lookup != lookdict)
         return 1;
+    dict_lock((PyDictObject *)dict);
     while (PyDict_Next(dict, &pos, &key, &value))
-        if (!PyUnicode_Check(key))
-            return 0;
-    return 1;
+        if (!PyUnicode_Check(key)) {
+            status = 0;
+            break;
+        }
+    dict_unlock((PyDictObject *)dict);
+    return status;
 }
 
 #define MAINTAIN_TRACKING(mp, key, value) \
@@ -712,19 +790,24 @@ _PyDict_MaybeUntrack(PyObject *op)
     PyObject *value;
     Py_ssize_t i, size;
 
-    if (!PyDict_CheckExact(op) || !_PyObject_GC_IS_TRACKED(op))
+    if (!PyDict_CheckExact(op))
         return;
 
     mp = (PyDictObject *) op;
+    dict_lock(mp);
+    if (!_PyObject_GC_IS_TRACKED(op))
+        goto exit;
     size = DK_SIZE(mp->ma_keys);
     if (_PyDict_HasSplitTable(mp)) {
         for (i = 0; i < size; i++) {
             if ((value = mp->ma_values[i]) == NULL)
                 continue;
             if (_PyObject_GC_MAY_BE_TRACKED(value)) {
-                assert(!_PyObject_GC_MAY_BE_TRACKED(
-                    mp->ma_keys->dk_entries[i].me_key));
-                return;
+                #ifndef NDEBUG
+                PyObject *key = mp->ma_keys->dk_entries[i].me_key;
+                assert(!_PyObject_GC_MAY_BE_TRACKED(key));
+                #endif
+                goto exit;
             }
         }
     }
@@ -735,14 +818,18 @@ _PyDict_MaybeUntrack(PyObject *op)
                 continue;
             if (_PyObject_GC_MAY_BE_TRACKED(value) ||
                 _PyObject_GC_MAY_BE_TRACKED(ep0[i].me_key))
-                return;
+                goto exit;
         }
     }
     _PyObject_GC_UNTRACK(op);
+exit:
+    dict_unlock(mp);
 }
 
 /* Internal function to find slot for an item from its hash
  * when it is known that the key is not present in the dict.
+ *
+ * This function assumes the dict is already locked.
  */
 static PyDictKeyEntry *
 find_empty_slot(PyDictObject *mp, PyObject *key, Py_hash_t hash,
@@ -781,6 +868,8 @@ insertion_resize(PyDictObject *mp)
 Internal routine to insert a new item into the table.
 Used both by the internal resize routine and by the public insert routine.
 Returns -1 if an error occurred, or 0 on success.
+
+This function assumes the dict is already locked.
 */
 static int
 insertdict(PyDictObject *mp, PyObject *key, Py_hash_t hash, PyObject *value)
@@ -1046,6 +1135,7 @@ PyDict_GetItem(PyObject *op, PyObject *key)
     PyDictKeyEntry *ep;
     PyThreadState *tstate;
     PyObject **value_addr;
+    PyObject *value;
 
     if (!PyDict_Check(op))
         return NULL;
@@ -1069,20 +1159,27 @@ PyDict_GetItem(PyObject *op, PyObject *key)
         /* preserve the existing exception */
         PyObject *err_type, *err_value, *err_tb;
         PyErr_Fetch(&err_type, &err_value, &err_tb);
+        dict_lock(mp);
         ep = (mp->ma_keys->dk_lookup)(mp, key, hash, &value_addr);
         /* ignore errors */
         PyErr_Restore(err_type, err_value, err_tb);
-        if (ep == NULL)
+        if (ep == NULL) {
+            dict_unlock(mp);
             return NULL;
+        }
     }
     else {
+        dict_lock(mp);
         ep = (mp->ma_keys->dk_lookup)(mp, key, hash, &value_addr);
         if (ep == NULL) {
+            dict_unlock(mp);
             PyErr_Clear();
             return NULL;
         }
     }
-    return *value_addr;
+    value = *value_addr;
+    dict_unlock(mp);
+    return value;
 }
 
 PyObject *
@@ -1092,6 +1189,7 @@ _PyDict_GetItem_KnownHash(PyObject *op, PyObject *key, Py_hash_t hash)
     PyDictKeyEntry *ep;
     PyThreadState *tstate;
     PyObject **value_addr;
+    PyObject *value;
 
     if (!PyDict_Check(op))
         return NULL;
@@ -1102,6 +1200,7 @@ _PyDict_GetItem_KnownHash(PyObject *op, PyObject *key, Py_hash_t hash)
        _PyThreadState_Current and not PyThreadState_GET() because in debug
        mode, the latter complains if tstate is NULL. */
     tstate = _PyThreadState_UncheckedGet();
+    dict_lock(mp);
     if (tstate != NULL && tstate->curexc_type != NULL) {
         /* preserve the existing exception */
         PyObject *err_type, *err_value, *err_tb;
@@ -1109,17 +1208,22 @@ _PyDict_GetItem_KnownHash(PyObject *op, PyObject *key, Py_hash_t hash)
         ep = (mp->ma_keys->dk_lookup)(mp, key, hash, &value_addr);
         /* ignore errors */
         PyErr_Restore(err_type, err_value, err_tb);
-        if (ep == NULL)
+        if (ep == NULL) {
+            dict_unlock(mp);
             return NULL;
+        }
     }
     else {
         ep = (mp->ma_keys->dk_lookup)(mp, key, hash, &value_addr);
         if (ep == NULL) {
             PyErr_Clear();
+            dict_unlock(mp);
             return NULL;
         }
     }
-    return *value_addr;
+    value = *value_addr;
+    dict_unlock(mp);
+    return value;
 }
 
 /* Variant of PyDict_GetItem() that doesn't suppress exceptions.
@@ -1133,6 +1237,7 @@ PyDict_GetItemWithError(PyObject *op, PyObject *key)
     PyDictObject*mp = (PyDictObject *)op;
     PyDictKeyEntry *ep;
     PyObject **value_addr;
+    PyObject *value;
 
     if (!PyDict_Check(op)) {
         PyErr_BadInternalCall();
@@ -1147,10 +1252,15 @@ PyDict_GetItemWithError(PyObject *op, PyObject *key)
         }
     }
 
+    dict_lock(mp);
     ep = (mp->ma_keys->dk_lookup)(mp, key, hash, &value_addr);
-    if (ep == NULL)
+    if (ep == NULL) {
+        dict_unlock(mp);
         return NULL;
-    return *value_addr;
+    }
+    value = *value_addr;
+    dict_unlock(mp);
+    return value;
 }
 
 PyObject *
@@ -1187,18 +1297,27 @@ _PyDict_LoadGlobal(PyDictObject *globals, PyDictObject *builtins, PyObject *key)
     }
 
     /* namespace 1: globals */
+    dict_lock(globals);
     entry = globals->ma_keys->dk_lookup(globals, key, hash, &value_addr);
-    if (entry == NULL)
+    if (entry == NULL) {
+        dict_unlock(globals);
         return NULL;
+    }
     value = *value_addr;
+    dict_unlock(globals);
     if (value != NULL)
         return value;
 
     /* namespace 2: builtins */
+    dict_lock(builtins);
     entry = builtins->ma_keys->dk_lookup(builtins, key, hash, &value_addr);
-    if (entry == NULL)
+    if (entry == NULL) {
+        dict_unlock(builtins);
         return NULL;
-    return *value_addr;
+    }
+    value = *value_addr;
+    dict_unlock(builtins);
+    return value;
 }
 
 /* CAUTION: PyDict_SetItem() must guarantee that it won't resize the
@@ -1211,6 +1330,7 @@ int
 PyDict_SetItem(PyObject *op, PyObject *key, PyObject *value)
 {
     PyDictObject *mp;
+    int i;
     Py_hash_t hash;
     if (!PyDict_Check(op)) {
         PyErr_BadInternalCall();
@@ -1228,7 +1348,10 @@ PyDict_SetItem(PyObject *op, PyObject *key, PyObject *value)
     }
 
     /* insertdict() handles any resizing that might be necessary */
-    return insertdict(mp, key, hash, value);
+    dict_lock(mp);
+    i = insertdict(mp, key, hash, value);
+    dict_unlock(mp);
+    return i;
 }
 
 int
@@ -1236,6 +1359,7 @@ _PyDict_SetItem_KnownHash(PyObject *op, PyObject *key, PyObject *value,
                          Py_hash_t hash)
 {
     PyDictObject *mp;
+    int i;
 
     if (!PyDict_Check(op)) {
         PyErr_BadInternalCall();
@@ -1247,7 +1371,10 @@ _PyDict_SetItem_KnownHash(PyObject *op, PyObject *key, PyObject *value,
     mp = (PyDictObject *)op;
 
     /* insertdict() handles any resizing that might be necessary */
-    return insertdict(mp, key, hash, value);
+    dict_lock(mp);
+    i = insertdict(mp, key, hash, value);
+    dict_unlock(mp);
+    return i;
 }
 
 int
@@ -1271,12 +1398,13 @@ PyDict_DelItem(PyObject *op, PyObject *key)
             return -1;
     }
     mp = (PyDictObject *)op;
+    dict_lock(mp);
     ep = (mp->ma_keys->dk_lookup)(mp, key, hash, &value_addr);
     if (ep == NULL)
-        return -1;
+        goto fail;
     if (*value_addr == NULL) {
         _PyErr_SetKeyError(key);
-        return -1;
+        goto fail;
     }
     old_value = *value_addr;
     *value_addr = NULL;
@@ -1288,8 +1416,12 @@ PyDict_DelItem(PyObject *op, PyObject *key)
         ep->me_key = dummy;
         Py_DECREF(old_key);
     }
+    dict_unlock(mp);
     Py_DECREF(old_value);
     return 0;
+fail:
+    dict_unlock(mp);
+    return -1;
 }
 
 int
@@ -1307,12 +1439,13 @@ _PyDict_DelItem_KnownHash(PyObject *op, PyObject *key, Py_hash_t hash)
     assert(key);
     assert(hash != -1);
     mp = (PyDictObject *)op;
+    dict_lock(mp);
     ep = (mp->ma_keys->dk_lookup)(mp, key, hash, &value_addr);
     if (ep == NULL)
-        return -1;
+        goto fail;
     if (*value_addr == NULL) {
         _PyErr_SetKeyError(key);
-        return -1;
+        goto fail;
     }
     old_value = *value_addr;
     *value_addr = NULL;
@@ -1324,8 +1457,12 @@ _PyDict_DelItem_KnownHash(PyObject *op, PyObject *key, Py_hash_t hash)
         ep->me_key = dummy;
         Py_DECREF(old_key);
     }
+    dict_unlock(mp);
     Py_DECREF(old_value);
     return 0;
+fail:
+    dict_unlock(mp);
+    return -1;
 }
 
 void
@@ -1339,15 +1476,20 @@ PyDict_Clear(PyObject *op)
     if (!PyDict_Check(op))
         return;
     mp = ((PyDictObject *)op);
+    dict_lock(mp);
     oldkeys = mp->ma_keys;
     oldvalues = mp->ma_values;
-    if (oldvalues == empty_values)
+    if (oldvalues == empty_values) {
+        dict_unlock(mp);
         return;
+    }
     /* Empty the dict... */
     DK_INCREF(Py_EMPTY_KEYS);
     mp->ma_keys = Py_EMPTY_KEYS;
     mp->ma_values = empty_values;
     mp->ma_used = 0;
+    dict_unlock(mp);
+
     /* ...then clear the keys and values */
     if (oldvalues != NULL) {
         n = DK_SIZE(oldkeys);
@@ -1416,14 +1558,18 @@ dict_next(PyObject *op, Py_ssize_t i, PyObject **pvalue)
 int
 PyDict_Next(PyObject *op, Py_ssize_t *ppos, PyObject **pkey, PyObject **pvalue)
 {
-    PyDictObject *mp;
-    Py_ssize_t i = dict_next(op, *ppos, pvalue);
-    if (i < 0)
+    PyDictObject *mp  = (PyDictObject *)op;
+    Py_ssize_t i;
+    dict_lock(mp);
+    i = dict_next(op, *ppos, pvalue);
+    if (i < 0) {
+        dict_unlock(mp);
         return 0;
-    mp = (PyDictObject *)op;
+    }
     *ppos = i+1;
     if (pkey)
         *pkey = mp->ma_keys->dk_entries[i].me_key;
+    dict_unlock(mp);
     return 1;
 }
 
@@ -1434,15 +1580,19 @@ int
 _PyDict_Next(PyObject *op, Py_ssize_t *ppos, PyObject **pkey,
              PyObject **pvalue, Py_hash_t *phash)
 {
-    PyDictObject *mp;
-    Py_ssize_t i = dict_next(op, *ppos, pvalue);
-    if (i < 0)
+    PyDictObject *mp = (PyDictObject *)op;
+    Py_ssize_t i;
+    dict_lock(mp);
+    i = dict_next(op, *ppos, pvalue);
+    if (i < 0) {
+        dict_unlock(mp);
         return 0;
-    mp = (PyDictObject *)op;
+    }
     *ppos = i+1;
     *phash = mp->ma_keys->dk_entries[i].me_hash;
     if (pkey)
         *pkey = mp->ma_keys->dk_entries[i].me_key;
+    dict_unlock(mp);
     return 1;
 }
 
@@ -1455,7 +1605,9 @@ _PyDict_Pop(PyDictObject *mp, PyObject *key, PyObject *deflt)
     PyDictKeyEntry *ep;
     PyObject **value_addr;
 
+    dict_lock(mp);
     if (mp->ma_used == 0) {
+        dict_unlock(mp);
         if (deflt) {
             Py_INCREF(deflt);
             return deflt;
@@ -1466,14 +1618,19 @@ _PyDict_Pop(PyDictObject *mp, PyObject *key, PyObject *deflt)
     if (!PyUnicode_CheckExact(key) ||
         (hash = ((PyASCIIObject *) key)->hash) == -1) {
         hash = PyObject_Hash(key);
-        if (hash == -1)
+        if (hash == -1) {
+            dict_unlock(mp);
             return NULL;
+        }
     }
     ep = (mp->ma_keys->dk_lookup)(mp, key, hash, &value_addr);
-    if (ep == NULL)
+    if (ep == NULL) {
+        dict_unlock(mp);
         return NULL;
+    }
     old_value = *value_addr;
     if (old_value == NULL) {
+        dict_unlock(mp);
         if (deflt) {
             Py_INCREF(deflt);
             return deflt;
@@ -1490,6 +1647,7 @@ _PyDict_Pop(PyDictObject *mp, PyObject *key, PyObject *deflt)
         ep->me_key = dummy;
         Py_DECREF(old_key);
     }
+    dict_unlock(mp);
     return old_value;
 }
 
@@ -1497,7 +1655,7 @@ _PyDict_Pop(PyDictObject *mp, PyObject *key, PyObject *deflt)
 PyObject *
 _PyDict_FromKeys(PyObject *cls, PyObject *iterable, PyObject *value)
 {
-    PyObject *it;       /* iter(iterable) */
+    PyObject *it = NULL;       /* iter(iterable) */
     PyObject *key;
     PyObject *d;
     int status;
@@ -1506,6 +1664,8 @@ _PyDict_FromKeys(PyObject *cls, PyObject *iterable, PyObject *value)
     if (d == NULL)
         return NULL;
 
+    PyObject_Lock2(d, iterable);
+
     if (PyDict_CheckExact(d) && ((PyDictObject *)d)->ma_used == 0) {
         if (PyDict_CheckExact(iterable)) {
             PyDictObject *mp = (PyDictObject *)d;
@@ -1515,16 +1675,15 @@ _PyDict_FromKeys(PyObject *cls, PyObject *iterable, PyObject *value)
             Py_hash_t hash;
 
             if (dictresize(mp, Py_SIZE(iterable))) {
-                Py_DECREF(d);
-                return NULL;
+                goto Fail;
             }
 
             while (_PyDict_Next(iterable, &pos, &key, &oldvalue, &hash)) {
                 if (insertdict(mp, key, hash, value)) {
-                    Py_DECREF(d);
-                    return NULL;
+                    goto Fail;
                 }
             }
+            PyObject_Unlock2(d, iterable);
             return d;
         }
         if (PyAnySet_CheckExact(iterable)) {
@@ -1534,24 +1693,22 @@ _PyDict_FromKeys(PyObject *cls, PyObject *iterable, PyObject *value)
             Py_hash_t hash;
 
             if (dictresize(mp, PySet_GET_SIZE(iterable))) {
-                Py_DECREF(d);
-                return NULL;
+                goto Fail;
             }
 
             while (_PySet_NextEntry(iterable, &pos, &key, &hash)) {
                 if (insertdict(mp, key, hash, value)) {
-                    Py_DECREF(d);
-                    return NULL;
+                    goto Fail;
                 }
             }
+            PyObject_Unlock2(d, iterable);
             return d;
         }
     }
 
     it = PyObject_GetIter(iterable);
     if (it == NULL){
-        Py_DECREF(d);
-        return NULL;
+        goto Fail;
     }
 
     if (PyDict_CheckExact(d)) {
@@ -1573,10 +1730,13 @@ _PyDict_FromKeys(PyObject *cls, PyObject *iterable, PyObject *value)
     if (PyErr_Occurred())
         goto Fail;
     Py_DECREF(it);
+    PyObject_Unlock2(d, iterable);
     return d;
 
 Fail:
-    Py_DECREF(it);
+    if (it)
+        Py_DECREF(it);
+    PyObject_Unlock2(d, iterable);
     Py_DECREF(d);
     return NULL;
 }
@@ -1604,10 +1764,16 @@ dict_dealloc(PyDictObject *mp)
         assert(keys->dk_refcnt == 1);
         DK_DECREF(keys);
     }
-    if (numfree < PyDict_MAXFREELIST && Py_TYPE(mp) == &PyDict_Type)
+    dict_lock_dealloc(mp);
+    module_lock();
+    if (numfree < PyDict_MAXFREELIST && Py_TYPE(mp) == &PyDict_Type) {
         free_list[numfree++] = mp;
-    else
+        module_unlock();
+    }
+    else {
+        module_unlock();
         Py_TYPE(mp)->tp_free((PyObject *)mp);
+    }
     Py_TRASHCAN_SAFE_END(mp)
 }
 
@@ -1625,8 +1791,11 @@ dict_repr(PyDictObject *mp)
         return i > 0 ? PyUnicode_FromString("{...}") : NULL;
     }
 
+    dict_lock(mp);
+
     if (mp->ma_used == 0) {
         Py_ReprLeave((PyObject *)mp);
+        dict_unlock(mp);
         return PyUnicode_FromString("{}");
     }
 
@@ -1683,11 +1852,13 @@ dict_repr(PyDictObject *mp)
     if (_PyUnicodeWriter_WriteChar(&writer, '}') < 0)
         goto error;
 
+    dict_unlock(mp);
     Py_ReprLeave((PyObject *)mp);
 
     return _PyUnicodeWriter_Finish(&writer);
 
 error:
+    dict_unlock(mp);
     Py_ReprLeave((PyObject *)mp);
     _PyUnicodeWriter_Dealloc(&writer);
     Py_XDECREF(key);
@@ -1698,7 +1869,11 @@ error:
 static Py_ssize_t
 dict_length(PyDictObject *mp)
 {
-    return mp->ma_used;
+    Py_ssize_t size;
+    dict_lock(mp);
+    size = mp->ma_used;
+    dict_unlock(mp);
+    return size;
 }
 
 static PyObject *
@@ -1715,9 +1890,12 @@ dict_subscript(PyDictObject *mp, PyObject *key)
         if (hash == -1)
             return NULL;
     }
+    dict_lock(mp);
     ep = (mp->ma_keys->dk_lookup)(mp, key, hash, &value_addr);
-    if (ep == NULL)
+    if (ep == NULL) {
+        dict_unlock(mp);
         return NULL;
+    }
     v = *value_addr;
     if (v == NULL) {
         if (!PyDict_CheckExact(mp)) {
@@ -1725,20 +1903,26 @@ dict_subscript(PyDictObject *mp, PyObject *key)
             PyObject *missing, *res;
             _Py_IDENTIFIER(__missing__);
             missing = _PyObject_LookupSpecial((PyObject *)mp, &PyId___missing__);
+            dict_unlock(mp);
             if (missing != NULL) {
                 res = PyObject_CallFunctionObjArgs(missing,
                                                    key, NULL);
+                dict_unlock(mp);
                 Py_DECREF(missing);
                 return res;
             }
-            else if (PyErr_Occurred())
+            if (PyErr_Occurred()) {
+                dict_unlock(mp);
                 return NULL;
+            }
         }
+        dict_unlock(mp);
         _PyErr_SetKeyError(key);
         return NULL;
     }
-    else
-        Py_INCREF(v);
+
+    dict_unlock(mp);
+    Py_INCREF(v);
     return v;
 }
 
@@ -1766,11 +1950,14 @@ dict_keys(PyDictObject *mp)
     Py_ssize_t size, n, offset;
     PyObject **value_ptr;
 
+    dict_lock(mp);
   again:
     n = mp->ma_used;
     v = PyList_New(n);
-    if (v == NULL)
+    if (v == NULL) {
+        dict_unlock(mp);
         return NULL;
+    }
     if (n != mp->ma_used) {
         /* Durnit.  The allocations caused the dict to resize.
          * Just start over, this shouldn't normally happen.
@@ -1798,6 +1985,7 @@ dict_keys(PyDictObject *mp)
         value_ptr = (PyObject **)(((char *)value_ptr) + offset);
     }
     assert(j == n);
+    dict_unlock(mp);
     return v;
 }
 
@@ -1809,11 +1997,14 @@ dict_values(PyDictObject *mp)
     Py_ssize_t size, n, offset;
     PyObject **value_ptr;
 
+    dict_lock(mp);
   again:
     n = mp->ma_used;
     v = PyList_New(n);
-    if (v == NULL)
+    if (v == NULL) {
+        dict_unlock(mp);
         return NULL;
+    }
     if (n != mp->ma_used) {
         /* Durnit.  The allocations caused the dict to resize.
          * Just start over, this shouldn't normally happen.
@@ -1840,6 +2031,7 @@ dict_values(PyDictObject *mp)
         }
     }
     assert(j == n);
+    dict_unlock(mp);
     return v;
 }
 
@@ -1857,14 +2049,18 @@ dict_items(PyDictObject *mp)
      * the loop over the items, which could trigger GC, which
      * could resize the dict. :-(
      */
+    dict_lock(mp);
   again:
     n = mp->ma_used;
     v = PyList_New(n);
-    if (v == NULL)
+    if (v == NULL) {
+        dict_unlock(mp);
         return NULL;
+    }
     for (i = 0; i < n; i++) {
         item = PyTuple_New(2);
         if (item == NULL) {
+            dict_unlock(mp);
             Py_DECREF(v);
             return NULL;
         }
@@ -1877,7 +2073,7 @@ dict_items(PyDictObject *mp)
         Py_DECREF(v);
         goto again;
     }
-    /* Nothing we do below makes any function calls. */
+    /* Nothing we do below makes any function calls (apart from the unlock) */
     ep = mp->ma_keys->dk_entries;
     size = DK_SIZE(mp->ma_keys);
     if (mp->ma_values) {
@@ -1902,6 +2098,7 @@ dict_items(PyDictObject *mp)
         }
     }
     assert(j == n);
+    dict_unlock(mp);
     return v;
 }
 
@@ -1977,9 +2174,13 @@ PyDict_MergeFromSeq2(PyObject *d, PyObject *seq2, int override)
     assert(PyDict_Check(d));
     assert(seq2 != NULL);
 
+    PyObject_Lock2(d, seq2);
+
     it = PyObject_GetIter(seq2);
-    if (it == NULL)
+    if (it == NULL) {
+        PyObject_Unlock2(d, seq2);
         return -1;
+    }
 
     for (i = 0; ; ++i) {
         PyObject *key, *value;
@@ -2032,6 +2233,7 @@ Fail:
     i = -1;
 Return:
     Py_DECREF(it);
+    PyObject_Unlock2(d, seq2);
     return Py_SAFE_DOWNCAST(i, Py_ssize_t, int);
 }
 
@@ -2057,12 +2259,15 @@ PyDict_Merge(PyObject *a, PyObject *b, int override)
         PyErr_BadInternalCall();
         return -1;
     }
+    PyObject_Lock2(a, b);
     mp = (PyDictObject*)a;
     if (PyDict_Check(b)) {
         other = (PyDictObject*)b;
-        if (other == mp || other->ma_used == 0)
+        if (other == mp || other->ma_used == 0) {
             /* a.update(a) or a.update({}); nothing to do */
+            PyObject_Unlock2(a, b);
             return 0;
+        }
         if (mp->ma_used == 0)
             /* Since the target dict is empty, PyDict_GetItem()
              * always returns NULL.  Setting override to 1
@@ -2074,8 +2279,10 @@ PyDict_Merge(PyObject *a, PyObject *b, int override)
          * that there will be no (or few) overlapping keys.
          */
         if (mp->ma_keys->dk_usable * 3 < other->ma_used * 2)
-            if (dictresize(mp, (mp->ma_used + other->ma_used)*2) != 0)
+            if (dictresize(mp, (mp->ma_used + other->ma_used)*2) != 0) {
+                PyObject_Unlock2(a, b);
                return -1;
+            }
         for (i = 0, n = DK_SIZE(other->ma_keys); i < n; i++) {
             PyObject *key, *value;
             Py_hash_t hash;
@@ -2095,10 +2302,13 @@ PyDict_Merge(PyObject *a, PyObject *b, int override)
                     err = insertdict(mp, key, hash, value);
                 Py_DECREF(value);
                 Py_DECREF(key);
-                if (err != 0)
+                if (err != 0) {
+                    PyObject_Unlock2(a, b);
                     return -1;
+                }
 
                 if (n != DK_SIZE(other->ma_keys)) {
+                    PyObject_Unlock2(a, b);
                     PyErr_SetString(PyExc_RuntimeError,
                                     "dict mutated during update");
                     return -1;
@@ -2113,18 +2323,22 @@ PyDict_Merge(PyObject *a, PyObject *b, int override)
         PyObject *key, *value;
         int status;
 
-        if (keys == NULL)
+        if (keys == NULL) {
             /* Docstring says this is equivalent to E.keys() so
              * if E doesn't have a .keys() method we want
              * AttributeError to percolate up.  Might as well
              * do the same for any other error.
              */
+            PyObject_Unlock2(a, b);
             return -1;
+        }
 
         iter = PyObject_GetIter(keys);
         Py_DECREF(keys);
-        if (iter == NULL)
+        if (iter == NULL) {
+            PyObject_Unlock2(a, b);
             return -1;
+        }
 
         for (key = PyIter_Next(iter); key; key = PyIter_Next(iter)) {
             if (!override && PyDict_GetItem(a, key) != NULL) {
@@ -2135,6 +2349,7 @@ PyDict_Merge(PyObject *a, PyObject *b, int override)
             if (value == NULL) {
                 Py_DECREF(iter);
                 Py_DECREF(key);
+                PyObject_Unlock2(a, b);
                 return -1;
             }
             status = PyDict_SetItem(a, key, value);
@@ -2142,14 +2357,18 @@ PyDict_Merge(PyObject *a, PyObject *b, int override)
             Py_DECREF(value);
             if (status < 0) {
                 Py_DECREF(iter);
+                PyObject_Unlock2(a, b);
                 return -1;
             }
         }
         Py_DECREF(iter);
-        if (PyErr_Occurred())
+        if (PyErr_Occurred()) {
+            PyObject_Unlock2(a, b);
             /* Iterator completed, via error */
             return -1;
+        }
     }
+    PyObject_Unlock2(a, b);
     return 0;
 }
 
@@ -2171,19 +2390,24 @@ PyDict_Copy(PyObject *o)
         return NULL;
     }
     mp = (PyDictObject *)o;
+    dict_lock(mp);
     if (_PyDict_HasSplitTable(mp)) {
         PyDictObject *split_copy;
         PyObject **newvalues = new_values(DK_SIZE(mp->ma_keys));
-        if (newvalues == NULL)
+        if (newvalues == NULL) {
+            dict_unlock(mp);
             return PyErr_NoMemory();
+        }
         split_copy = PyObject_GC_New(PyDictObject, &PyDict_Type);
         if (split_copy == NULL) {
+            dict_unlock(mp);
             free_values(newvalues);
             return NULL;
         }
         split_copy->ma_values = newvalues;
         split_copy->ma_keys = mp->ma_keys;
         split_copy->ma_used = mp->ma_used;
+        dict_lock_new(split_copy);
         DK_INCREF(mp->ma_keys);
         for (i = 0, n = DK_SIZE(mp->ma_keys); i < n; i++) {
             PyObject *value = mp->ma_values[i];
@@ -2192,8 +2416,10 @@ PyDict_Copy(PyObject *o)
         }
         if (_PyObject_GC_IS_TRACKED(mp))
             _PyObject_GC_TRACK(split_copy);
+        dict_unlock(mp);
         return (PyObject *)split_copy;
     }
+    dict_unlock(mp);
     copy = PyDict_New();
     if (copy == NULL)
         return NULL;
@@ -2206,41 +2432,57 @@ PyDict_Copy(PyObject *o)
 Py_ssize_t
 PyDict_Size(PyObject *mp)
 {
+    Py_ssize_t size;
     if (mp == NULL || !PyDict_Check(mp)) {
         PyErr_BadInternalCall();
         return -1;
     }
-    return ((PyDictObject *)mp)->ma_used;
+    dict_lock((PyDictObject *)mp);
+    size = ((PyDictObject *)mp)->ma_used;
+    dict_unlock((PyDictObject *)mp);
+    return size;
 }
 
 PyObject *
 PyDict_Keys(PyObject *mp)
 {
+    PyObject *keys;
     if (mp == NULL || !PyDict_Check(mp)) {
         PyErr_BadInternalCall();
         return NULL;
     }
-    return dict_keys((PyDictObject *)mp);
+    dict_lock((PyDictObject *)mp);
+    keys = dict_keys((PyDictObject *)mp);
+    dict_unlock((PyDictObject *)mp);
+    return keys;
 }
 
 PyObject *
 PyDict_Values(PyObject *mp)
 {
+    PyObject *values;
     if (mp == NULL || !PyDict_Check(mp)) {
         PyErr_BadInternalCall();
         return NULL;
     }
-    return dict_values((PyDictObject *)mp);
+    dict_lock((PyDictObject *)mp);
+    values = dict_values((PyDictObject *)mp);
+    dict_unlock((PyDictObject *)mp);
+    return values;
 }
 
 PyObject *
 PyDict_Items(PyObject *mp)
 {
+    PyObject *items;
     if (mp == NULL || !PyDict_Check(mp)) {
         PyErr_BadInternalCall();
         return NULL;
     }
-    return dict_items((PyDictObject *)mp);
+    dict_lock((PyDictObject *)mp);
+    items = dict_items((PyDictObject *)mp);
+    dict_unlock((PyDictObject *)mp);
+    return items;
 }
 
 /* Return 1 if dicts equal, 0 if not, -1 if error.
@@ -2252,9 +2494,12 @@ dict_equal(PyDictObject *a, PyDictObject *b)
 {
     Py_ssize_t i;
 
-    if (a->ma_used != b->ma_used)
+    dict_lock2(a, b);
+    if (a->ma_used != b->ma_used) {
         /* can't be equal if # of entries differ */
+        dict_unlock2(a, b);
         return 0;
+    }
     /* Same # of entries -- check all of 'em.  Exit early on any diff. */
     for (i = 0; i < DK_SIZE(a->ma_keys); i++) {
         PyDictKeyEntry *ep = &a->ma_keys->dk_entries[i];
@@ -2281,16 +2526,21 @@ dict_equal(PyDictObject *a, PyDictObject *b)
             Py_DECREF(key);
             if (bval == NULL) {
                 Py_DECREF(aval);
+                dict_unlock2(a, b);
                 if (PyErr_Occurred())
                     return -1;
                 return 0;
             }
             cmp = PyObject_RichCompareBool(aval, bval, Py_EQ);
             Py_DECREF(aval);
-            if (cmp <= 0)  /* error or not equal */
+            if (cmp <= 0) {
+                /* error or not equal */
+                dict_unlock2(a, b);
                 return cmp;
+            }
         }
     }
+    dict_unlock2(a, b);
     return 1;
 }
 
@@ -2335,13 +2585,19 @@ dict___contains__(PyDictObject *self, PyObject *key)
     PyDictKeyEntry *ep;
     PyObject **value_addr;
 
+    PyObject_Lock(key);
     if (!PyUnicode_CheckExact(key) ||
         (hash = ((PyASCIIObject *) key)->hash) == -1) {
         hash = PyObject_Hash(key);
-        if (hash == -1)
+        if (hash == -1) {
+            PyObject_Unlock(key);
             return NULL;
+        }
     }
+    PyObject_Unlock(key);
+    dict_lock(mp);
     ep = (mp->ma_keys->dk_lookup)(mp, key, hash, &value_addr);
+    dict_unlock(mp);
     if (ep == NULL)
         return NULL;
     return PyBool_FromLong(*value_addr != NULL);
@@ -2360,13 +2616,19 @@ dict_get(PyDictObject *mp, PyObject *args)
     if (!PyArg_UnpackTuple(args, "get", 1, 2, &key, &failobj))
         return NULL;
 
+    PyObject_Lock(key);
     if (!PyUnicode_CheckExact(key) ||
         (hash = ((PyASCIIObject *) key)->hash) == -1) {
         hash = PyObject_Hash(key);
-        if (hash == -1)
+        if (hash == -1) {
+            PyObject_Unlock(key);
             return NULL;
+        }
     }
+    PyObject_Unlock(key);
+    dict_lock(mp);
     ep = (mp->ma_keys->dk_lookup)(mp, key, hash, &value_addr);
+    dict_unlock(mp);
     if (ep == NULL)
         return NULL;
     val = *value_addr;
@@ -2389,21 +2651,30 @@ PyDict_SetDefault(PyObject *d, PyObject *key, PyObject *defaultobj)
         PyErr_BadInternalCall();
         return NULL;
     }
+    PyObject_Lock(key);
     if (!PyUnicode_CheckExact(key) ||
         (hash = ((PyASCIIObject *) key)->hash) == -1) {
         hash = PyObject_Hash(key);
-        if (hash == -1)
+        if (hash == -1) {
+            PyObject_Unlock(key);
             return NULL;
+        }
     }
+    PyObject_Unlock(key);
+    dict_lock(mp);
     ep = (mp->ma_keys->dk_lookup)(mp, key, hash, &value_addr);
-    if (ep == NULL)
+    if (ep == NULL) {
+        dict_unlock(mp);
         return NULL;
+    }
     val = *value_addr;
     if (val == NULL) {
         if (mp->ma_keys->dk_usable <= 0) {
             /* Need to resize. */
-            if (insertion_resize(mp) < 0)
+            if (insertion_resize(mp) < 0) {
+                dict_unlock(mp);
                 return NULL;
+            }
             ep = find_empty_slot(mp, key, hash, &value_addr);
         }
         Py_INCREF(defaultobj);
@@ -2416,6 +2687,7 @@ PyDict_SetDefault(PyObject *d, PyObject *key, PyObject *defaultobj)
         mp->ma_keys->dk_usable--;
         mp->ma_used++;
     }
+    dict_unlock(mp);
     return val;
 }
 
@@ -2471,7 +2743,9 @@ dict_popitem(PyDictObject *mp)
     res = PyTuple_New(2);
     if (res == NULL)
         return NULL;
+    dict_lock(mp);
     if (mp->ma_used == 0) {
+        dict_unlock(mp);
         Py_DECREF(res);
         PyErr_SetString(PyExc_KeyError,
                         "popitem(): dictionary is empty");
@@ -2480,6 +2754,7 @@ dict_popitem(PyDictObject *mp)
     /* Convert split table to combined table */
     if (mp->ma_keys->dk_lookup == lookdict_split) {
         if (dictresize(mp, DK_SIZE(mp->ma_keys))) {
+            dict_unlock(mp);
             Py_DECREF(res);
             return NULL;
         }
@@ -2516,6 +2791,7 @@ dict_popitem(PyDictObject *mp)
     mp->ma_used--;
     assert(mp->ma_keys->dk_entries[0].me_value == NULL);
     mp->ma_keys->dk_entries[0].me_hash = i + 1;  /* next place to start */
+    dict_unlock(mp);
     return res;
 }
 
@@ -2524,6 +2800,7 @@ dict_traverse(PyObject *op, visitproc visit, void *arg)
 {
     Py_ssize_t i, n;
     PyDictObject *mp = (PyDictObject *)op;
+    dict_lock(mp);
     if (mp->ma_keys->dk_lookup == lookdict) {
         for (i = 0; i < DK_SIZE(mp->ma_keys); i++) {
             if (mp->ma_keys->dk_entries[i].me_value != NULL) {
@@ -2543,6 +2820,7 @@ dict_traverse(PyObject *op, visitproc visit, void *arg)
             }
         }
     }
+    dict_unlock(mp);
     return 0;
 }
 
@@ -2560,6 +2838,7 @@ _PyDict_SizeOf(PyDictObject *mp)
 {
     Py_ssize_t size, res;
 
+    dict_lock(mp);
     size = DK_SIZE(mp->ma_keys);
     res = _PyObject_SIZE(Py_TYPE(mp));
     if (mp->ma_values)
@@ -2568,13 +2847,16 @@ _PyDict_SizeOf(PyDictObject *mp)
        in the type object. */
     if (mp->ma_keys->dk_refcnt == 1)
         res += sizeof(PyDictKeysObject) + (size-1) * sizeof(PyDictKeyEntry);
+    dict_unlock(mp);
     return res;
 }
 
 Py_ssize_t
 _PyDict_KeysSize(PyDictKeysObject *keys)
 {
-    return sizeof(PyDictKeysObject) + (DK_SIZE(keys)-1) * sizeof(PyDictKeyEntry);
+    Py_ssize_t size;
+    size = sizeof(PyDictKeysObject) + (DK_SIZE(keys)-1) * sizeof(PyDictKeyEntry);
+    return size;
 }
 
 static PyObject *
@@ -2665,13 +2947,19 @@ PyDict_Contains(PyObject *op, PyObject *key)
     PyDictKeyEntry *ep;
     PyObject **value_addr;
 
+    PyObject_Lock(key);
     if (!PyUnicode_CheckExact(key) ||
         (hash = ((PyASCIIObject *) key)->hash) == -1) {
         hash = PyObject_Hash(key);
-        if (hash == -1)
+        if (hash == -1) {
+            PyObject_Unlock(key);
             return -1;
+        }
     }
+    PyObject_Unlock(key);
+    dict_lock(mp);
     ep = (mp->ma_keys->dk_lookup)(mp, key, hash, &value_addr);
+    dict_unlock(mp);
     return (ep == NULL) ? -1 : (*value_addr != NULL);
 }
 
@@ -2683,7 +2971,9 @@ _PyDict_Contains(PyObject *op, PyObject *key, Py_hash_t hash)
     PyDictKeyEntry *ep;
     PyObject **value_addr;
 
+    dict_lock(mp);
     ep = (mp->ma_keys->dk_lookup)(mp, key, hash, &value_addr);
+    dict_unlock(mp);
     return (ep == NULL) ? -1 : (*value_addr != NULL);
 }
 
@@ -2718,6 +3008,7 @@ dict_new(PyTypeObject *type, PyObject *args, PyObject *kwds)
         _PyObject_GC_UNTRACK(d);
 
     d->ma_used = 0;
+    dict_lock_new(d);
     d->ma_keys = new_keys_object(PyDict_MINSIZE_COMBINED);
     if (d->ma_keys == NULL) {
         Py_DECREF(self);
@@ -2790,6 +3081,22 @@ PyTypeObject PyDict_Type = {
     PyType_GenericAlloc,                        /* tp_alloc */
     dict_new,                                   /* tp_new */
     PyObject_GC_Del,                            /* tp_free */
+
+    0, /* tp_is_gc */
+    0, /* tp_bases */
+    0, /* tp_mro */
+    0, /* tp_cache */
+    0, /* tp_subclasses */
+    0, /* tp_weaklist */
+    0, /* tp_del */
+
+    0, /* tp_version_tag */
+
+    0, /* tp_finalize */
+
+    (lockfunc)dict_lock, /* tp_rlock */
+    (lockfunc)dict_unlock, /* tp_runlock */
+
 };
 
 PyObject *
@@ -3145,7 +3452,7 @@ static PyObject *dictiter_iternextitem(dictiterobject *di)
     if (i > mask)
         goto fail;
 
-    if (result->ob_refcnt == 1) {
+    if (Py_REFCNT(result) == 1) {
         Py_INCREF(result);
         Py_DECREF(PyTuple_GET_ITEM(result, 0));
         Py_DECREF(PyTuple_GET_ITEM(result, 1));
@@ -3935,6 +4242,6 @@ static PyTypeObject PyDictDummy_Type = {
 
 static PyObject _dummy_struct = {
   _PyObject_EXTRA_INIT
-  2, &PyDictDummy_Type
+  _PyObject_REFCNT_INIT(2), &PyDictDummy_Type
 };
 
diff --git a/Objects/enumobject.c b/Objects/enumobject.c
index c458cfe73d..3fb1b9a312 100644
--- a/Objects/enumobject.c
+++ b/Objects/enumobject.c
@@ -102,7 +102,7 @@ enum_next_long(enumobject *en, PyObject* next_item)
         return NULL;
     en->en_longindex = stepped_up;
 
-    if (result->ob_refcnt == 1) {
+    if (Py_REFCNT(result) == 1) {
         Py_INCREF(result);
         Py_DECREF(PyTuple_GET_ITEM(result, 0));
         Py_DECREF(PyTuple_GET_ITEM(result, 1));
@@ -141,7 +141,7 @@ enum_next(enumobject *en)
     }
     en->en_index++;
 
-    if (result->ob_refcnt == 1) {
+    if (Py_REFCNT(result) == 1) {
         Py_INCREF(result);
         Py_DECREF(PyTuple_GET_ITEM(result, 0));
         Py_DECREF(PyTuple_GET_ITEM(result, 1));
diff --git a/Objects/exceptions.c b/Objects/exceptions.c
index 7374368164..3214086b21 100644
--- a/Objects/exceptions.c
+++ b/Objects/exceptions.c
@@ -10,6 +10,14 @@
 #include "osdefs.h"
 
 
+static py_recursivelock_t module_rlock = PY_RECURSIVELOCK_STATIC_INIT("exceptions module lock");
+#define module_lock() py_recursivelock_lock(&module_rlock)
+#define module_unlock() py_recursivelock_unlock(&module_rlock)
+void exceptions_lock_stats(void) {
+    py_recursivelock_stats(&module_rlock);
+}
+
+
 /* Compatibility aliases */
 PyObject *PyExc_EnvironmentError = NULL;
 PyObject *PyExc_IOError = NULL;
@@ -2213,8 +2221,10 @@ MemoryError_new(PyTypeObject *type, PyObject *args, PyObject *kwds)
     /* This shouldn't happen since the empty tuple is persistent */
     if (self->args == NULL)
         return NULL;
+    module_lock();
     memerrors_freelist = (PyBaseExceptionObject *) self->dict;
     memerrors_numfree--;
+    module_unlock();
     self->dict = NULL;
     _Py_NewReference((PyObject *)self);
     _PyObject_GC_TRACK(self);
@@ -2226,12 +2236,15 @@ MemoryError_dealloc(PyBaseExceptionObject *self)
 {
     _PyObject_GC_UNTRACK(self);
     BaseException_clear(self);
-    if (memerrors_numfree >= MEMERRORS_SAVE)
+    module_lock();
+    if (memerrors_numfree >= MEMERRORS_SAVE) {
+        module_unlock();
         Py_TYPE(self)->tp_free((PyObject *)self);
-    else {
+    } else {
         self->dict = (PyObject *) memerrors_freelist;
         memerrors_freelist = self;
         memerrors_numfree++;
+        module_unlock();
     }
 }
 
@@ -2256,11 +2269,23 @@ preallocate_memerrors(void)
 static void
 free_preallocated_memerrors(void)
 {
-    while (memerrors_freelist != NULL) {
-        PyObject *self = (PyObject *) memerrors_freelist;
-        memerrors_freelist = (PyBaseExceptionObject *) memerrors_freelist->dict;
-        Py_TYPE(self)->tp_free((PyObject *)self);
+    PyBaseExceptionObject *head;
+    int numfree;
+
+    module_lock();
+    head = memerrors_freelist;
+    numfree = memerrors_numfree;
+    memerrors_numfree = 0;
+    memerrors_freelist = NULL;
+    module_unlock();
+
+    while (head) {
+        PyObject *self = (PyObject *)head;
+        head = (PyBaseExceptionObject *)head->dict;
+        Py_TYPE(self)->tp_free(self);
+        numfree--;
     }
+    assert(numfree == 0);
 }
 
 
diff --git a/Objects/fileobject.c b/Objects/fileobject.c
index 234d07e5c6..3623f04085 100644
--- a/Objects/fileobject.c
+++ b/Objects/fileobject.c
@@ -94,7 +94,7 @@ PyFile_GetLine(PyObject *f, int n)
                             "EOF when reading a line");
         }
         else if (s[len-1] == '\n') {
-            if (result->ob_refcnt == 1)
+            if (Py_REFCNT(result) == 1)
                 _PyBytes_Resize(&result, len-1);
             else {
                 PyObject *v;
diff --git a/Objects/floatobject.c b/Objects/floatobject.c
index eb60659615..cc4a3747b8 100644
--- a/Objects/floatobject.c
+++ b/Objects/floatobject.c
@@ -10,6 +10,13 @@
 #include <float.h>
 
 
+static py_recursivelock_t module_rlock = PY_RECURSIVELOCK_STATIC_INIT("floatobject module lock");
+#define module_lock() py_recursivelock_lock(&module_rlock)
+#define module_unlock() py_recursivelock_unlock(&module_rlock)
+void floatobject_lock_stats(void) {
+    py_recursivelock_stats(&module_rlock);
+}
+
 /* Special free list
    free_list is a singly-linked list of available PyFloatObjects, linked
    via abuse of their ob_type members.
@@ -109,11 +116,15 @@ PyFloat_GetInfo(void)
 PyObject *
 PyFloat_FromDouble(double fval)
 {
-    PyFloatObject *op = free_list;
+    PyFloatObject *op;
+    module_lock();
+    op = free_list;
     if (op != NULL) {
         free_list = (PyFloatObject *) Py_TYPE(op);
         numfree--;
+        module_unlock();
     } else {
+        module_unlock();
         op = (PyFloatObject*) PyObject_MALLOC(sizeof(PyFloatObject));
         if (!op)
             return PyErr_NoMemory();
@@ -198,17 +209,22 @@ PyFloat_FromString(PyObject *v)
 static void
 float_dealloc(PyFloatObject *op)
 {
+    module_lock();
     if (PyFloat_CheckExact(op)) {
         if (numfree >= PyFloat_MAXFREELIST)  {
+            module_unlock();
             PyObject_FREE(op);
             return;
         }
         numfree++;
         Py_TYPE(op) = (struct _typeobject *)free_list;
         free_list = op;
+        module_unlock();
     }
-    else
+    else {
+        module_unlock();
         Py_TYPE(op)->tp_free((PyObject *)op);
+    }
 }
 
 double
@@ -1933,16 +1949,25 @@ _PyFloat_Init(void)
 int
 PyFloat_ClearFreeList(void)
 {
-    PyFloatObject *f = free_list, *next;
-    int i = numfree;
-    while (f) {
-        next = (PyFloatObject*) Py_TYPE(f);
-        PyObject_FREE(f);
-        f = next;
-    }
+    PyFloatObject *head;
+    int count, i;
+
+    module_lock();
+    head = free_list;
+    count = numfree;
     free_list = NULL;
     numfree = 0;
-    return i;
+    module_unlock();
+
+    i = 0;
+    while (head) {
+        PyObject *self = (PyObject *)head;
+        head = (PyFloatObject *)Py_TYPE(head);
+        PyObject_FREE(self);
+        i++;
+    }
+    assert(i == count);
+    return count;
 }
 
 void
@@ -1955,9 +1980,11 @@ PyFloat_Fini(void)
 void
 _PyFloat_DebugMallocStats(FILE *out)
 {
+    module_lock();
     _PyDebugAllocatorStats(out,
                            "free PyFloatObject",
                            numfree, sizeof(PyFloatObject));
+    module_unlock();
 }
 
 
diff --git a/Objects/frameobject.c b/Objects/frameobject.c
index da2d2ed215..dbef3d9587 100644
--- a/Objects/frameobject.c
+++ b/Objects/frameobject.c
@@ -408,12 +408,12 @@ static PyGetSetDef frame_getsetlist[] = {
    Later, PyFrame_MAXFREELIST was added to bound the # of frames saved on
    free_list.  Else programs creating lots of cyclic trash involving
    frames could provoke free_list into growing without bound.
+
+   Later still, the frame freelist was moved to the PyThreadState
+   object for each thread, because contention for the module lock
+   was quite costly.
 */
 
-static PyFrameObject *free_list = NULL;
-static int numfree = 0;         /* number of frames currently in free_list */
-/* max value for numfree */
-#define PyFrame_MAXFREELIST 200
 
 static void
 frame_dealloc(PyFrameObject *f)
@@ -444,16 +444,19 @@ frame_dealloc(PyFrameObject *f)
     Py_CLEAR(f->f_exc_traceback);
 
     co = f->f_code;
-    if (co->co_zombieframe == NULL)
+    /*
+    TODO HACK
+    DISABLED FOR NOW
+    this causes "GC object already tracked" problems
+    must be a race condition
+    I can live without the optimization for now
+    if (co->co_zombieframe == NULL) {
+        Py_ssize_t refs = _PyGCHead_REFS(_Py_AS_GC(f));
         co->co_zombieframe = f;
-    else if (numfree < PyFrame_MAXFREELIST) {
-        ++numfree;
-        f->f_back = free_list;
-        free_list = f;
     }
     else
-        PyObject_GC_Del(f);
-
+    */
+    PyThreadState_FrameFreeListFree(PyThreadState_GET(), f);
     Py_DECREF(co);
     Py_TRASHCAN_SAFE_END(f)
 }
@@ -667,19 +670,16 @@ PyFrame_New(PyThreadState *tstate, PyCodeObject *code, PyObject *globals,
         nfrees = PyTuple_GET_SIZE(code->co_freevars);
         extras = code->co_stacksize + code->co_nlocals + ncells +
             nfrees;
-        if (free_list == NULL) {
+        f = PyThreadState_FrameFreeListAlloc(tstate);
+        if (f == NULL) {
             f = PyObject_GC_NewVar(PyFrameObject, &PyFrame_Type,
-            extras);
+                extras);
             if (f == NULL) {
                 Py_DECREF(builtins);
                 return NULL;
             }
         }
         else {
-            assert(numfree > 0);
-            --numfree;
-            f = free_list;
-            free_list = free_list->f_back;
             if (Py_SIZE(f) < extras) {
                 PyFrameObject *new_f = PyObject_GC_Resize(PyFrameObject, f, extras);
                 if (new_f == NULL) {
@@ -705,6 +705,7 @@ PyFrame_New(PyThreadState *tstate, PyCodeObject *code, PyObject *globals,
     f->f_builtins = builtins;
     Py_XINCREF(back);
     f->f_back = back;
+    f->f_tstate = tstate;
     Py_INCREF(code);
     Py_INCREF(globals);
     f->f_globals = globals;
@@ -976,16 +977,17 @@ PyFrame_LocalsToFast(PyFrameObject *f, int clear)
 int
 PyFrame_ClearFreeList(void)
 {
-    int freelist_size = numfree;
-
-    while (free_list != NULL) {
-        PyFrameObject *f = free_list;
-        free_list = free_list->f_back;
-        PyObject_GC_Del(f);
-        --numfree;
-    }
-    assert(numfree == 0);
-    return freelist_size;
+    // TODO this should walk all tstates
+    // and free their frameobject freelists
+    //
+    // there's no locks on the tstate freelists,
+    // but if you use CAS to grab the head pointer
+    // and replace it with NULL you'll be fine.
+    //
+    // if a thread is shutting down, would you be
+    // in a race with it?  hmm, maybe.  maybe we
+    // need a lock around tstate creation/destruction.
+    return 0;
 }
 
 void
@@ -998,8 +1000,9 @@ PyFrame_Fini(void)
 void
 _PyFrame_DebugMallocStats(FILE *out)
 {
+    // TODO fix this for the new world order of per-tstate framelists
     _PyDebugAllocatorStats(out,
                            "free PyFrameObject",
-                           numfree, sizeof(PyFrameObject));
+                           0, sizeof(PyFrameObject));
 }
 
diff --git a/Objects/listobject.c b/Objects/listobject.c
index fcc21cbebe..aba8a569ee 100644
--- a/Objects/listobject.c
+++ b/Objects/listobject.c
@@ -9,6 +9,56 @@
 #include <sys/types.h>          /* For size_t */
 #endif
 
+
+Py_LOCAL_INLINE(void) list_lock_new(PyListObject *self)
+{
+    py_recursivelock_init(&self->lock, "list()");
+}
+
+Py_LOCAL_INLINE(void) list_lock_dealloc(PyListObject *self)
+{
+}
+
+void list_lock(PyListObject *self)
+{
+    // printf("%5d: locking %p\n", getpid(), d);
+    py_recursivelock_lock(&(self->lock));
+    // futex_lock(&(d->ob_base.ob_lock.futex));
+    // printf("%5d:  locked %p\n", getpid(), d);
+}
+
+void list_unlock(PyListObject *self)
+{
+    // printf("%5d:  unlock %p\n", getpid(), d);
+    py_recursivelock_unlock(&(self->lock));
+    // futex_unlock(&(d->ob_base.ob_lock.futex));
+}
+
+Py_LOCAL_INLINE(void) list_lock2(PyListObject *o1, PyListObject *o2)
+{
+    /*
+    if o1 == o2 we *do* want to lock twice,
+    because they're going to call unlock twice.
+
+    work correctly if either object is null.
+    */
+    if (o1 && (o1 <= o2))
+        list_lock(o1);
+    if (o2)
+        list_lock(o2);
+    if (o1 > o2)
+        list_lock(o1);
+}
+
+Py_LOCAL_INLINE(void) list_unlock2(PyListObject *o1, PyListObject *o2)
+{
+    if (o1)
+        list_unlock(o1);
+    if (o2)
+        list_unlock(o2);
+}
+
+
 /* Ensure ob_item has room for at least newsize elements, and set
  * ob_size to newsize.  If newsize > ob_size on entry, the content
  * of the new slots at exit is undefined heap trash; it's the caller's
@@ -73,6 +123,14 @@ list_resize(PyListObject *self, Py_ssize_t newsize)
     return 0;
 }
 
+static py_recursivelock_t module_rlock = PY_RECURSIVELOCK_STATIC_INIT("listobject module lock");
+#define module_lock() py_recursivelock_lock(&module_rlock)
+#define module_unlock() py_recursivelock_unlock(&module_rlock)
+void listobject_lock_stats(void) {
+    py_recursivelock_stats(&module_rlock);
+}
+
+
 /* Debug statistic to compare allocations with reuse through the free list */
 #undef SHOW_ALLOC_COUNT
 #ifdef SHOW_ALLOC_COUNT
@@ -82,12 +140,14 @@ static size_t count_reuse = 0;
 static void
 show_alloc(void)
 {
+    module_lock();
     fprintf(stderr, "List allocations: %" PY_FORMAT_SIZE_T "d\n",
         count_alloc);
     fprintf(stderr, "List reuse through freelist: %" PY_FORMAT_SIZE_T
         "d\n", count_reuse);
     fprintf(stderr, "%.2f%% reuse rate\n\n",
         (100.0*count_reuse/(count_alloc+count_reuse)));
+    module_unlock();
 }
 #endif
 
@@ -102,9 +162,16 @@ int
 PyList_ClearFreeList(void)
 {
     PyListObject *op;
-    int ret = numfree;
-    while (numfree) {
+    int ret = 0;
+    for (;;) {
+        module_lock();
+        if (!numfree) {
+            module_unlock();
+            break;
+        }
+        ret++;
         op = free_list[--numfree];
+        module_unlock();
         assert(PyList_CheckExact(op));
         PyObject_GC_Del(op);
     }
@@ -121,9 +188,11 @@ PyList_Fini(void)
 void
 _PyList_DebugMallocStats(FILE *out)
 {
+    module_lock();
     _PyDebugAllocatorStats(out,
                            "free PyListObject",
                            numfree, sizeof(PyListObject));
+    module_unlock();
 }
 
 PyObject *
@@ -148,19 +217,26 @@ PyList_New(Py_ssize_t size)
     if ((size_t)size > PY_SIZE_MAX / sizeof(PyObject *))
         return PyErr_NoMemory();
     nbytes = size * sizeof(PyObject *);
+    module_lock();
     if (numfree) {
         numfree--;
         op = free_list[numfree];
+        module_unlock();
         _Py_NewReference((PyObject *)op);
 #ifdef SHOW_ALLOC_COUNT
+        module_lock();
         count_reuse++;
+        module_unlock();
 #endif
     } else {
+        module_unlock();
         op = PyObject_GC_New(PyListObject, &PyList_Type);
         if (op == NULL)
             return NULL;
 #ifdef SHOW_ALLOC_COUNT
+        module_lock();
         count_alloc++;
+        module_unlock();
 #endif
     }
     if (size <= 0)
@@ -175,6 +251,7 @@ PyList_New(Py_ssize_t size)
     }
     Py_SIZE(op) = size;
     op->allocated = size;
+    list_lock_new(op);
     _PyObject_GC_TRACK(op);
     return (PyObject *) op;
 }
@@ -182,12 +259,15 @@ PyList_New(Py_ssize_t size)
 Py_ssize_t
 PyList_Size(PyObject *op)
 {
+    Py_ssize_t size;
     if (!PyList_Check(op)) {
         PyErr_BadInternalCall();
         return -1;
     }
-    else
-        return Py_SIZE(op);
+    list_lock((PyListObject *)op);
+    size = Py_SIZE(op);
+    list_unlock((PyListObject *)op);
+    return size;
 }
 
 static PyObject *indexerr = NULL;
@@ -195,11 +275,14 @@ static PyObject *indexerr = NULL;
 PyObject *
 PyList_GetItem(PyObject *op, Py_ssize_t i)
 {
+    PyObject *item;
     if (!PyList_Check(op)) {
         PyErr_BadInternalCall();
         return NULL;
     }
+    list_lock((PyListObject *)op);
     if (i < 0 || i >= Py_SIZE(op)) {
+        list_unlock((PyListObject *)op);
         if (indexerr == NULL) {
             indexerr = PyUnicode_FromString(
                 "list index out of range");
@@ -209,7 +292,9 @@ PyList_GetItem(PyObject *op, Py_ssize_t i)
         PyErr_SetObject(PyExc_IndexError, indexerr);
         return NULL;
     }
-    return ((PyListObject *)op) -> ob_item[i];
+    item = ((PyListObject *)op) -> ob_item[i];
+    list_unlock((PyListObject *)op);
+    return item;
 }
 
 int
@@ -222,7 +307,9 @@ PyList_SetItem(PyObject *op, Py_ssize_t i,
         PyErr_BadInternalCall();
         return -1;
     }
+    list_lock((PyListObject *)op);
     if (i < 0 || i >= Py_SIZE(op)) {
+        list_unlock((PyListObject *)op);
         Py_XDECREF(newitem);
         PyErr_SetString(PyExc_IndexError,
                         "list assignment index out of range");
@@ -230,26 +317,32 @@ PyList_SetItem(PyObject *op, Py_ssize_t i,
     }
     p = ((PyListObject *)op) -> ob_item + i;
     Py_SETREF(*p, newitem);
+    list_unlock((PyListObject *)op);
     return 0;
 }
 
 static int
 ins1(PyListObject *self, Py_ssize_t where, PyObject *v)
 {
-    Py_ssize_t i, n = Py_SIZE(self);
+    Py_ssize_t i, n;
     PyObject **items;
     if (v == NULL) {
         PyErr_BadInternalCall();
         return -1;
     }
+    list_lock(self);
+    n = Py_SIZE(self);
     if (n == PY_SSIZE_T_MAX) {
+        list_unlock(self);
         PyErr_SetString(PyExc_OverflowError,
             "cannot add more objects to list");
         return -1;
     }
 
-    if (list_resize(self, n+1) == -1)
+    if (list_resize(self, n+1) == -1) {
+        list_unlock(self);
         return -1;
+    }
 
     if (where < 0) {
         where += n;
@@ -263,6 +356,7 @@ ins1(PyListObject *self, Py_ssize_t where, PyObject *v)
         items[i+1] = items[i];
     Py_INCREF(v);
     items[where] = v;
+    list_unlock(self);
     return 0;
 }
 
@@ -279,20 +373,26 @@ PyList_Insert(PyObject *op, Py_ssize_t where, PyObject *newitem)
 static int
 app1(PyListObject *self, PyObject *v)
 {
-    Py_ssize_t n = PyList_GET_SIZE(self);
+    Py_ssize_t n;
 
     assert (v != NULL);
+    list_lock(self);
+    n = PyList_GET_SIZE(self);
     if (n == PY_SSIZE_T_MAX) {
+        list_unlock(self);
         PyErr_SetString(PyExc_OverflowError,
             "cannot add more objects to list");
         return -1;
     }
 
-    if (list_resize(self, n+1) == -1)
+    if (list_resize(self, n+1) == -1) {
+        list_unlock(self);
         return -1;
+    }
 
     Py_INCREF(v);
     PyList_SET_ITEM(self, n, v);
+    list_unlock(self);
     return 0;
 }
 
@@ -307,9 +407,22 @@ PyList_Append(PyObject *op, PyObject *newitem)
 
 /* Methods */
 
+static PyObject* list_new(PyTypeObject *type, PyObject *args, PyObject *kwds)
+{
+    PyListObject *list;
+
+    list = (PyListObject*)PyType_GenericNew(type, args, kwds);
+    if (list == NULL)
+        return NULL;
+
+    py_nativelock_init(&list->lock.lock.nativelock);
+    return (PyObject*) list;
+}
+
 static void
 list_dealloc(PyListObject *op)
 {
+    /* note: locking not needed in dealloc! */
     Py_ssize_t i;
     PyObject_GC_UnTrack(op);
     Py_TRASHCAN_SAFE_BEGIN(op)
@@ -324,10 +437,15 @@ list_dealloc(PyListObject *op)
         }
         PyMem_FREE(op->ob_item);
     }
-    if (numfree < PyList_MAXFREELIST && PyList_CheckExact(op))
+    module_lock();
+    if (numfree < PyList_MAXFREELIST && PyList_CheckExact(op)) {
         free_list[numfree++] = op;
-    else
+        module_unlock();
+    }
+    else {
+        module_unlock();
         Py_TYPE(op)->tp_free((PyObject *)op);
+    }
     Py_TRASHCAN_SAFE_END(op)
 }
 
@@ -338,12 +456,15 @@ list_repr(PyListObject *v)
     PyObject *s;
     _PyUnicodeWriter writer;
 
+    list_lock(v);
     if (Py_SIZE(v) == 0) {
+        list_unlock(v);
         return PyUnicode_FromString("[]");
     }
 
     i = Py_ReprEnter((PyObject*)v);
     if (i != 0) {
+        list_unlock(v);
         return i > 0 ? PyUnicode_FromString("[...]") : NULL;
     }
 
@@ -382,18 +503,24 @@ list_repr(PyListObject *v)
         goto error;
 
     Py_ReprLeave((PyObject *)v);
+    list_unlock(v);
     return _PyUnicodeWriter_Finish(&writer);
 
 error:
     _PyUnicodeWriter_Dealloc(&writer);
     Py_ReprLeave((PyObject *)v);
+    list_unlock(v);
     return NULL;
 }
 
 static Py_ssize_t
 list_length(PyListObject *a)
 {
-    return Py_SIZE(a);
+    Py_ssize_t size;
+    list_lock(a);
+    size = Py_SIZE(a);
+    list_unlock(a);
+    return size;
 }
 
 static int
@@ -402,16 +529,21 @@ list_contains(PyListObject *a, PyObject *el)
     Py_ssize_t i;
     int cmp;
 
+    list_lock(a);
     for (i = 0, cmp = 0 ; cmp == 0 && i < Py_SIZE(a); ++i)
         cmp = PyObject_RichCompareBool(el, PyList_GET_ITEM(a, i),
                                            Py_EQ);
+    list_unlock(a);
     return cmp;
 }
 
 static PyObject *
 list_item(PyListObject *a, Py_ssize_t i)
 {
+    PyObject *o;
+    list_lock(a);
     if (i < 0 || i >= Py_SIZE(a)) {
+        list_unlock(a);
         if (indexerr == NULL) {
             indexerr = PyUnicode_FromString(
                 "list index out of range");
@@ -421,8 +553,10 @@ list_item(PyListObject *a, Py_ssize_t i)
         PyErr_SetObject(PyExc_IndexError, indexerr);
         return NULL;
     }
-    Py_INCREF(a->ob_item[i]);
-    return a->ob_item[i];
+    o = a->ob_item[i];
+    Py_INCREF(o);
+    list_unlock(a);
+    return o;
 }
 
 static PyObject *
@@ -431,6 +565,7 @@ list_slice(PyListObject *a, Py_ssize_t ilow, Py_ssize_t ihigh)
     PyListObject *np;
     PyObject **src, **dest;
     Py_ssize_t i, len;
+    list_lock(a);
     if (ilow < 0)
         ilow = 0;
     else if (ilow > Py_SIZE(a))
@@ -441,8 +576,10 @@ list_slice(PyListObject *a, Py_ssize_t ilow, Py_ssize_t ihigh)
         ihigh = Py_SIZE(a);
     len = ihigh - ilow;
     np = (PyListObject *) PyList_New(len);
-    if (np == NULL)
+    if (np == NULL) {
+        list_unlock(a);
         return NULL;
+    }
 
     src = a->ob_item + ilow;
     dest = np->ob_item;
@@ -451,6 +588,7 @@ list_slice(PyListObject *a, Py_ssize_t ilow, Py_ssize_t ihigh)
         Py_INCREF(v);
         dest[i] = v;
     }
+    list_unlock(a);
     return (PyObject *)np;
 }
 
@@ -478,11 +616,15 @@ list_concat(PyListObject *a, PyObject *bb)
         return NULL;
     }
 #define b ((PyListObject *)bb)
+    list_lock2(a, b);
     size = Py_SIZE(a) + Py_SIZE(b);
-    if (size < 0)
+    if (size < 0) {
+        list_unlock2(a, b);
         return PyErr_NoMemory();
+    }
     np = (PyListObject *) PyList_New(size);
     if (np == NULL) {
+        list_unlock2(a, b);
         return NULL;
     }
     src = a->ob_item;
@@ -499,6 +641,7 @@ list_concat(PyListObject *a, PyObject *bb)
         Py_INCREF(v);
         dest[i] = v;
     }
+    list_unlock2(a, b);
     return (PyObject *)np;
 #undef b
 }
@@ -511,16 +654,23 @@ list_repeat(PyListObject *a, Py_ssize_t n)
     PyListObject *np;
     PyObject **p, **items;
     PyObject *elem;
+    list_lock(a);
     if (n < 0)
         n = 0;
-    if (n > 0 && Py_SIZE(a) > PY_SSIZE_T_MAX / n)
+    if (n > 0 && Py_SIZE(a) > PY_SSIZE_T_MAX / n) {
+        list_unlock(a);
         return PyErr_NoMemory();
+    }
     size = Py_SIZE(a) * n;
-    if (size == 0)
+    if (size == 0) {
+        list_unlock(a);
         return PyList_New(0);
+    }
     np = (PyListObject *) PyList_New(size);
-    if (np == NULL)
+    if (np == NULL) {
+        list_unlock(a);
         return NULL;
+    }
 
     items = np->ob_item;
     if (Py_SIZE(a) == 1) {
@@ -529,6 +679,7 @@ list_repeat(PyListObject *a, Py_ssize_t n)
             items[i] = elem;
             Py_INCREF(elem);
         }
+        list_unlock(a);
         return (PyObject *) np;
     }
     p = np->ob_item;
@@ -540,6 +691,7 @@ list_repeat(PyListObject *a, Py_ssize_t n)
             p++;
         }
     }
+    list_unlock(a);
     return (PyObject *) np;
 }
 
@@ -547,7 +699,9 @@ static int
 list_clear(PyListObject *a)
 {
     Py_ssize_t i;
-    PyObject **item = a->ob_item;
+    PyObject **item;
+    list_lock(a);
+    item = a->ob_item;
     if (item != NULL) {
         /* Because XDECREF can recursively invoke operations on
            this list, we make it empty first. */
@@ -563,6 +717,7 @@ list_clear(PyListObject *a)
     /* Never fails; the return value can be ignored.
        Note that there is no guarantee that the list is actually empty
        at this point, because XDECREF may have populated it again! */
+    list_unlock(a);
     return 0;
 }
 
@@ -593,16 +748,20 @@ list_ass_slice(PyListObject *a, Py_ssize_t ilow, Py_ssize_t ihigh, PyObject *v)
     size_t s;
     int result = -1;            /* guilty until proved innocent */
 #define b ((PyListObject *)v)
+    PyObject_Lock2((PyObject *)a, v);
     if (v == NULL)
         n = 0;
     else {
         if (a == b) {
             /* Special case "a[i:j] = a" -- copy b first */
             v = list_slice(b, 0, Py_SIZE(b));
-            if (v == NULL)
+            if (v == NULL) {
+                PyObject_Unlock2((PyObject *)a, v);
                 return result;
+            }
             result = list_ass_slice(a, ilow, ihigh, v);
             Py_DECREF(v);
+            PyObject_Unlock2((PyObject *)a, v);
             return result;
         }
         v_as_SF = PySequence_Fast(v, "can only assign an iterable");
@@ -625,8 +784,11 @@ list_ass_slice(PyListObject *a, Py_ssize_t ilow, Py_ssize_t ihigh, PyObject *v)
     assert(norig >= 0);
     d = n - norig;
     if (Py_SIZE(a) + d == 0) {
+        int status;
         Py_XDECREF(v_as_SF);
-        return list_clear(a);
+        status = list_clear(a);
+        PyObject_Unlock2((PyObject *)a, v);
+        return status;
     }
     item = a->ob_item;
     /* recycle the items that we are about to remove */
@@ -668,6 +830,7 @@ list_ass_slice(PyListObject *a, Py_ssize_t ilow, Py_ssize_t ihigh, PyObject *v)
         Py_XDECREF(recycle[k]);
     result = 0;
  Error:
+    PyObject_Unlock2((PyObject *)a, v);
     if (recycle != recycle_on_stack)
         PyMem_FREE(recycle);
     Py_XDECREF(v_as_SF);
@@ -691,25 +854,30 @@ list_inplace_repeat(PyListObject *self, Py_ssize_t n)
     PyObject **items;
     Py_ssize_t size, i, j, p;
 
-
+    list_lock(self);
     size = PyList_GET_SIZE(self);
     if (size == 0 || n == 1) {
         Py_INCREF(self);
+        list_unlock(self);
         return (PyObject *)self;
     }
 
     if (n < 1) {
         (void)list_clear(self);
         Py_INCREF(self);
+        list_unlock(self);
         return (PyObject *)self;
     }
 
     if (size > PY_SSIZE_T_MAX / n) {
+        list_unlock(self);
         return PyErr_NoMemory();
     }
 
-    if (list_resize(self, size*n) == -1)
+    if (list_resize(self, size*n) == -1) {
+        list_unlock(self);
         return NULL;
+    }
 
     p = size;
     items = self->ob_item;
@@ -721,21 +889,28 @@ list_inplace_repeat(PyListObject *self, Py_ssize_t n)
         }
     }
     Py_INCREF(self);
+    list_unlock(self);
     return (PyObject *)self;
 }
 
 static int
 list_ass_item(PyListObject *a, Py_ssize_t i, PyObject *v)
 {
+    list_lock(a);
     if (i < 0 || i >= Py_SIZE(a)) {
+        list_unlock(a);
         PyErr_SetString(PyExc_IndexError,
                         "list assignment index out of range");
         return -1;
     }
-    if (v == NULL)
-        return list_ass_slice(a, i, i+1, v);
+    if (v == NULL) {
+        int status = list_ass_slice(a, i, i+1, v);
+        list_unlock(a);
+        return status;
+    }
     Py_INCREF(v);
     Py_SETREF(a->ob_item[i], v);
+    list_unlock(a);
     return 0;
 }
 
@@ -786,19 +961,24 @@ listextend(PyListObject *self, PyObject *b)
        1) lists and tuples which can use PySequence_Fast ops
        2) extending self to self requires making a copy first
     */
+    PyObject_Lock2((PyObject *)self, b);
     if (PyList_CheckExact(b) || PyTuple_CheckExact(b) || (PyObject *)self == b) {
         PyObject **src, **dest;
         b = PySequence_Fast(b, "argument must be iterable");
-        if (!b)
+        if (!b) {
+            PyObject_Unlock2((PyObject *)self, b);
             return NULL;
+        }
         n = PySequence_Fast_GET_SIZE(b);
         if (n == 0) {
             /* short circuit when b is empty */
+            PyObject_Unlock2((PyObject *)self, b);
             Py_DECREF(b);
             Py_RETURN_NONE;
         }
         m = Py_SIZE(self);
         if (list_resize(self, m + n) == -1) {
+            PyObject_Unlock2((PyObject *)self, b);
             Py_DECREF(b);
             return NULL;
         }
@@ -815,18 +995,22 @@ listextend(PyListObject *self, PyObject *b)
             Py_INCREF(o);
             dest[i] = o;
         }
+        PyObject_Unlock2((PyObject *)self, b);
         Py_DECREF(b);
         Py_RETURN_NONE;
     }
 
     it = PyObject_GetIter(b);
-    if (it == NULL)
+    if (it == NULL) {
+        PyObject_Unlock2((PyObject *)self, b);
         return NULL;
+    }
     iternext = *it->ob_type->tp_iternext;
 
     /* Guess a result list size. */
     n = PyObject_LengthHint(b, 8);
     if (n == -1) {
+        PyObject_Unlock2((PyObject *)self, b);
         Py_DECREF(it);
         return NULL;
     }
@@ -875,10 +1059,12 @@ listextend(PyListObject *self, PyObject *b)
             goto error;
     }
 
+    PyObject_Unlock2((PyObject *)self, b);
     Py_DECREF(it);
     Py_RETURN_NONE;
 
   error:
+    PyObject_Unlock2((PyObject *)self, b);
     Py_DECREF(it);
     return NULL;
 }
@@ -912,20 +1098,24 @@ listpop(PyListObject *self, PyObject *args)
     if (!PyArg_ParseTuple(args, "|n:pop", &i))
         return NULL;
 
+    list_lock(self);
     if (Py_SIZE(self) == 0) {
         /* Special-case most common failure cause */
+        list_unlock(self);
         PyErr_SetString(PyExc_IndexError, "pop from empty list");
         return NULL;
     }
     if (i < 0)
         i += Py_SIZE(self);
     if (i < 0 || i >= Py_SIZE(self)) {
+        list_unlock(self);
         PyErr_SetString(PyExc_IndexError, "pop index out of range");
         return NULL;
     }
     v = self->ob_item[i];
     if (i == Py_SIZE(self) - 1) {
         status = list_resize(self, Py_SIZE(self) - 1);
+        list_unlock(self);
         if (status >= 0)
             return v; /* and v now owns the reference the list had */
         else
@@ -933,6 +1123,7 @@ listpop(PyListObject *self, PyObject *args)
     }
     Py_INCREF(v);
     status = list_ass_slice(self, i, i+1, (PyObject *)NULL);
+    list_unlock(self);
     if (status < 0) {
         Py_DECREF(v);
         return NULL;
@@ -956,6 +1147,7 @@ reverse_slice(PyObject **lo, PyObject **hi)
     }
 }
 
+
 /* Lots of code for an adaptive, stable, natural mergesort.  There are many
  * pieces to this algorithm; read listsort.txt for overviews and details.
  */
@@ -1932,6 +2124,7 @@ listsort(PyListObject *self, PyObject *args, PyObject *kwds)
     if (keyfunc == Py_None)
         keyfunc = NULL;
 
+    list_lock(self);
     /* The list is temporarily made empty, so that mutations performed
      * by comparison functions can't affect the slice of memory we're
      * sorting (allowing mutations during sorting is a core-dump
@@ -2063,6 +2256,7 @@ keyfunc_fail:
     Py_SIZE(self) = saved_ob_size;
     self->ob_item = saved_ob_item;
     self->allocated = saved_allocated;
+    list_unlock(self);
     if (final_ob_item != NULL) {
         /* we cannot use list_clear() for this because it does not
            guarantee that the list is really empty when it returns */
@@ -2080,22 +2274,31 @@ keyfunc_fail:
 int
 PyList_Sort(PyObject *v)
 {
+    PyObject *result;
     if (v == NULL || !PyList_Check(v)) {
         PyErr_BadInternalCall();
         return -1;
     }
-    v = listsort((PyListObject *)v, (PyObject *)NULL, (PyObject *)NULL);
-    if (v == NULL)
+    if (!PyList_CheckExact(v)) {
+        printf("yup, %p is not a real list-y list, it's type \"%s\"\n", v, v->ob_type->tp_name);
+       exit(-1);
+    }
+    list_lock((PyListObject *)v);
+    result = listsort((PyListObject *)v, (PyObject *)NULL, (PyObject *)NULL);
+    list_unlock((PyListObject *)v);
+    if (result == NULL)
         return -1;
-    Py_DECREF(v);
+    Py_DECREF(result);
     return 0;
 }
 
 static PyObject *
 listreverse(PyListObject *self)
 {
+    list_lock(self);
     if (Py_SIZE(self) > 1)
         reverse_slice(self->ob_item, self->ob_item + Py_SIZE(self));
+    list_unlock(self);
     Py_RETURN_NONE;
 }
 
@@ -2108,8 +2311,10 @@ PyList_Reverse(PyObject *v)
         PyErr_BadInternalCall();
         return -1;
     }
+    list_lock(self);
     if (Py_SIZE(self) > 1)
         reverse_slice(self->ob_item, self->ob_item + Py_SIZE(self));
+    list_unlock(self);
     return 0;
 }
 
@@ -2123,10 +2328,13 @@ PyList_AsTuple(PyObject *v)
         PyErr_BadInternalCall();
         return NULL;
     }
+    list_lock((PyListObject *)v);
     n = Py_SIZE(v);
     w = PyTuple_New(n);
-    if (w == NULL)
+    if (w == NULL) {
+        list_unlock((PyListObject *)v);
         return NULL;
+    }
     p = ((PyTupleObject *)w)->ob_item;
     q = ((PyListObject *)v)->ob_item;
     while (--n >= 0) {
@@ -2135,6 +2343,7 @@ PyList_AsTuple(PyObject *v)
         p++;
         q++;
     }
+    list_unlock((PyListObject *)v);
     return w;
 }
 
@@ -2148,6 +2357,7 @@ listindex(PyListObject *self, PyObject *args)
                                 _PyEval_SliceIndex, &start,
                                 _PyEval_SliceIndex, &stop))
         return NULL;
+    list_lock(self);
     if (start < 0) {
         start += Py_SIZE(self);
         if (start < 0)
@@ -2160,11 +2370,16 @@ listindex(PyListObject *self, PyObject *args)
     }
     for (i = start; i < stop && i < Py_SIZE(self); i++) {
         int cmp = PyObject_RichCompareBool(self->ob_item[i], v, Py_EQ);
-        if (cmp > 0)
+        if (cmp > 0) {
+            list_unlock(self);
             return PyLong_FromSsize_t(i);
-        else if (cmp < 0)
+        }
+        else if (cmp < 0) {
+            list_unlock(self);
             return NULL;
+        }
     }
+    list_unlock(self);
     PyErr_Format(PyExc_ValueError, "%R is not in list", v);
     return NULL;
 }
@@ -2175,13 +2390,17 @@ listcount(PyListObject *self, PyObject *v)
     Py_ssize_t count = 0;
     Py_ssize_t i;
 
+    list_lock(self);
     for (i = 0; i < Py_SIZE(self); i++) {
         int cmp = PyObject_RichCompareBool(self->ob_item[i], v, Py_EQ);
         if (cmp > 0)
             count++;
-        else if (cmp < 0)
+        else if (cmp < 0) {
+            list_unlock(self);
             return NULL;
+        }
     }
+    list_unlock(self);
     return PyLong_FromSsize_t(count);
 }
 
@@ -2190,46 +2409,75 @@ listremove(PyListObject *self, PyObject *v)
 {
     Py_ssize_t i;
 
+    list_lock(self);
     for (i = 0; i < Py_SIZE(self); i++) {
         int cmp = PyObject_RichCompareBool(self->ob_item[i], v, Py_EQ);
         if (cmp > 0) {
-            if (list_ass_slice(self, i, i+1,
-                               (PyObject *)NULL) == 0)
+            int result = list_ass_slice(self, i, i+1,
+                               (PyObject *)NULL);
+            list_unlock(self);
+            if (result == 0)
                 Py_RETURN_NONE;
             return NULL;
         }
-        else if (cmp < 0)
+        else if (cmp < 0) {
+            list_unlock(self);
             return NULL;
+        }
     }
+    list_unlock(self);
     PyErr_SetString(PyExc_ValueError, "list.remove(x): x not in list");
     return NULL;
 }
 
+
 static int
 list_traverse(PyListObject *o, visitproc visit, void *arg)
 {
     Py_ssize_t i;
 
-    for (i = Py_SIZE(o); --i >= 0; )
-        Py_VISIT(o->ob_item[i]);
+    list_lock(o);
+    i = Py_SIZE(o) - 1;
+    if (i >= 0) {
+        for (;;) {
+            PyObject *item = o->ob_item[i];
+            Py_VISIT(item);
+            if (!i--)
+                break;
+        }
+    }
+    list_unlock(o);
     return 0;
 }
 
+#define list_lock(o)
+#define list_lock2(o, p)
+#define list_unlock(o)
+#define list_unlock2(o, p)
+
+#undef list_lock
+#undef list_lock2
+#undef list_unlock
+#undef list_unlock2
+
 static PyObject *
 list_richcompare(PyObject *v, PyObject *w, int op)
 {
     PyListObject *vl, *wl;
     Py_ssize_t i;
+    PyObject *result;
 
     if (!PyList_Check(v) || !PyList_Check(w))
         Py_RETURN_NOTIMPLEMENTED;
 
     vl = (PyListObject *)v;
     wl = (PyListObject *)w;
+    list_lock2(vl, wl);
 
     if (Py_SIZE(vl) != Py_SIZE(wl) && (op == Py_EQ || op == Py_NE)) {
         /* Shortcut: if the lengths differ, the lists differ */
         PyObject *res;
+        list_unlock2(vl, wl);
         if (op == Py_EQ)
             res = Py_False;
         else
@@ -2242,8 +2490,10 @@ list_richcompare(PyObject *v, PyObject *w, int op)
     for (i = 0; i < Py_SIZE(vl) && i < Py_SIZE(wl); i++) {
         int k = PyObject_RichCompareBool(vl->ob_item[i],
                                          wl->ob_item[i], Py_EQ);
-        if (k < 0)
+        if (k < 0) {
+            list_unlock2(vl, wl);
             return NULL;
+        }
         if (!k)
             break;
     }
@@ -2254,6 +2504,7 @@ list_richcompare(PyObject *v, PyObject *w, int op)
         Py_ssize_t ws = Py_SIZE(wl);
         int cmp;
         PyObject *res;
+        list_unlock2(vl, wl);
         switch (op) {
         case Py_LT: cmp = vs <  ws; break;
         case Py_LE: cmp = vs <= ws; break;
@@ -2273,16 +2524,20 @@ list_richcompare(PyObject *v, PyObject *w, int op)
 
     /* We have an item that differs -- shortcuts for EQ/NE */
     if (op == Py_EQ) {
+        list_unlock2(vl, wl);
         Py_INCREF(Py_False);
         return Py_False;
     }
     if (op == Py_NE) {
+        list_unlock2(vl, wl);
         Py_INCREF(Py_True);
         return Py_True;
     }
 
     /* Compare the final item again using the proper operator */
-    return PyObject_RichCompare(vl->ob_item[i], wl->ob_item[i], op);
+    result = PyObject_RichCompare(vl->ob_item[i], wl->ob_item[i], op);
+    list_unlock2(vl, wl);
+    return result;
 }
 
 static int
@@ -2300,16 +2555,20 @@ list_init(PyListObject *self, PyObject *args, PyObject *kw)
     assert(self->ob_item != NULL ||
            self->allocated == 0 || self->allocated == -1);
 
+    list_lock(self);
     /* Empty previous contents */
     if (self->ob_item != NULL) {
         (void)list_clear(self);
     }
     if (arg != NULL) {
         PyObject *rv = listextend(self, arg);
-        if (rv == NULL)
+        if (rv == NULL) {
+            list_unlock(self);
             return -1;
+        }
         Py_DECREF(rv);
     }
+    list_unlock(self);
     return 0;
 }
 
@@ -2318,7 +2577,9 @@ list_sizeof(PyListObject *self)
 {
     Py_ssize_t res;
 
+    list_lock(self);
     res = _PyObject_SIZE(Py_TYPE(self)) + self->allocated * sizeof(void*);
+    list_unlock(self);
     return PyLong_FromSsize_t(res);
 }
 
@@ -2397,14 +2658,18 @@ PyDoc_STRVAR(list_doc,
 static PyObject *
 list_subscript(PyListObject* self, PyObject* item)
 {
+    PyObject *result;
     if (PyIndex_Check(item)) {
         Py_ssize_t i;
         i = PyNumber_AsSsize_t(item, PyExc_IndexError);
         if (i == -1 && PyErr_Occurred())
             return NULL;
+        list_lock(self);
         if (i < 0)
             i += PyList_GET_SIZE(self);
-        return list_item(self, i);
+        result = list_item(self, i);
+        list_unlock(self);
+        return result;
     }
     else if (PySlice_Check(item)) {
         Py_ssize_t start, stop, step, slicelength, cur, i;
@@ -2412,20 +2677,28 @@ list_subscript(PyListObject* self, PyObject* item)
         PyObject* it;
         PyObject **src, **dest;
 
+        list_lock(self);
         if (PySlice_GetIndicesEx(item, Py_SIZE(self),
                          &start, &stop, &step, &slicelength) < 0) {
+            list_unlock(self);
             return NULL;
         }
 
         if (slicelength <= 0) {
+            list_unlock(self);
             return PyList_New(0);
         }
         else if (step == 1) {
-            return list_slice(self, start, stop);
+            result = list_slice(self, start, stop);
+            list_unlock(self);
+            return result;
         }
         else {
             result = PyList_New(slicelength);
-            if (!result) return NULL;
+            if (!result) {
+                list_unlock(self);
+                return NULL;
+            }
 
             src = self->ob_item;
             dest = ((PyListObject *)result)->ob_item;
@@ -2436,10 +2709,12 @@ list_subscript(PyListObject* self, PyObject* item)
                 dest[i] = it;
             }
 
+            list_unlock(self);
             return result;
         }
     }
     else {
+        list_unlock(self);
         PyErr_Format(PyExc_TypeError,
                      "list indices must be integers or slices, not %.200s",
                      item->ob_type->tp_name);
@@ -2450,24 +2725,33 @@ list_subscript(PyListObject* self, PyObject* item)
 static int
 list_ass_subscript(PyListObject* self, PyObject* item, PyObject* value)
 {
+    int result;
     if (PyIndex_Check(item)) {
         Py_ssize_t i = PyNumber_AsSsize_t(item, PyExc_IndexError);
         if (i == -1 && PyErr_Occurred())
             return -1;
+        list_lock(self);
         if (i < 0)
             i += PyList_GET_SIZE(self);
-        return list_ass_item(self, i, value);
+        result = list_ass_item(self, i, value);
+        list_unlock(self);
+        return result;
     }
     else if (PySlice_Check(item)) {
         Py_ssize_t start, stop, step, slicelength;
 
+        list_lock(self);
         if (PySlice_GetIndicesEx(item, Py_SIZE(self),
                          &start, &stop, &step, &slicelength) < 0) {
+            list_unlock(self);
             return -1;
         }
 
-        if (step == 1)
-            return list_ass_slice(self, start, stop, value);
+        if (step == 1) {
+            result = list_ass_slice(self, start, stop, value);
+            list_unlock(self);
+            return result;
+        }
 
         /* Make sure s[5:2] = [..] inserts at the right place:
            before 5, not before 2. */
@@ -2482,8 +2766,10 @@ list_ass_subscript(PyListObject* self, PyObject* item, PyObject* value)
             Py_ssize_t i;
             int res;
 
-            if (slicelength <= 0)
+            if (slicelength <= 0) {
+                list_unlock(self);
                 return 0;
+            }
 
             if (step < 0) {
                 stop = start + 1;
@@ -2498,6 +2784,7 @@ list_ass_subscript(PyListObject* self, PyObject* item, PyObject* value)
                 PyMem_MALLOC(slicelength*sizeof(PyObject*));
             if (!garbage) {
                 PyErr_NoMemory();
+                list_unlock(self);
                 return -1;
             }
 
@@ -2538,7 +2825,8 @@ list_ass_subscript(PyListObject* self, PyObject* item, PyObject* value)
             }
             PyMem_FREE(garbage);
 
-            return res;
+        list_unlock(self);
+        return res;
         }
         else {
             /* assign slice */
@@ -2556,8 +2844,10 @@ list_ass_subscript(PyListObject* self, PyObject* item, PyObject* value)
                                       "must assign iterable "
                                       "to extended slice");
             }
-            if (!seq)
+            if (!seq) {
+                list_unlock(self);
                 return -1;
+            }
 
             if (PySequence_Fast_GET_SIZE(seq) != slicelength) {
                 PyErr_Format(PyExc_ValueError,
@@ -2567,11 +2857,13 @@ list_ass_subscript(PyListObject* self, PyObject* item, PyObject* value)
                          PySequence_Fast_GET_SIZE(seq),
                          slicelength);
                 Py_DECREF(seq);
+                list_unlock(self);
                 return -1;
             }
 
             if (!slicelength) {
                 Py_DECREF(seq);
+                list_unlock(self);
                 return 0;
             }
 
@@ -2580,6 +2872,7 @@ list_ass_subscript(PyListObject* self, PyObject* item, PyObject* value)
             if (!garbage) {
                 Py_DECREF(seq);
                 PyErr_NoMemory();
+                list_unlock(self);
                 return -1;
             }
 
@@ -2600,10 +2893,12 @@ list_ass_subscript(PyListObject* self, PyObject* item, PyObject* value)
             PyMem_FREE(garbage);
             Py_DECREF(seq);
 
+            list_unlock(self);
             return 0;
         }
     }
     else {
+        list_unlock(self);
         PyErr_Format(PyExc_TypeError,
                      "list indices must be integers or slices, not %.200s",
                      item->ob_type->tp_name);
@@ -2656,8 +2951,25 @@ PyTypeObject PyList_Type = {
     0,                                          /* tp_dictoffset */
     (initproc)list_init,                        /* tp_init */
     PyType_GenericAlloc,                        /* tp_alloc */
-    PyType_GenericNew,                          /* tp_new */
+    list_new,                                   /* tp_new */
     PyObject_GC_Del,                            /* tp_free */
+
+
+    0, /* tp_is_gc */
+    0, /* tp_bases */
+    0, /* tp_mro */
+    0, /* tp_cache */
+    0, /* tp_subclasses */
+    0, /* tp_weaklist */
+    0, /* tp_del */
+
+    0, /* tp_version_tag */
+
+    0, /* tp_finalize */
+
+    (lockfunc)list_lock, /* tp_rlock */
+    (lockfunc)list_unlock, /* tp_runlock */
+
 };
 
 
diff --git a/Objects/longobject.c b/Objects/longobject.c
index d05de8bf07..d0ebba4e92 100644
--- a/Objects/longobject.c
+++ b/Objects/longobject.c
@@ -78,7 +78,7 @@ _PyLong_Negate(PyLongObject **x_p)
     PyLongObject *x;
 
     x = (PyLongObject *)*x_p;
-    if (Py_REFCNT(x) == 1) {
+    if (Py_REFCNT((PyObject*) x) == 1) {
         Py_SIZE(x) = -Py_SIZE(x);
         return;
     }
@@ -4493,7 +4493,7 @@ _PyLong_GCD(PyObject *aarg, PyObject *barg)
         }
         if (c != NULL)
             Py_SIZE(c) = size_a;
-        else if (Py_REFCNT(a) == 1) {
+        else if (Py_REFCNT((PyObject*)a) == 1) {
             Py_INCREF(a);
             c = a;
         }
@@ -4506,7 +4506,7 @@ _PyLong_GCD(PyObject *aarg, PyObject *barg)
 
         if (d != NULL)
             Py_SIZE(d) = size_a;
-        else if (Py_REFCNT(b) == 1 && size_a <= alloc_b) {
+        else if (Py_REFCNT((PyObject*)b) == 1 && size_a <= alloc_b) {
             Py_INCREF(b);
             d = b;
             Py_SIZE(d) = size_a;
@@ -5361,7 +5361,7 @@ _PyLong_Init(void)
             /* _Py_NewReference sets the ref count to 1 but
              * the ref count might be larger. Set the refcnt
              * to the original refcnt + 1 */
-            Py_REFCNT(op) = refcnt + 1;
+            Py_REFCNT_Initialize(op, refcnt + 1);
             assert(Py_SIZE(op) == size);
             assert(v->ob_digit[0] == (digit)abs(ival));
         }
diff --git a/Objects/methodobject.c b/Objects/methodobject.c
index 946357f24a..5f62cf2354 100644
--- a/Objects/methodobject.c
+++ b/Objects/methodobject.c
@@ -4,6 +4,13 @@
 #include "Python.h"
 #include "structmember.h"
 
+static py_recursivelock_t module_rlock = PY_RECURSIVELOCK_STATIC_INIT("methodobject module lock");
+#define module_lock() py_recursivelock_lock(&module_rlock)
+#define module_unlock() py_recursivelock_unlock(&module_rlock)
+void methodobject_lock_stats(void) {
+    py_recursivelock_stats(&module_rlock);
+}
+
 /* Free list for method objects to safe malloc/free overhead
  * The m_self element is used to chain the objects.
  */
@@ -26,13 +33,16 @@ PyObject *
 PyCFunction_NewEx(PyMethodDef *ml, PyObject *self, PyObject *module)
 {
     PyCFunctionObject *op;
+    module_lock();
     op = free_list;
     if (op != NULL) {
         free_list = (PyCFunctionObject *)(op->m_self);
-        (void)PyObject_INIT(op, &PyCFunction_Type);
         numfree--;
+        module_unlock();
+        (void)PyObject_INIT(op, &PyCFunction_Type);
     }
     else {
+        module_unlock();
         op = PyObject_GC_New(PyCFunctionObject, &PyCFunction_Type);
         if (op == NULL)
             return NULL;
@@ -156,12 +166,15 @@ meth_dealloc(PyCFunctionObject *m)
     }
     Py_XDECREF(m->m_self);
     Py_XDECREF(m->m_module);
+    module_lock();
     if (numfree < PyCFunction_MAXFREELIST) {
         m->m_self = (PyObject *)free_list;
         free_list = m;
         numfree++;
+        module_unlock();
     }
     else {
+        module_unlock();
         PyObject_GC_Del(m);
     }
 }
@@ -374,16 +387,25 @@ PyTypeObject PyCFunction_Type = {
 int
 PyCFunction_ClearFreeList(void)
 {
-    int freelist_size = numfree;
-
-    while (free_list) {
-        PyCFunctionObject *v = free_list;
-        free_list = (PyCFunctionObject *)(v->m_self);
+    PyCFunctionObject *head;
+    int freed, count;
+
+    module_lock();
+    head = free_list;
+    freed = count = numfree;
+    free_list = NULL;
+    numfree = 0;
+    module_unlock();
+
+    while (head) {
+        PyCFunctionObject *v = head;
+        head = (PyCFunctionObject *)(head->m_self);
         PyObject_GC_Del(v);
-        numfree--;
+        count--;
     }
-    assert(numfree == 0);
-    return freelist_size;
+    assert(count == 0);
+
+    return freed;
 }
 
 void
@@ -396,7 +418,9 @@ PyCFunction_Fini(void)
 void
 _PyCFunction_DebugMallocStats(FILE *out)
 {
+    module_lock();
     _PyDebugAllocatorStats(out,
                            "free PyCFunctionObject",
                            numfree, sizeof(PyCFunctionObject));
+    module_unlock();
 }
diff --git a/Objects/moduleobject.c b/Objects/moduleobject.c
index 24c5f4c282..8ee71194a3 100644
--- a/Objects/moduleobject.c
+++ b/Objects/moduleobject.c
@@ -35,7 +35,7 @@ PyModuleDef_Init(struct PyModuleDef* def)
          return NULL;
     if (def->m_base.m_index == 0) {
         max_module_number++;
-        Py_REFCNT(def) = 1;
+        Py_REFCNT_Initialize((PyObject*)def, 1);
         Py_TYPE(def) = &PyModuleDef_Type;
         def->m_base.m_index = max_module_number;
     }
@@ -88,6 +88,7 @@ PyModule_NewObject(PyObject *name)
     m->md_weaklist = NULL;
     m->md_name = NULL;
     m->md_dict = PyDict_New();
+    ((PyDictObject *)(m->md_dict))->ma_lock.description = PyUnicode_AsUTF8(name);
     if (module_init_dict(m, m->md_dict, name, NULL) != 0)
         goto fail;
     PyObject_GC_Track(m);
diff --git a/Objects/object.c b/Objects/object.c
index 8072dbced2..041f352882 100644
--- a/Objects/object.c
+++ b/Objects/object.c
@@ -27,10 +27,10 @@ _Py_GetRefTotal(void)
        hash table code is well-tested) */
     o = _PyDict_Dummy();
     if (o != NULL)
-        total -= o->ob_refcnt;
+        total -= Py_REFCNT(o);
     o = _PySet_Dummy;
     if (o != NULL)
-        total -= o->ob_refcnt;
+        total -= Py_REFCNT(o);
     return total;
 }
 
@@ -215,7 +215,7 @@ _Py_NegativeRefcount(const char *fname, int lineno, PyObject *op)
     PyOS_snprintf(buf, sizeof(buf),
                   "%s:%i object at %p has negative ref count "
                   "%" PY_FORMAT_SIZE_T "d",
-                  fname, lineno, op, op->ob_refcnt);
+                  fname, lineno, op, Py_REFCNT(op));
     Py_FatalError(buf);
 }
 
@@ -302,27 +302,30 @@ PyObject_CallFinalizerFromDealloc(PyObject *self)
     Py_ssize_t refcnt;
 
     /* Temporarily resurrect the object. */
-    if (self->ob_refcnt != 0) {
+    if (Py_REFCNT(self) != 0) {
         Py_FatalError("PyObject_CallFinalizerFromDealloc called on "
                       "object with a non-zero refcount");
     }
-    self->ob_refcnt = 1;
+    Py_REFCNT_Initialize(self, 1);
 
     PyObject_CallFinalizer(self);
 
     /* Undo the temporary resurrection; can't use DECREF here, it would
      * cause a recursive call.
      */
-    assert(self->ob_refcnt > 0);
-    if (--self->ob_refcnt == 0)
+    assert(Py_REFCNT(self) > 0);
+    if (Py_REFCNT(self) == 1) {
+	Py_REFCNT_Initialize(self, 0);
         return 0;         /* this is the normal path out */
+    }
+    Py_DECREF(self);
 
     /* tp_finalize resurrected it!  Make it look like the original Py_DECREF
      * never happened.
      */
-    refcnt = self->ob_refcnt;
+    refcnt = Py_REFCNT(self);
     _Py_NewReference(self);
-    self->ob_refcnt = refcnt;
+    Py_REFCNT_Initialize(self, refcnt);
 
     if (PyType_IS_GC(Py_TYPE(self))) {
         assert(_PyGC_REFS(self) != _PyGC_REFS_UNTRACKED);
@@ -362,12 +365,12 @@ PyObject_Print(PyObject *op, FILE *fp, int flags)
         Py_END_ALLOW_THREADS
     }
     else {
-        if (op->ob_refcnt <= 0)
+        if (Py_REFCNT(op) <= 0)
             /* XXX(twouters) cast refcount to long until %zd is
                universally available */
             Py_BEGIN_ALLOW_THREADS
             fprintf(fp, "<refcnt %ld at %p>",
-                (long)op->ob_refcnt, op);
+                (long)Py_REFCNT(op), op);
             Py_END_ALLOW_THREADS
         else {
             PyObject *s;
@@ -449,7 +452,7 @@ _PyObject_Dump(PyObject* op)
             "refcount: %ld\n"
             "address : %p\n",
             Py_TYPE(op)==NULL ? "NULL" : Py_TYPE(op)->tp_name,
-            (long)op->ob_refcnt,
+            (long)Py_REFCNT(op),
             op);
     }
 }
@@ -939,7 +942,7 @@ PyObject_SetAttr(PyObject *v, PyObject *name, PyObject *value)
         return err;
     }
     Py_DECREF(name);
-    assert(name->ob_refcnt >= 1);
+    assert(Py_REFCNT(name) >= 1);
     if (tp->tp_getattr == NULL && tp->tp_getattro == NULL)
         PyErr_Format(PyExc_TypeError,
                      "'%.100s' object has no attributes "
@@ -1266,6 +1269,59 @@ PyObject_Not(PyObject *v)
     return res == 0;
 }
 
+/* Generic lock functions */
+
+void
+PyObject_Lock(PyObject *o)
+{
+    lockfunc lf;
+    if (!o)
+        return;
+
+    lf = o->ob_type->tp_lock;
+    if (lf)
+        lf(o);
+}
+
+void
+PyObject_Unlock(PyObject *o)
+{
+    lockfunc ulf;
+    if (!o)
+        return;
+
+    ulf = o->ob_type->tp_unlock;
+    if (ulf)
+        ulf(o);
+}
+
+void
+PyObject_Lock2(PyObject *o1, PyObject *o2)
+{
+    /*
+    if o1 == o2 we *do* want to lock twice,
+    because they're going to call unlock twice.
+
+    work correctly if either object is null.
+    */
+    if (o1 && (o1 <= o2))
+        PyObject_Lock(o1);
+    if (o2)
+        PyObject_Lock(o2);
+    if (o1 > o2)
+        PyObject_Lock(o1);
+}
+
+void
+PyObject_Unlock2(PyObject *o1, PyObject *o2)
+{
+    if (o1)
+        PyObject_Unlock(o1);
+    if (o2)
+        PyObject_Unlock(o2);
+}
+
+
 /* Test whether an object can be called */
 
 int
@@ -1465,7 +1521,7 @@ PyTypeObject _PyNone_Type = {
 
 PyObject _Py_NoneStruct = {
   _PyObject_EXTRA_INIT
-  1, &_PyNone_Type
+  _PyObject_REFCNT_INIT(1), &_PyNone_Type
 };
 
 /* NotImplemented is an object that can be used to signal that an
@@ -1550,7 +1606,7 @@ PyTypeObject _PyNotImplemented_Type = {
 
 PyObject _Py_NotImplementedStruct = {
     _PyObject_EXTRA_INIT
-    1, &_PyNotImplemented_Type
+    _PyObject_REFCNT_INIT(1), &_PyNotImplemented_Type
 };
 
 void
@@ -1738,7 +1794,7 @@ void
 _Py_NewReference(PyObject *op)
 {
     _Py_INC_REFTOTAL;
-    op->ob_refcnt = 1;
+    Py_REFCNT_Initialize(op, 1);
     _Py_AddToAllObjects(op, 1);
     _Py_INC_TPALLOCS(op);
 }
@@ -1749,7 +1805,7 @@ _Py_ForgetReference(PyObject *op)
 #ifdef SLOW_UNREF_CHECK
     PyObject *p;
 #endif
-    if (op->ob_refcnt < 0)
+    if (Py_REFCNT(op) < 0)
         Py_FatalError("UNREF negative refcnt");
     if (op == &refchain ||
         op->_ob_prev->_ob_next != op || op->_ob_next->_ob_prev != op) {
@@ -1792,7 +1848,7 @@ _Py_PrintReferences(FILE *fp)
     PyObject *op;
     fprintf(fp, "Remaining objects:\n");
     for (op = refchain._ob_next; op != &refchain; op = op->_ob_next) {
-        fprintf(fp, "%p [%" PY_FORMAT_SIZE_T "d] ", op, op->ob_refcnt);
+        fprintf(fp, "%p [%" PY_FORMAT_SIZE_T "d] ", op, Py_REFCNT(op));
         if (PyObject_Print(op, fp, 0) != 0)
             PyErr_Clear();
         putc('\n', fp);
@@ -1809,7 +1865,7 @@ _Py_PrintReferenceAddresses(FILE *fp)
     fprintf(fp, "Remaining object addresses:\n");
     for (op = refchain._ob_next; op != &refchain; op = op->_ob_next)
         fprintf(fp, "%p [%" PY_FORMAT_SIZE_T "d] %s\n", op,
-            op->ob_refcnt, Py_TYPE(op)->tp_name);
+            Py_REFCNT(op), Py_TYPE(op)->tp_name);
 }
 
 PyObject *
@@ -1954,7 +2010,7 @@ _PyTrash_deposit_object(PyObject *op)
 {
     assert(PyObject_IS_GC(op));
     assert(_PyGC_REFS(op) == _PyGC_REFS_UNTRACKED);
-    assert(op->ob_refcnt == 0);
+    assert(Py_REFCNT(op) == 0);
     _Py_AS_GC(op)->gc.gc_prev = (PyGC_Head *)_PyTrash_delete_later;
     _PyTrash_delete_later = op;
 }
@@ -1966,7 +2022,7 @@ _PyTrash_thread_deposit_object(PyObject *op)
     PyThreadState *tstate = PyThreadState_GET();
     assert(PyObject_IS_GC(op));
     assert(_PyGC_REFS(op) == _PyGC_REFS_UNTRACKED);
-    assert(op->ob_refcnt == 0);
+    assert(Py_REFCNT(op) == 0);
     _Py_AS_GC(op)->gc.gc_prev = (PyGC_Head *) tstate->trash_delete_later;
     tstate->trash_delete_later = op;
 }
@@ -1990,7 +2046,7 @@ _PyTrash_destroy_chain(void)
          * assorted non-release builds calling Py_DECREF again ends
          * up distorting allocation statistics.
          */
-        assert(op->ob_refcnt == 0);
+        assert(Py_REFCNT(op) == 0);
         ++_PyTrash_delete_nesting;
         (*dealloc)(op);
         --_PyTrash_delete_nesting;
@@ -2015,7 +2071,7 @@ _PyTrash_thread_destroy_chain(void)
          * assorted non-release builds calling Py_DECREF again ends
          * up distorting allocation statistics.
          */
-        assert(op->ob_refcnt == 0);
+        assert(Py_REFCNT(op) == 0);
         ++tstate->trash_delete_nesting;
         (*dealloc)(op);
         --tstate->trash_delete_nesting;
diff --git a/Objects/obmalloc.c b/Objects/obmalloc.c
index 7cc889f817..3336cb633e 100644
--- a/Objects/obmalloc.c
+++ b/Objects/obmalloc.c
@@ -621,26 +621,62 @@ static int running_on_valgrind = -1;
 /*
  * Locking
  *
- * To reduce lock contention, it would probably be better to refine the
- * crude function locking with per size class locking. I'm not positive
- * however, whether it's worth switching to such locking policy because
- * of the performance penalty it might introduce.
- *
- * The following macros describe the simplest (should also be the fastest)
- * lock object on a particular platform and the init/fini/lock/unlock
- * operations on it. The locks defined here are not expected to be recursive
- * because it is assumed that they will always be called in the order:
- * INIT, [LOCK, UNLOCK]*, FINI.
  */
 
 /*
- * Python's threads are serialized, so object malloc locking is disabled.
+ * per-size class locking is a small win.
+ * it reduces contention at the cost of the overhead of needing the arena lock.
  */
-#define SIMPLELOCK_DECL(lock)   /* simple lock declaration              */
-#define SIMPLELOCK_INIT(lock)   /* allocate (if needed) and initialize  */
-#define SIMPLELOCK_FINI(lock)   /* free/destroy an existing lock        */
-#define SIMPLELOCK_LOCK(lock)   /* acquire released lock */
-#define SIMPLELOCK_UNLOCK(lock) /* release acquired lock */
+#define OBMALLOC_LOCK_PER_SIZE_CLASS
+
+
+#ifdef OBMALLOC_LOCK_PER_SIZE_CLASS
+py_lock_t _arena_lock = PY_LOCK_STATIC_INIT("arena lock");
+#define arena_lock()    (py_lock_lock  (&_arena_lock))
+#define arena_unlock()  (py_lock_unlock(&_arena_lock))
+
+py_lock_t _pool_locks[NB_SMALL_SIZE_CLASSES];
+#define LOCK(class)     (py_lock_lock  (_pool_locks + class))
+#define UNLOCK(class)   (py_lock_unlock(_pool_locks + class))
+
+void obmalloc_lock_stats(void) {
+    py_lock_t stats;
+    memset(&stats, 0, sizeof(stats));
+    stats.description = "obmalloc cumulative pool locks";
+#ifdef PY_LOCK_WANT_STATS
+    {
+    int i;
+
+    for (i = 0; i < NB_SMALL_SIZE_CLASSES; i++) {
+        py_lock_t *p = _pool_locks + i;
+        #define ACCUMULATE_LOCK_STAT(field) stats.field += p->field;
+        ACCUMULATE_LOCK_STAT(no_contention_count);
+        ACCUMULATE_LOCK_STAT(contention_count);
+        ACCUMULATE_LOCK_STAT(contention_total_delay);
+        ACCUMULATE_LOCK_STAT(contention_max_delta);
+    }
+
+    }
+#endif
+    py_lock_stats(&stats);
+    py_lock_stats(&_arena_lock);
+}
+
+#else /* OBMALLOC_LOCK_PER_SIZE_CLASS */
+py_lock_t _obmalloc_lock = PY_LOCK_STATIC_INIT("obmalloc (single lock)");
+
+#define LOCK(class)     (py_lock_lock  (&_obmalloc_lock))
+#define UNLOCK(class)   (py_lock_unlock(&_obmalloc_lock))
+
+#define arena_lock()
+#define arena_unlock()
+
+
+void obmalloc_lock_stats(void) {
+    py_lock_stats(&_obmalloc_lock);
+}
+
+#endif /* OBMALLOC_LOCK_PER_SIZE_CLASS */
 
 /*
  * Basic types
@@ -729,15 +765,6 @@ struct arena_object {
 
 /*==========================================================================*/
 
-/*
- * This malloc lock
- */
-SIMPLELOCK_DECL(_malloc_lock)
-#define LOCK()          SIMPLELOCK_LOCK(_malloc_lock)
-#define UNLOCK()        SIMPLELOCK_UNLOCK(_malloc_lock)
-#define LOCK_INIT()     SIMPLELOCK_INIT(_malloc_lock)
-#define LOCK_FINI()     SIMPLELOCK_FINI(_malloc_lock)
-
 /*
  * Pool table -- headed, circular, doubly-linked lists of partially used pools.
 
@@ -931,6 +958,17 @@ static size_t narenas_highwater = 0;
 
 static Py_ssize_t _Py_AllocatedBlocks = 0;
 
+void
+_Py_ObMalloc_Init(void)
+{
+    int i;
+
+    for (i = 0; i < NB_SMALL_SIZE_CLASSES; i++) {
+        py_lock_init(&_pool_locks[i], "obmalloc pool lock");
+    }
+}
+
+
 Py_ssize_t
 _Py_GetAllocatedBlocks(void)
 {
@@ -1173,8 +1211,9 @@ _PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)
     poolp pool;
     poolp next;
     uint size;
+    uint class;
 
-    _Py_AllocatedBlocks++;
+    ATOMIC_INC(&_Py_AllocatedBlocks);
 
     assert(nelem <= PY_SSIZE_T_MAX / elsize);
     nbytes = nelem * elsize;
@@ -1190,12 +1229,12 @@ _PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)
         goto redirect;
 
     if ((nbytes - 1) < SMALL_REQUEST_THRESHOLD) {
-        LOCK();
+        class = (uint)(nbytes - 1) >> ALIGNMENT_SHIFT;
+        LOCK(class);
         /*
          * Most frequent paths first
          */
-        size = (uint)(nbytes - 1) >> ALIGNMENT_SHIFT;
-        pool = usedpools[size + size];
+        pool = usedpools[class + class];
         if (pool != pool->nextpool) {
             /*
              * There is a used pool for this size class.
@@ -1205,7 +1244,7 @@ _PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)
             bp = pool->freeblock;
             assert(bp != NULL);
             if ((pool->freeblock = *(block **)bp) != NULL) {
-                UNLOCK();
+                UNLOCK(class);
                 if (use_calloc)
                     memset(bp, 0, nbytes);
                 return (void *)bp;
@@ -1217,9 +1256,9 @@ _PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)
                 /* There is room for another block. */
                 pool->freeblock = (block*)pool +
                                   pool->nextoffset;
-                pool->nextoffset += INDEX2SIZE(size);
+                pool->nextoffset += INDEX2SIZE(class);
                 *(block **)(pool->freeblock) = NULL;
-                UNLOCK();
+                UNLOCK(class);
                 if (use_calloc)
                     memset(bp, 0, nbytes);
                 return (void *)bp;
@@ -1229,7 +1268,7 @@ _PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)
             pool = pool->prevpool;
             next->prevpool = pool;
             pool->nextpool = next;
-            UNLOCK();
+            UNLOCK(class);
             if (use_calloc)
                 memset(bp, 0, nbytes);
             return (void *)bp;
@@ -1238,17 +1277,20 @@ _PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)
         /* There isn't a pool of the right size class immediately
          * available:  use a free pool.
          */
+        arena_lock();
         if (usable_arenas == NULL) {
             /* No arena has a free pool:  allocate a new arena. */
 #ifdef WITH_MEMORY_LIMITS
             if (narenas_currently_allocated >= MAX_ARENAS) {
-                UNLOCK();
+                arena_unlock();
+                UNLOCK(class);
                 goto redirect;
             }
 #endif
             usable_arenas = new_arena();
             if (usable_arenas == NULL) {
-                UNLOCK();
+                arena_unlock();
+                UNLOCK(class);
                 goto redirect;
             }
             usable_arenas->nextarena =
@@ -1294,15 +1336,16 @@ _PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)
                        (block*)usable_arenas->address +
                            ARENA_SIZE - POOL_SIZE);
             }
+        arena_unlock();
         init_pool:
             /* Frontlink to used pools. */
-            next = usedpools[size + size]; /* == prev */
+            next = usedpools[class + class]; /* == prev */
             pool->nextpool = next;
             pool->prevpool = next;
             next->nextpool = pool;
             next->prevpool = pool;
             pool->ref.count = 1;
-            if (pool->szidx == size) {
+            if (pool->szidx == class) {
                 /* Luckily, this pool last contained blocks
                  * of the same size class, so its header
                  * and free list are already initialized.
@@ -1310,7 +1353,7 @@ _PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)
                 bp = pool->freeblock;
                 assert(bp != NULL);
                 pool->freeblock = *(block **)bp;
-                UNLOCK();
+                UNLOCK(class);
                 if (use_calloc)
                     memset(bp, 0, nbytes);
                 return (void *)bp;
@@ -1320,14 +1363,14 @@ _PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)
              * contain just the second block, and return the first
              * block.
              */
-            pool->szidx = size;
-            size = INDEX2SIZE(size);
+            pool->szidx = class;
+            size = INDEX2SIZE(class);
             bp = (block *)pool + POOL_OVERHEAD;
             pool->nextoffset = POOL_OVERHEAD + (size << 1);
             pool->maxnextoffset = POOL_SIZE - size;
             pool->freeblock = bp + size;
             *(block **)(pool->freeblock) = NULL;
-            UNLOCK();
+            UNLOCK(class);
             if (use_calloc)
                 memset(bp, 0, nbytes);
             return (void *)bp;
@@ -1357,6 +1400,7 @@ _PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)
             }
         }
 
+        arena_unlock();
         goto init_pool;
     }
 
@@ -1375,7 +1419,7 @@ redirect:
         else
             result = PyMem_RawMalloc(nbytes);
         if (!result)
-            _Py_AllocatedBlocks--;
+            ATOMIC_DEC(&_Py_AllocatedBlocks);
         return result;
     }
 }
@@ -1401,7 +1445,7 @@ _PyObject_Free(void *ctx, void *p)
     poolp pool;
     block *lastfree;
     poolp next, prev;
-    uint size;
+    uint class;
 #ifndef Py_USING_MEMORY_DEBUGGER
     uint arenaindex_temp;
 #endif
@@ -1409,7 +1453,7 @@ _PyObject_Free(void *ctx, void *p)
     if (p == NULL)      /* free(NULL) has no effect */
         return;
 
-    _Py_AllocatedBlocks--;
+    ATOMIC_DEC(&_Py_AllocatedBlocks);
 
 #ifdef WITH_VALGRIND
     if (UNLIKELY(running_on_valgrind > 0))
@@ -1417,9 +1461,10 @@ _PyObject_Free(void *ctx, void *p)
 #endif
 
     pool = POOL_ADDR(p);
+    class = pool->szidx;
     if (Py_ADDRESS_IN_RANGE(p, pool)) {
         /* We allocated this address. */
-        LOCK();
+        LOCK(class);
         /* Link p to the start of the pool's freeblock list.  Since
          * the pool had at least the p block outstanding, the pool
          * wasn't empty (so it's already in a usedpools[] list, or
@@ -1438,7 +1483,7 @@ _PyObject_Free(void *ctx, void *p)
              */
             if (--pool->ref.count != 0) {
                 /* pool isn't empty:  leave it in usedpools */
-                UNLOCK();
+                UNLOCK(class);
                 return;
             }
             /* Pool is now empty:  unlink from usedpools, and
@@ -1454,6 +1499,7 @@ _PyObject_Free(void *ctx, void *p)
             /* Link the pool to freepools.  This is a singly-linked
              * list, and pool->prevpool isn't used there.
              */
+            arena_lock();
             ao = &arenas[pool->arenaindex];
             pool->nextpool = ao->freepools;
             ao->freepools = pool;
@@ -1510,7 +1556,8 @@ _PyObject_Free(void *ctx, void *p)
                 ao->address = 0;                        /* mark unassociated */
                 --narenas_currently_allocated;
 
-                UNLOCK();
+                arena_unlock();
+                UNLOCK(class);
                 return;
             }
             if (nf == 1) {
@@ -1526,7 +1573,8 @@ _PyObject_Free(void *ctx, void *p)
                 usable_arenas = ao;
                 assert(usable_arenas->address != 0);
 
-                UNLOCK();
+                arena_unlock();
+                UNLOCK(class);
                 return;
             }
             /* If this arena is now out of order, we need to keep
@@ -1539,7 +1587,8 @@ _PyObject_Free(void *ctx, void *p)
             if (ao->nextarena == NULL ||
                          nf <= ao->nextarena->nfreepools) {
                 /* Case 4.  Nothing to do. */
-                UNLOCK();
+                arena_unlock();
+                UNLOCK(class);
                 return;
             }
             /* Case 3:  We have to move the arena towards the end
@@ -1588,7 +1637,8 @@ _PyObject_Free(void *ctx, void *p)
                 ao->prevarena == NULL) ||
                 ao->prevarena->nextarena == ao);
 
-            UNLOCK();
+            arena_unlock();
+            UNLOCK(class);
             return;
         }
         /* Pool was full, so doesn't currently live in any list:
@@ -1599,15 +1649,14 @@ _PyObject_Free(void *ctx, void *p)
          */
         --pool->ref.count;
         assert(pool->ref.count > 0);            /* else the pool is empty */
-        size = pool->szidx;
-        next = usedpools[size + size];
+        next = usedpools[class + class];
         prev = next->prevpool;
         /* insert pool before next:   prev <-> pool <-> next */
         pool->nextpool = next;
         pool->prevpool = prev;
         next->prevpool = pool;
         prev->nextpool = pool;
-        UNLOCK();
+        UNLOCK(class);
         return;
     }
 
diff --git a/Objects/refcount.c b/Objects/refcount.c
new file mode 100644
index 0000000000..47e72e83ff
--- /dev/null
+++ b/Objects/refcount.c
@@ -0,0 +1,96 @@
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include "object.h"
+
+void py_time_refcounts_setzero(py_time_refcounts_t *t) {
+#ifdef PY_TIME_REFCOUNTS
+    t->total_refcount_time = 0;
+    t->total_refcounts = 0;
+#endif /* PY_TIME_REFCOUNTS */
+}
+
+py_time_refcounts_t py_time_refcounts;
+
+void py_time_refcounts_persist(py_time_refcounts_t *t) {
+#ifdef PY_TIME_REFCOUNTS
+    py_time_refcounts_t* const zero = 0;
+    PY_TIME_FETCH_AND_ADD(zero, total_refcount_time, t->total_refcount_time);
+    PY_TIME_FETCH_AND_ADD(zero, total_refcounts, t->total_refcounts);
+    py_time_refcounts_setzero(t);
+#endif /* PY_TIME_REFCOUNTS */
+}
+
+void py_time_refcounts_stats(void) {
+#ifdef PY_TIME_REFCOUNTS
+    if (py_time_refcounts.total_refcounts) {
+        printf("[py_incr/py_decr] %lu total calls\n", py_time_refcounts.total_refcounts);
+        printf("[py_incr/py_decr] %lu total time spent, in cycles\n", py_time_refcounts.total_refcount_time);
+        printf("[py_incr/py_decr] %f total time spent, in seconds\n", py_time_refcounts.total_refcount_time / 2600000000.0);
+        printf("[py_incr/py_decr] %f average cycles for a py_incr/py_decr\n", ((double)py_time_refcounts.total_refcount_time) / py_time_refcounts.total_refcounts);
+    }
+#endif /* PY_TIME_REFCOUNTS */
+}
+
+#ifdef PY_TIME_REFCOUNTS
+
+int __py_incref__(PyObject *o) {
+    uint64_t start, delta;
+    py_time_refcounts_t *t = PyState_GetThisThreadPyTimeRefcounts();
+    _Py_INC_REFTOTAL;
+    start = fast_get_cycles();
+    __sync_fetch_and_add(&o->ob_refcnt.shared_refcnt, 1);
+    delta = fast_get_cycles() - start;
+    PY_TIME_FETCH_AND_ADD(t, total_refcount_time, delta);
+    PY_TIME_FETCH_AND_ADD(t, total_refcounts, 1);
+    return 1;
+}
+
+void __py_decref__(PyObject *o) {
+    uint64_t start, delta, new_rc;
+    py_time_refcounts_t *t = PyState_GetThisThreadPyTimeRefcounts();
+    _Py_DEC_REFTOTAL;
+    start = fast_get_cycles();
+    new_rc = __sync_sub_and_fetch(&(o->ob_refcnt.shared_refcnt), 1);
+    delta = fast_get_cycles() - start;
+    PY_TIME_FETCH_AND_ADD(t, total_refcount_time, delta);
+    PY_TIME_FETCH_AND_ADD(t, total_refcounts, 1);
+    if (new_rc != 0)
+        _Py_CHECK_REFCNT(o)
+    else
+        _Py_Dealloc(o);
+}
+
+#endif /* PY_TIME_REFCOUNTS */
+
+void py_recursivelock_stats(py_recursivelock_t *f) {
+#ifdef PY_RECURSIVELOCK_WANT_STATS
+    printf("[%s] %ld total locks\n", f->description, (long)(f->no_contention_count + f->contention_count));
+    printf("[%s] %ld locks without contention\n", f->description, (long)f->no_contention_count);
+    printf("[%s] %ld locks with contention\n", f->description, (long)f->contention_count);
+    if (f->contention_count) {
+        printf("[%s] %ld contention total delay in cycles\n", f->description, (long)f->contention_total_delay);
+        printf("[%s] %f contention total delay in cpu-seconds\n", f->description, f->contention_total_delay / 2600000000.0);
+        printf("[%s] %f contention average delay in cycles\n", f->description, ((double)f->contention_total_delay) / f->contention_count);
+        printf("[%s] %ld contention max delay in cycles\n", f->description, (long)f->contention_max_delta);
+    }
+    py_recursivelock_reset_stats(f);
+#endif /* PY_RECURSIVELOCK_WANT_STATS */
+}
+
+void py_lock_stats(py_lock_t *f) {
+#ifdef PY_LOCK_WANT_STATS
+    printf("[%s] %ld total locks\n", f->description, (long)(f->no_contention_count + f->contention_count));
+    printf("[%s] %ld locks without contention\n", f->description, (long)f->no_contention_count);
+    printf("[%s] %ld locks with contention\n", f->description, (long)f->contention_count);
+    if (f->contention_count) {
+        printf("[%s] %ld contention total delay in cycles\n", f->description, (long)f->contention_total_delay);
+        printf("[%s] %f contention total delay in cpu-seconds\n", f->description, f->contention_total_delay / F_CYCLES_PER_SEC);
+        printf("[%s] %f contention average delay in cycles\n", f->description, ((double)f->contention_total_delay) / f->contention_count);
+        printf("[%s] %ld contention max delay in cycles\n", f->description, (long)f->contention_max_delta);
+    }
+    py_lock_reset_stats(f);
+#endif /*  PY_LOCK_WANT_STATS */
+}
+
diff --git a/Objects/setobject.c b/Objects/setobject.c
index 8cb3f364c5..b5c1892367 100644
--- a/Objects/setobject.c
+++ b/Objects/setobject.c
@@ -32,7 +32,6 @@ static PyObject _dummy_struct;
 
 #define dummy (&_dummy_struct)
 
-
 /* ======================================================================== */
 /* ======= Begin logic for probing the hash table ========================= */
 
@@ -800,6 +799,28 @@ frozenset_hash(PyObject *self)
     return hash;
 }
 
+
+/***** set_lock functions *************************************************/
+
+Py_LOCAL_INLINE(void) set_lock_new(PySetObject *d)
+{
+    py_recursivelock_init(&d->lock, "set()");
+}
+
+Py_LOCAL_INLINE(void) set_lock_dealloc(PySetObject *d)
+{
+}
+
+Py_LOCAL_INLINE(void) set_lock(PySetObject *d)
+{
+    py_recursivelock_lock(&(d->lock));
+}
+
+Py_LOCAL_INLINE(void) set_unlock(PySetObject *d)
+{
+    py_recursivelock_unlock(&(d->lock));
+}
+
 /***** Set iterator type ***********************************************/
 
 typedef struct {
@@ -1057,6 +1078,7 @@ make_new_set(PyTypeObject *type, PyObject *iterable)
     so->hash = -1;
     so->finger = 0;
     so->weakreflist = NULL;
+    set_lock_new(so);
 
     if (iterable != NULL) {
         if (set_update_internal(so, iterable)) {
@@ -1108,7 +1130,8 @@ frozenset_new(PyTypeObject *type, PyObject *args, PyObject *kwds)
             return result;
         Py_DECREF(result);
     }
-    /* The empty frozenset is a singleton */
+    /* The empty frozenset is a singleton
+       we initialize it in _PySet_Init, so after that it should always be != NULL */
     if (emptyfrozenset == NULL)
         emptyfrozenset = make_new_set(type, NULL);
     Py_XINCREF(emptyfrozenset);
@@ -1121,6 +1144,12 @@ PySet_ClearFreeList(void)
     return 0;
 }
 
+int
+_PySet_Init(void)
+{
+    return make_new_set(&PyFrozenSet_Type, NULL) ? 1 : 0;
+}
+
 void
 PySet_Fini(void)
 {
@@ -2273,7 +2302,6 @@ PyTypeObject PyFrozenSet_Type = {
     PyObject_GC_Del,                    /* tp_free */
 };
 
-
 /***** C API functions *************************************************/
 
 PyObject *
@@ -2291,88 +2319,120 @@ PyFrozenSet_New(PyObject *iterable)
 Py_ssize_t
 PySet_Size(PyObject *anyset)
 {
+    Py_ssize_t res;
     if (!PyAnySet_Check(anyset)) {
         PyErr_BadInternalCall();
         return -1;
     }
-    return PySet_GET_SIZE(anyset);
+    set_lock((PySetObject *)anyset);
+    res = PySet_GET_SIZE(anyset);
+    set_unlock((PySetObject *)anyset);
+    return res;
 }
 
 int
 PySet_Clear(PyObject *set)
 {
+    int res;
     if (!PySet_Check(set)) {
         PyErr_BadInternalCall();
         return -1;
     }
-    return set_clear_internal((PySetObject *)set);
+    set_lock((PySetObject *)set);
+    res = set_clear_internal((PySetObject *)set);
+    set_unlock((PySetObject *)set);
+    return res;
 }
 
 int
 PySet_Contains(PyObject *anyset, PyObject *key)
 {
+    int res;
     if (!PyAnySet_Check(anyset)) {
         PyErr_BadInternalCall();
         return -1;
     }
-    return set_contains_key((PySetObject *)anyset, key);
+    set_lock((PySetObject *)anyset);
+    res = set_contains_key((PySetObject *)anyset, key);
+    set_unlock((PySetObject *)anyset);
+    return res;
 }
 
 int
 PySet_Discard(PyObject *set, PyObject *key)
 {
+    int res;
     if (!PySet_Check(set)) {
         PyErr_BadInternalCall();
         return -1;
     }
-    return set_discard_key((PySetObject *)set, key);
+    set_lock((PySetObject *)set);
+    res = set_discard_key((PySetObject *)set, key);
+    set_unlock((PySetObject *)set);
+    return res;
 }
 
 int
 PySet_Add(PyObject *anyset, PyObject *key)
 {
+    int res;
     if (!PySet_Check(anyset) &&
         (!PyFrozenSet_Check(anyset) || Py_REFCNT(anyset) != 1)) {
         PyErr_BadInternalCall();
         return -1;
     }
-    return set_add_key((PySetObject *)anyset, key);
+    set_lock((PySetObject *)anyset);
+    res = set_add_key((PySetObject *)anyset, key);
+    set_unlock((PySetObject *)anyset);
+    return res;
 }
 
 int
 _PySet_NextEntry(PyObject *set, Py_ssize_t *pos, PyObject **key, Py_hash_t *hash)
 {
     setentry *entry;
+    int res = 0;
 
     if (!PyAnySet_Check(set)) {
         PyErr_BadInternalCall();
         return -1;
     }
-    if (set_next((PySetObject *)set, pos, &entry) == 0)
-        return 0;
-    *key = entry->key;
-    *hash = entry->hash;
-    return 1;
+    set_lock((PySetObject *)set);
+    if (set_next((PySetObject *)set, pos, &entry) != 0) {
+        *key = entry->key;
+        *hash = entry->hash;
+        res = 1;
+    }
+    set_unlock((PySetObject *)set);
+    return res;
 }
 
 PyObject *
 PySet_Pop(PyObject *set)
 {
+    PyObject * res;
     if (!PySet_Check(set)) {
         PyErr_BadInternalCall();
         return NULL;
     }
-    return set_pop((PySetObject *)set);
+    set_lock((PySetObject *)set);
+    res = set_pop((PySetObject *)set);
+    set_unlock((PySetObject *)set);
+    return res;
 }
 
 int
 _PySet_Update(PyObject *set, PyObject *iterable)
 {
+    int res;
     if (!PySet_Check(set)) {
         PyErr_BadInternalCall();
         return -1;
     }
-    return set_update_internal((PySetObject *)set, iterable);
+    set_lock((PySetObject *)set);
+    res = set_update_internal((PySetObject *)set, iterable);
+    set_unlock((PySetObject *)set);
+    return res;
 }
 
 /* Exported for the gdb plugin's benefit. */
@@ -2559,6 +2619,6 @@ static PyTypeObject _PySetDummy_Type = {
 
 static PyObject _dummy_struct = {
   _PyObject_EXTRA_INIT
-  2, &_PySetDummy_Type
+  _PyObject_REFCNT_INIT(2), &_PySetDummy_Type
 };
 
diff --git a/Objects/sliceobject.c b/Objects/sliceobject.c
index 104952333a..2a64efa1f6 100644
--- a/Objects/sliceobject.c
+++ b/Objects/sliceobject.c
@@ -87,7 +87,7 @@ PyTypeObject PyEllipsis_Type = {
 
 PyObject _Py_EllipsisObject = {
     _PyObject_EXTRA_INIT
-    1, &PyEllipsis_Type
+    _PyObject_REFCNT_INIT(1), &PyEllipsis_Type
 };
 
 
diff --git a/Objects/tupleobject.c b/Objects/tupleobject.c
index 8e1b00b63d..9b3549d681 100644
--- a/Objects/tupleobject.c
+++ b/Objects/tupleobject.c
@@ -12,6 +12,13 @@
 #define PyTuple_MAXFREELIST  2000  /* Maximum number of tuples of each size to save */
 #endif
 
+static py_recursivelock_t module_rlock = PY_RECURSIVELOCK_STATIC_INIT("tuple module lock");
+#define module_lock() py_recursivelock_lock(&module_rlock)
+#define module_unlock() py_recursivelock_unlock(&module_rlock)
+void tupleobject_lock_stats(void) {
+    py_recursivelock_stats(&module_rlock);
+}
+
 #if PyTuple_MAXSAVESIZE > 0
 /* Entries 1 up to PyTuple_MAXSAVESIZE are free lists, entry 0 is the empty
    tuple () of which at most one instance will be allocated.
@@ -36,12 +43,14 @@ static Py_ssize_t count_tracked = 0;
 static void
 show_track(void)
 {
+    module_lock();
     fprintf(stderr, "Tuples created: %" PY_FORMAT_SIZE_T "d\n",
         count_tracked + count_untracked);
     fprintf(stderr, "Tuples tracked by the GC: %" PY_FORMAT_SIZE_T
         "d\n", count_tracked);
     fprintf(stderr, "%.2f%% tuple tracking rate\n\n",
         (100.0*count_tracked/(count_untracked+count_tracked)));
+    module_unlock();
 }
 #endif
 
@@ -52,6 +61,7 @@ _PyTuple_DebugMallocStats(FILE *out)
 #if PyTuple_MAXSAVESIZE > 0
     int i;
     char buf[128];
+    module_lock();
     for (i = 1; i < PyTuple_MAXSAVESIZE; i++) {
         PyOS_snprintf(buf, sizeof(buf),
                       "free %d-sized PyTupleObject", i);
@@ -59,6 +69,7 @@ _PyTuple_DebugMallocStats(FILE *out)
                                buf,
                                numfree[i], _PyObject_VAR_SIZE(&PyTuple_Type, i));
     }
+    module_unlock();
 #endif
 }
 
@@ -72,12 +83,14 @@ PyTuple_New(Py_ssize_t size)
         return NULL;
     }
 #if PyTuple_MAXSAVESIZE > 0
+    module_lock();
     if (size == 0 && free_list[0]) {
         op = free_list[0];
-        Py_INCREF(op);
 #ifdef COUNT_ALLOCS
         tuple_zero_allocs++;
 #endif
+        module_unlock();
+        Py_INCREF(op);
         return (PyObject *) op;
     }
     if (size < PyTuple_MAXSAVESIZE && (op = free_list[size]) != NULL) {
@@ -86,6 +99,10 @@ PyTuple_New(Py_ssize_t size)
 #ifdef COUNT_ALLOCS
         fast_tuple_allocs++;
 #endif
+#ifdef SHOW_TRACK_COUNT
+        count_tracked++;
+#endif
+        module_unlock();
         /* Inline PyObject_InitVar */
 #ifdef Py_TRACE_REFS
         Py_SIZE(op) = size;
@@ -96,27 +113,37 @@ PyTuple_New(Py_ssize_t size)
     else
 #endif
     {
+#if PyTuple_MAXSAVESIZE > 0
+        module_unlock();
+#endif
         /* Check for overflow */
         if ((size_t)size > ((size_t)PY_SSIZE_T_MAX - sizeof(PyTupleObject) -
                     sizeof(PyObject *)) / sizeof(PyObject *)) {
             return PyErr_NoMemory();
         }
+
         op = PyObject_GC_NewVar(PyTupleObject, &PyTuple_Type, size);
         if (op == NULL)
             return NULL;
+
+#ifdef SHOW_TRACK_COUNT
+        module_lock();
+        count_tracked++;
+        module_unlock();
+#endif
+#if PyTuple_MAXSAVESIZE > 0
+        if (size == 0) {
+            module_lock();
+            free_list[0] = op;
+            ++numfree[0];
+            module_unlock();
+            Py_INCREF(op);          /* extra INCREF so that this is never freed */
+        }
+#endif
     }
     for (i=0; i < size; i++)
         op->ob_item[i] = NULL;
-#if PyTuple_MAXSAVESIZE > 0
-    if (size == 0) {
-        free_list[0] = op;
-        ++numfree[0];
-        Py_INCREF(op);          /* extra INCREF so that this is never freed */
-    }
-#endif
-#ifdef SHOW_TRACK_COUNT
-    count_tracked++;
-#endif
+
     _PyObject_GC_TRACK(op);
     return (PyObject *) op;
 }
@@ -150,7 +177,7 @@ int
 PyTuple_SetItem(PyObject *op, Py_ssize_t i, PyObject *newitem)
 {
     PyObject **p;
-    if (!PyTuple_Check(op) || op->ob_refcnt != 1) {
+    if (!PyTuple_Check(op) || Py_REFCNT(op) != 1) {
         Py_XDECREF(newitem);
         PyErr_BadInternalCall();
         return -1;
@@ -186,8 +213,10 @@ _PyTuple_MaybeUntrack(PyObject *op)
             return;
     }
 #ifdef SHOW_TRACK_COUNT
+    module_lock();
     count_tracked--;
     count_untracked++;
+    module_unlock();
 #endif
     _PyObject_GC_UNTRACK(op);
 }
@@ -232,6 +261,7 @@ tupledealloc(PyTupleObject *op)
         while (--i >= 0)
             Py_XDECREF(op->ob_item[i]);
 #if PyTuple_MAXSAVESIZE > 0
+        module_lock();
         if (len < PyTuple_MAXSAVESIZE &&
             numfree[len] < PyTuple_MAXFREELIST &&
             Py_TYPE(op) == &PyTuple_Type)
@@ -239,8 +269,10 @@ tupledealloc(PyTupleObject *op)
             op->ob_item[0] = (PyObject *) free_list[len];
             numfree[len]++;
             free_list[len] = op;
+            module_unlock();
             goto done; /* return */
         }
+        module_unlock();
 #endif
     }
     Py_TYPE(op)->tp_free((PyObject *)op);
@@ -838,7 +870,7 @@ _PyTuple_Resize(PyObject **pv, Py_ssize_t newsize)
 
     v = (PyTupleObject *) *pv;
     if (v == NULL || Py_TYPE(v) != &PyTuple_Type ||
-        (Py_SIZE(v) != 0 && Py_REFCNT(v) != 1)) {
+        (Py_SIZE(v) != 0 && Py_REFCNT((PyObject *) v) != 1)) {
         *pv = 0;
         Py_XDECREF(v);
         PyErr_BadInternalCall();
@@ -885,23 +917,41 @@ _PyTuple_Resize(PyObject **pv, Py_ssize_t newsize)
 int
 PyTuple_ClearFreeList(void)
 {
-    int freelist_size = 0;
+    int freed = 0;
 #if PyTuple_MAXSAVESIZE > 0
+    PyTupleObject *fl[PyTuple_MAXSAVESIZE];
+    int nf[PyTuple_MAXSAVESIZE];
     int i;
-    for (i = 1; i < PyTuple_MAXSAVESIZE; i++) {
-        PyTupleObject *p, *q;
-        p = free_list[i];
-        freelist_size += numfree[i];
-        free_list[i] = NULL;
-        numfree[i] = 0;
-        while (p) {
-            q = p;
-            p = (PyTupleObject *)(p->ob_item[0]);
-            PyObject_GC_Del(q);
+
+    for (;;) {
+        int previous_freed = freed;
+        module_lock();
+        memcpy(fl, free_list, sizeof(fl));
+        memcpy(nf, numfree, sizeof(nf));
+
+        memset(free_list, 0, sizeof(free_list));
+        memset(numfree, 0, sizeof(numfree));
+        module_unlock();
+
+        for (i = 1; i < PyTuple_MAXSAVESIZE; i++) {
+            PyTupleObject *t;
+            PyTupleObject *head = fl[i];
+            int counter = numfree[i];
+            freed += counter;
+
+            while (head) {
+                t = head;
+                head = (PyTupleObject *)(head->ob_item[0]);
+                PyObject_GC_Del(t);
+                counter--;
+            }
+            assert(counter == 0);
         }
+        if (previous_freed == freed)
+            break;
     }
 #endif
-    return freelist_size;
+    return freed;
 }
 
 void
@@ -910,7 +960,9 @@ PyTuple_Fini(void)
 #if PyTuple_MAXSAVESIZE > 0
     /* empty tuples are used all over the place and applications may
      * rely on the fact that an empty tuple is a singleton. */
+    module_lock();
     Py_CLEAR(free_list[0]);
+    module_unlock();
 
     (void)PyTuple_ClearFreeList();
 #endif
diff --git a/Objects/typeobject.c b/Objects/typeobject.c
index 46fb27e339..66b09b10d4 100644
--- a/Objects/typeobject.c
+++ b/Objects/typeobject.c
@@ -1095,7 +1095,7 @@ subtype_dealloc(PyObject *self)
         }
         if (type->tp_del) {
             type->tp_del(self);
-            if (self->ob_refcnt > 0)
+            if (Py_REFCNT(self) > 0)
                 return;
         }
 
@@ -1163,7 +1163,7 @@ subtype_dealloc(PyObject *self)
 
     if (type->tp_del) {
         type->tp_del(self);
-        if (self->ob_refcnt > 0) {
+        if (Py_REFCNT(self) > 0) {
             /* Resurrected */
             goto endlabel;
         }
diff --git a/Objects/unicodeobject.c b/Objects/unicodeobject.c
index fb79bd94f6..0cad7af75f 100644
--- a/Objects/unicodeobject.c
+++ b/Objects/unicodeobject.c
@@ -1745,7 +1745,7 @@ unicode_dealloc(PyObject *unicode)
 
     case SSTATE_INTERNED_MORTAL:
         /* revive dead object temporarily for DelItem */
-        Py_REFCNT(unicode) = 3;
+        Py_REFCNT_Initialize(unicode, 3);
         if (PyDict_DelItem(interned, unicode) != 0)
             Py_FatalError(
                 "deletion of interned string failed");
@@ -15271,7 +15271,8 @@ PyUnicode_InternInPlace(PyObject **p)
     PyThreadState_GET()->recursion_critical = 0;
     /* The two references in interned are not counted by refcnt.
        The deallocator will take care of this */
-    Py_REFCNT(s) -= 2;
+    Py_DECREF(s);
+    Py_DECREF(s);
     _PyUnicode_STATE(s).interned = SSTATE_INTERNED_MORTAL;
 }
 
@@ -15330,11 +15331,12 @@ _Py_ReleaseInternedUnicodeStrings(void)
             /* XXX Shouldn't happen */
             break;
         case SSTATE_INTERNED_IMMORTAL:
-            Py_REFCNT(s) += 1;
+            Py_INCREF(s);
             immortal_size += PyUnicode_GET_LENGTH(s);
             break;
         case SSTATE_INTERNED_MORTAL:
-            Py_REFCNT(s) += 2;
+            Py_INCREF(s);
+            Py_INCREF(s);
             mortal_size += PyUnicode_GET_LENGTH(s);
             break;
         default:
diff --git a/Objects/weakrefobject.c b/Objects/weakrefobject.c
index f42fe3d59d..0d5ba43993 100644
--- a/Objects/weakrefobject.c
+++ b/Objects/weakrefobject.c
@@ -886,7 +886,7 @@ PyObject_ClearWeakRefs(PyObject *object)
 
     if (object == NULL
         || !PyType_SUPPORTS_WEAKREFS(Py_TYPE(object))
-        || object->ob_refcnt != 0) {
+        || Py_REFCNT(object) != 0) {
         PyErr_BadInternalCall();
         return;
     }
@@ -909,7 +909,7 @@ PyObject_ClearWeakRefs(PyObject *object)
             current->wr_callback = NULL;
             clear_weakref(current);
             if (callback != NULL) {
-                if (((PyObject *)current)->ob_refcnt > 0)
+                if (Py_REFCNT((PyObject *)current) > 0)
                     handle_callback(current, callback);
                 Py_DECREF(callback);
             }
@@ -927,7 +927,7 @@ PyObject_ClearWeakRefs(PyObject *object)
             for (i = 0; i < count; ++i) {
                 PyWeakReference *next = current->wr_next;
 
-                if (((PyObject *)current)->ob_refcnt > 0)
+                if (Py_REFCNT((PyObject *)current) > 0)
                 {
                     Py_INCREF(current);
                     PyTuple_SET_ITEM(tuple, i * 2, (PyObject *) current);
diff --git a/PC/python3.def b/PC/python3.def
index e8d2d8c7e5..5a248eeb8d 100644
--- a/PC/python3.def
+++ b/PC/python3.def
@@ -712,3 +712,6 @@ EXPORTS
   _PyArg_VaParse_SizeT=python36._PyArg_VaParse_SizeT
   _PyArg_VaParseTupleAndKeywords_SizeT=python36._PyArg_VaParseTupleAndKeywords_SizeT
   _Py_BuildValue_SizeT=python36._Py_BuildValue_SizeT
+  Py_AtomicInc=python36.Py_AtomicInc
+  Py_AtomicDec=python36.Py_AtomicDec
+  Py_AtomicAdd=python36.Py_AtomicAdd
diff --git a/PCbuild/pythoncore.vcxproj b/PCbuild/pythoncore.vcxproj
index 9cbe8b9384..6f10e400d3 100644
--- a/PCbuild/pythoncore.vcxproj
+++ b/PCbuild/pythoncore.vcxproj
@@ -341,6 +341,7 @@ <?xml version="1.0" encoding="utf-8"?>
     <ClCompile Include="..\PC\config.c" />
     <ClCompile Include="..\PC\getpathp.c" />
     <ClCompile Include="..\PC\msvcrtmodule.c" />
+    <ClCompile Include="..\Python\lock_win.c" />
     <ClCompile Include="..\Python\pyhash.c" />
     <ClCompile Include="..\Python\random.c" />
     <ClCompile Include="..\Python\_warnings.c" />
diff --git a/PCbuild/pythoncore.vcxproj.filters b/PCbuild/pythoncore.vcxproj.filters
index 837b73690a..7217a37941 100644
--- a/PCbuild/pythoncore.vcxproj.filters
+++ b/PCbuild/pythoncore.vcxproj.filters
@@ -974,6 +974,9 @@ <?xml version="1.0" encoding="utf-8"?>
     <ClCompile Include="..\Objects\odictobject.c">
       <Filter>Objects</Filter>
     </ClCompile>
+    <ClCompile Include="..\Python\lock_win.c">
+      <Filter>Python</Filter>
+    </ClCompile>
   </ItemGroup>
   <ItemGroup>
     <ResourceCompile Include="..\PC\python_nt.rc">
diff --git a/Parser/pgenmain.c b/Parser/pgenmain.c
index 3ca4afefd3..a5cec60f91 100644
--- a/Parser/pgenmain.c
+++ b/Parser/pgenmain.c
@@ -26,6 +26,9 @@ int Py_DebugFlag;
 int Py_VerboseFlag;
 int Py_IgnoreEnvironmentFlag;
 
+/* We don't have an interpreter or threads here */
+py_time_refcounts_t* PyState_GetThisThreadPyTimeRefcounts(void) { return 0; }
+
 /* Forward */
 grammar *getgrammar(const char *filename);
 
diff --git a/Python/ceval.c b/Python/ceval.c
index 3835cbb956..a66b7f1784 100644
--- a/Python/ceval.c
+++ b/Python/ceval.c
@@ -323,16 +323,18 @@ _PyEval_FiniThreads(void)
     if (!gil_created())
         return;
     destroy_gil();
-    assert(!gil_created());
+    //assert(!gil_created());
 }
 
 void
 PyEval_AcquireLock(void)
 {
+  /*
     PyThreadState *tstate = PyThreadState_GET();
     if (tstate == NULL)
         Py_FatalError("PyEval_AcquireLock: current thread state is NULL");
     take_gil(tstate);
+    */
 }
 
 void
@@ -342,31 +344,38 @@ PyEval_ReleaseLock(void)
        We therefore avoid PyThreadState_GET() which dumps a fatal error
        in debug mode.
     */
+       /*
     drop_gil((PyThreadState*)_Py_atomic_load_relaxed(
         &_PyThreadState_Current));
+        */
 }
 
 void
 PyEval_AcquireThread(PyThreadState *tstate)
 {
+  #if 0
     if (tstate == NULL)
         Py_FatalError("PyEval_AcquireThread: NULL new thread state");
+
     /* Check someone has called PyEval_InitThreads() to create the lock */
     assert(gil_created());
     take_gil(tstate);
     if (PyThreadState_Swap(tstate) != NULL)
         Py_FatalError(
             "PyEval_AcquireThread: non-NULL old thread state");
+  #endif
 }
 
 void
 PyEval_ReleaseThread(PyThreadState *tstate)
 {
+  #if 0
     if (tstate == NULL)
         Py_FatalError("PyEval_ReleaseThread: NULL thread state");
     if (PyThreadState_Swap(NULL) != tstate)
         Py_FatalError("PyEval_ReleaseThread: wrong thread state");
     drop_gil(tstate);
+  #endif
 }
 
 /* This function is called from PyOS_AfterFork to destroy all threads which are
@@ -381,11 +390,13 @@ PyEval_ReInitThreads(void)
     PyObject *threading, *result;
     PyThreadState *current_tstate = PyThreadState_GET();
 
+/*
     if (!gil_created())
         return;
     recreate_gil();
+    */
     pending_lock = PyThread_allocate_lock();
-    take_gil(current_tstate);
+    // take_gil(current_tstate);
     main_thread = PyThread_get_thread_ident();
 
     /* Update the threading module with the new state.
@@ -429,6 +440,8 @@ _PyEval_SignalAsyncExc(void)
 PyThreadState *
 PyEval_SaveThread(void)
 {
+    return PyThreadState_Swap(NULL);
+#if 0
     PyThreadState *tstate = PyThreadState_Swap(NULL);
     if (tstate == NULL)
         Py_FatalError("PyEval_SaveThread: NULL tstate");
@@ -437,11 +450,13 @@ PyEval_SaveThread(void)
         drop_gil(tstate);
 #endif
     return tstate;
+#endif
 }
 
 void
 PyEval_RestoreThread(PyThreadState *tstate)
 {
+#if 0
     if (tstate == NULL)
         Py_FatalError("PyEval_RestoreThread: NULL tstate");
 #ifdef WITH_THREAD
@@ -458,6 +473,7 @@ PyEval_RestoreThread(PyThreadState *tstate)
     }
 #endif
     PyThreadState_Swap(tstate);
+#endif
 }
 
 
@@ -1262,6 +1278,7 @@ PyEval_EvalFrameEx(PyFrameObject *f, int throwflag)
                     goto error;
             }
 #ifdef WITH_THREAD
+#if 0
             if (_Py_atomic_load_relaxed(&gil_drop_request)) {
                 /* Give another thread a chance */
                 if (PyThreadState_Swap(NULL) != tstate)
@@ -1281,6 +1298,7 @@ PyEval_EvalFrameEx(PyFrameObject *f, int throwflag)
                 if (PyThreadState_Swap(tstate) != NULL)
                     Py_FatalError("ceval: orphan tstate");
             }
+#endif
 #endif
             /* Check for asynchronous exceptions. */
             if (tstate->async_exc != NULL) {
diff --git a/Python/ceval_gil.h b/Python/ceval_gil.h
index 8d38ee9dfc..ad5898efa6 100644
--- a/Python/ceval_gil.h
+++ b/Python/ceval_gil.h
@@ -129,11 +129,12 @@ static MUTEX_T switch_mutex;
 
 static int gil_created(void)
 {
-    return _Py_atomic_load_explicit(&gil_locked, _Py_memory_order_acquire) >= 0;
+    return 1; // _Py_atomic_load_explicit(&gil_locked, _Py_memory_order_acquire) >= 0;
 }
 
 static void create_gil(void)
 {
+    return;
     MUTEX_INIT(gil_mutex);
 #ifdef FORCE_SWITCHING
     MUTEX_INIT(switch_mutex);
@@ -149,6 +150,7 @@ static void create_gil(void)
 
 static void destroy_gil(void)
 {
+    return;
     /* some pthread-like implementations tie the mutex to the cond
      * and must have the cond destroyed first.
      */
@@ -162,51 +164,10 @@ static void destroy_gil(void)
     _Py_ANNOTATE_RWLOCK_DESTROY(&gil_locked);
 }
 
-static void recreate_gil(void)
-{
-    _Py_ANNOTATE_RWLOCK_DESTROY(&gil_locked);
-    /* XXX should we destroy the old OS resources here? */
-    create_gil();
-}
-
-static void drop_gil(PyThreadState *tstate)
-{
-    if (!_Py_atomic_load_relaxed(&gil_locked))
-        Py_FatalError("drop_gil: GIL is not locked");
-    /* tstate is allowed to be NULL (early interpreter init) */
-    if (tstate != NULL) {
-        /* Sub-interpreter support: threads might have been switched
-           under our feet using PyThreadState_Swap(). Fix the GIL last
-           holder variable so that our heuristics work. */
-        _Py_atomic_store_relaxed(&gil_last_holder, (Py_uintptr_t)tstate);
-    }
-
-    MUTEX_LOCK(gil_mutex);
-    _Py_ANNOTATE_RWLOCK_RELEASED(&gil_locked, /*is_write=*/1);
-    _Py_atomic_store_relaxed(&gil_locked, 0);
-    COND_SIGNAL(gil_cond);
-    MUTEX_UNLOCK(gil_mutex);
-
-#ifdef FORCE_SWITCHING
-    if (_Py_atomic_load_relaxed(&gil_drop_request) && tstate != NULL) {
-        MUTEX_LOCK(switch_mutex);
-        /* Not switched yet => wait */
-        if ((PyThreadState*)_Py_atomic_load_relaxed(&gil_last_holder) == tstate) {
-        RESET_GIL_DROP_REQUEST();
-            /* NOTE: if COND_WAIT does not atomically start waiting when
-               releasing the mutex, another thread can run through, take
-               the GIL and drop it again, and reset the condition
-               before we even had a chance to wait for it. */
-            COND_WAIT(switch_cond, switch_mutex);
-    }
-        MUTEX_UNLOCK(switch_mutex);
-    }
-#endif
-}
-
 static void take_gil(PyThreadState *tstate)
 {
     int err;
+    return;
     if (tstate == NULL)
         Py_FatalError("take_gil: NULL tstate");
 
diff --git a/Python/lock_linux.c b/Python/lock_linux.c
new file mode 100644
index 0000000000..8b13789179
--- /dev/null
+++ b/Python/lock_linux.c
@@ -0,0 +1 @@
+
diff --git a/Python/lock_win.c b/Python/lock_win.c
new file mode 100644
index 0000000000..b60a82e7bf
--- /dev/null
+++ b/Python/lock_win.c
@@ -0,0 +1,36 @@
+#include "lock_win.h"
+
+#define WIN32_LEAN_AND_MEAN
+#include <Windows.h>
+
+#oid py_nativelock_init(py_nativelock_t *nativelock) {
+	InitializeSRWLock((PSRWLOCK)nativelock);
+}
+
+void py_nativelock_lock(py_nativelock_t *nativelock) {
+	AcquireSRWLockExclusive((PSRWLOCK)nativelock);
+}
+
+void py_nativelock_unlock(cheaplock_t *nativelock) {
+	ReleaseSRWLockExclusive((PSRWLOCK)nativelock);
+}
+
+unsigned long win32_threadid() {
+	return GetCurrentThreadId();
+}
+
+Py_ssize_t Py_AtomicAddSSize_t(Py_ssize_t *to, Py_ssize_t value) {
+#if WIN64
+	return (Py_ssize_t)InterlockedAdd64((LONGLONG *)to, (LONGLONG)value);
+#else
+	return (Py_ssize_t)InterlockedAdd((LONG *)to, (LONG)value);
+#endif
+}
+
+Py_ssize_t Py_AtomicSubSSize_t(Py_ssize_t *to, Py_ssize_t value) {
+#if WIN64
+	return (Py_ssize_t)InterlockedAdd64((LONGLONG *)to, -(LONGLONG)value);
+#else
+	return (Py_ssize_t)InterlockedAdd((LONG *)to, -(LONG)value);
+#endif
+}
diff --git a/Python/pyarena.c b/Python/pyarena.c
index 103603fcdf..3bfdf0a980 100644
--- a/Python/pyarena.c
+++ b/Python/pyarena.c
@@ -169,7 +169,7 @@ PyArena_Free(PyArena *arena)
     block_free(arena->a_head);
     /* This property normally holds, except when the code being compiled
        is sys.getobjects(0), in which case there will be two references.
-    assert(arena->a_objects->ob_refcnt == 1);
+    assert(Py_REFCNT(arena->a_objects) == 1);
     */
 
     Py_DECREF(arena->a_objects);
diff --git a/Python/pylifecycle.c b/Python/pylifecycle.c
index e9db7f6351..831fce9d1f 100644
--- a/Python/pylifecycle.c
+++ b/Python/pylifecycle.c
@@ -316,6 +316,9 @@ _Py_InitializeEx_Private(int install_sigs, int install_importlib)
         Py_HashRandomizationFlag = add_flag(Py_HashRandomizationFlag, p);
 
     _PyRandom_Init();
+    py_time_refcounts_setzero(&py_time_refcounts);
+
+    _Py_ObMalloc_Init();
 
     interp = PyInterpreterState_New();
     if (interp == NULL)
@@ -324,7 +327,7 @@ _Py_InitializeEx_Private(int install_sigs, int install_importlib)
     tstate = PyThreadState_New(interp);
     if (tstate == NULL)
         Py_FatalError("Py_Initialize: can't make first thread");
-    (void) PyThreadState_Swap(tstate);
+    // (void) PyThreadState_Swap(tstate);
 
 #ifdef WITH_THREAD
     /* We can't call _PyEval_FiniThreads() in Py_FinalizeEx because
@@ -343,6 +346,9 @@ _Py_InitializeEx_Private(int install_sigs, int install_importlib)
     if (!_PyFrame_Init())
         Py_FatalError("Py_Initialize: can't init frames");
 
+    if (!_PySet_Init())
+        Py_FatalError("Py_Initialize: can't init sets");
+
     if (!_PyLong_Init())
         Py_FatalError("Py_Initialize: can't init longs");
 
@@ -549,6 +555,24 @@ Py_FinalizeEx(void)
     tstate = PyThreadState_GET();
     interp = tstate->interp;
 
+    py_recursivelock_stats(&(((PyDictObject *)interp->builtins)->ma_lock));
+
+    #define CALL_EXTERNAL_LOCK_STATS(name) \
+    { \
+    extern void name ## _lock_stats(void); \
+    name ## _lock_stats(); \
+    } \
+
+    CALL_EXTERNAL_LOCK_STATS(collectionsmodule);
+    CALL_EXTERNAL_LOCK_STATS(threadmodule);
+    CALL_EXTERNAL_LOCK_STATS(exceptions);
+    CALL_EXTERNAL_LOCK_STATS(classobject);
+    CALL_EXTERNAL_LOCK_STATS(floatobject);
+    CALL_EXTERNAL_LOCK_STATS(tupleobject);
+    CALL_EXTERNAL_LOCK_STATS(listobject);
+    CALL_EXTERNAL_LOCK_STATS(dictobject);
+    CALL_EXTERNAL_LOCK_STATS(methodobject);
+
     /* Remaining threads (e.g. daemon threads) will automatically exit
        after taking the GIL (in PyEval_RestoreThread()). */
     _Py_Finalizing = tstate;
@@ -585,6 +609,11 @@ Py_FinalizeEx(void)
     /* Destroy all modules */
     PyImport_Cleanup();
 
+    {
+    extern void py_time_refcounts_stats(void);
+    py_time_refcounts_stats();
+    }
+
     /* Flush sys.stdout and sys.stderr (again, in case more was printed) */
     if (flush_std_files() < 0) {
         status = -1;
@@ -691,7 +720,7 @@ Py_FinalizeEx(void)
 #endif /* WITH_THREAD */
 
     /* Delete current thread. After this, many C API calls become crashy. */
-    PyThreadState_Swap(NULL);
+    // PyThreadState_Swap(NULL);
     PyInterpreterState_Delete(interp);
 
 #ifdef Py_TRACE_REFS
@@ -734,7 +763,8 @@ PyThreadState *
 Py_NewInterpreter(void)
 {
     PyInterpreterState *interp;
-    PyThreadState *tstate, *save_tstate;
+    PyThreadState *tstate;
+    // PyThreadState *save_tstate;
     PyObject *bimod, *sysmod;
 
     if (!initialized)
@@ -750,7 +780,7 @@ Py_NewInterpreter(void)
         return NULL;
     }
 
-    save_tstate = PyThreadState_Swap(tstate);
+    // save_tstate = PyThreadState_Swap(tstate);
 
     /* XXX The following is lax in error checking */
 
@@ -810,7 +840,7 @@ handle_error:
 
     PyErr_PrintEx(0);
     PyThreadState_Clear(tstate);
-    PyThreadState_Swap(save_tstate);
+    // PyThreadState_Swap(save_tstate);
     PyThreadState_Delete(tstate);
     PyInterpreterState_Delete(interp);
 
@@ -834,6 +864,8 @@ Py_EndInterpreter(PyThreadState *tstate)
 {
     PyInterpreterState *interp = tstate->interp;
 
+    py_recursivelock_stats(&(((PyDictObject *)interp->builtins)->ma_lock));
+
     if (tstate != PyThreadState_GET())
         Py_FatalError("Py_EndInterpreter: thread is not current");
     if (tstate->frame != NULL)
@@ -846,7 +878,7 @@ Py_EndInterpreter(PyThreadState *tstate)
 
     PyImport_Cleanup();
     PyInterpreterState_Clear(interp);
-    PyThreadState_Swap(NULL);
+    // PyThreadState_Swap(NULL);
     PyInterpreterState_Delete(interp);
 }
 
diff --git a/Python/pystate.c b/Python/pystate.c
index 853e5c746d..80f6770680 100644
--- a/Python/pystate.c
+++ b/Python/pystate.c
@@ -3,13 +3,23 @@
 
 #include "Python.h"
 
+#include <frameobject.h>
+
+/*
 #define GET_TSTATE() \
     ((PyThreadState*)_Py_atomic_load_relaxed(&_PyThreadState_Current))
 #define SET_TSTATE(value) \
     _Py_atomic_store_relaxed(&_PyThreadState_Current, (Py_uintptr_t)(value))
 #define GET_INTERP_STATE() \
     (GET_TSTATE()->interp)
+*/
+
+#define GET_TSTATE() \
+    PyThreadState_GET()
+#define SET_TSTATE(value)
 
+#define GET_INTERP_STATE() \
+    (GET_TSTATE()->interp)
 
 /* --------------------------------------------------------------------------
 CAUTION
@@ -54,11 +64,12 @@ static int autoTLSkey = 0;
 
 static PyInterpreterState *interp_head = NULL;
 
-/* Assuming the current thread holds the GIL, this is the
-   PyThreadState for the current thread. */
-_Py_atomic_address _PyThreadState_Current = {0};
 PyThreadFrameGetter _PyThreadState_GetFrame = NULL;
 
+/* Now that there isn't a GIL, there is no such thing as
+   a global pointer to the frame of whoever has the GIL. */
+const _Py_atomic_address const _PyThreadState_Current = {0};
+
 #ifdef WITH_THREAD
 static void _PyGILState_NoteThreadState(PyThreadState* tstate);
 #endif
@@ -202,6 +213,8 @@ new_threadstate(PyInterpreterState *interp, int init)
 
         tstate->dict = NULL;
 
+        py_time_refcounts_setzero(&(tstate->py_time_refcounts));
+
         tstate->curexc_type = NULL;
         tstate->curexc_value = NULL;
         tstate->curexc_traceback = NULL;
@@ -219,6 +232,8 @@ new_threadstate(PyInterpreterState *interp, int init)
         tstate->trash_delete_later = NULL;
         tstate->on_delete = NULL;
         tstate->on_delete_data = NULL;
+        tstate->frame_freelist = NULL;
+        tstate->frame_freelist_count = 0;
 
         tstate->coroutine_wrapper = NULL;
         tstate->in_coroutine_wrapper = 0;
@@ -374,6 +389,47 @@ _PyState_ClearModules(void)
     }
 }
 
+/*
+the frame freelist abuses the pyobject header:
+  * ob_refcnt contains the # of objects in the freelist (including this one)
+  * ob_type points to the next object in the freelist
+*/
+
+void PyThreadState_FrameFreeListFree(PyThreadState *tstate, struct _frame *o) {
+    if (tstate->frame_freelist_count >= PyFrame_MAXFREELIST) {
+        PyObject_GC_Del(o);
+        return;
+    }
+
+    assert(o->ob_base.ob_base.ob_type == &PyFrame_Type);
+    tstate->frame_freelist_count++;
+    o->ob_base.ob_base.ob_type = (PyTypeObject *)tstate->frame_freelist;
+    tstate->frame_freelist = o;
+}
+
+
+struct _frame *PyThreadState_FrameFreeListAlloc(PyThreadState *tstate) {
+    struct _frame *f = tstate->frame_freelist;
+    if (!f)
+        return NULL;
+
+    tstate->frame_freelist_count--;
+    tstate->frame_freelist = (struct _frame *)f->ob_base.ob_base.ob_type;
+    f->ob_base.ob_base.ob_type = &PyFrame_Type;
+    return f;
+}
+
+void
+PyThreadState_FrameFreeListClear(PyThreadState *tstate)
+{
+    for (;;) {
+        struct _frame *f = PyThreadState_FrameFreeListAlloc(tstate);
+        if (!f)
+            break;
+        PyObject_GC_Del(f);
+    }
+}
+
 void
 PyThreadState_Clear(PyThreadState *tstate)
 {
@@ -403,6 +459,17 @@ PyThreadState_Clear(PyThreadState *tstate)
 }
 
 
+py_time_refcounts_t *
+PyState_GetThisThreadPyTimeRefcounts()
+{
+    PyThreadState *tstate = PyGILState_GetThisThreadState();
+    if (!tstate)
+        return NULL;
+
+    return &(tstate->py_time_refcounts);
+}
+
+
 /* Common code for PyThreadState_Delete() and PyThreadState_DeleteCurrent() */
 static void
 tstate_delete_common(PyThreadState *tstate)
@@ -413,6 +480,8 @@ tstate_delete_common(PyThreadState *tstate)
     interp = tstate->interp;
     if (interp == NULL)
         Py_FatalError("PyThreadState_Delete: NULL interp");
+    PyThreadState_FrameFreeListClear(tstate);
+    py_time_refcounts_persist(&(tstate->py_time_refcounts));
     HEAD_LOCK();
     if (tstate->prev)
         tstate->prev->next = tstate->next;
@@ -498,18 +567,22 @@ _PyThreadState_DeleteExcept(PyThreadState *tstate)
 PyThreadState *
 _PyThreadState_UncheckedGet(void)
 {
-    return GET_TSTATE();
+    return PyGILState_GetThisThreadState();
+    /* return GET_TSTATE(); */
 }
 
 
 PyThreadState *
 PyThreadState_Get(void)
 {
+    return PyGILState_GetThisThreadState();
+    /*
     PyThreadState *tstate = GET_TSTATE();
     if (tstate == NULL)
         Py_FatalError("PyThreadState_Get: no current thread");
 
     return tstate;
+    */
 }
 
 
@@ -517,6 +590,7 @@ PyThreadState *
 PyThreadState_Swap(PyThreadState *newts)
 {
     PyThreadState *oldts = GET_TSTATE();
+    return oldts;
 
     SET_TSTATE(newts);
     /* It should not be possible for more than one thread state
@@ -784,8 +858,10 @@ PyGILState_GetThisThreadState(void)
 int
 PyGILState_Check(void)
 {
-    PyThreadState *tstate = GET_TSTATE();
+    return 1;
+    /*PyThreadState *tstate = GET_TSTATE();
     return tstate && (tstate == PyGILState_GetThisThreadState());
+    */
 }
 
 PyGILState_STATE
diff --git a/Python/sysmodule.c b/Python/sysmodule.c
index 702e8f0f9f..5de027c2f0 100644
--- a/Python/sysmodule.c
+++ b/Python/sysmodule.c
@@ -1012,7 +1012,7 @@ Return the size of object in bytes.");
 static PyObject *
 sys_getrefcount(PyObject *self, PyObject *arg)
 {
-    return PyLong_FromSsize_t(arg->ob_refcnt);
+    return PyLong_FromSsize_t(Py_REFCNT(arg));
 }
 
 #ifdef Py_REF_DEBUG
diff --git a/README.md b/README.md
new file mode 100644
index 0000000000..33cccccf4b
--- /dev/null
+++ b/README.md
@@ -0,0 +1,26 @@
+GILECTOMY README
+================
+
+Welcome to the exciting world of segfaults and massive slowdowns!
+
+Some things you need to know in order to work with the Gilectomy.
+
+First, this branch is known to minimally work on 64-bit platforms
+only, Linux and OS X.  Work is underway for Win64.  We have no idea
+whether or not it works on 32-bit platforms.  Boldly go!  Forge the
+new frontier!  Let us know!
+
+Second, as you hack on the Gilectomy you may break your "python"
+executable rather badly.  This is of course expected.  However, the
+python Makefile itself depends on having a working local python
+interpreter, so when you break that you often break your build too.
+We provide a workaround available for this problem: "fix_makefile.py"
+in the root of the Gilectomy branch.  You should run this with a
+known-good python excecutable *from circa the time the Gilectomy was
+forked from CPython*.  There's a git "tag", "gilectomy_base", on the
+correct revision.  Once that's built, run this:
+
+    % cd gilectomy_branch_checkout
+    % ./configure
+    % ../path/to/gilectomy_base/python fix_makefile.py
+    % make
diff --git a/fix_makefile.py b/fix_makefile.py
new file mode 100755
index 0000000000..7681e6a7a9
--- /dev/null
+++ b/fix_makefile.py
@@ -0,0 +1,133 @@
+#!/usr/bin/env python3
+
+usage_str = """
+fix_makefile.py
+Copyright 2016 by Larry Hastings
+
+usage: fix_makefile.py [-h] [path-to-cpython-trunk] [path-to-python-binary]
+"""
+
+docs = """
+CPython's build process itself depends on the python interpreter
+that it builds.  So when you break the CPython interpreter as much
+as I have, you discover that the build breaks too...!
+
+This script modifies CPython's Makefile (in the current directory)
+to use a different interpreter.  The default is my "known good"
+interpreter I build from trunk now and then.  You can specify your
+own, though you must specify the path to the directory where you
+built a recent CPython trunk.
+
+Why must it be a trunk you built yourself?  It also needs the
+_freeze_importlib program, which uses the CPython .so, and
+isn't installed when you install python3.  And anyway that's all
+black magic and I don't know if something bad happens if
+_freeze_importlib is built from a very different revision of trunk.
+So I just keep my "buildtrunk" at a reasonably similar version and
+hope for the best.  Good luck!
+"""
+
+
+import os
+import stat
+import sys
+
+def error(s, path=None):
+    print(s)
+    if (path):
+        print("   ", path)
+    print(usage_str)
+    sys.exit(-1)
+
+if "-h" in sys.argv[1:]:
+    print(usage_str)
+    print(docs.strip())
+    sys.exit(0)
+
+
+if len(sys.argv) > 3:
+    error("Your command-line parameters are wrong and bad!  Shame on you!")
+
+if len(sys.argv) == 3:
+    path_to_python = sys.argv[2]
+else:
+    path_to_python = sys.executable
+
+if len(sys.argv) >= 2:
+    path_to_trunk = sys.argv[1]
+else:
+    path_to_trunk = "."
+
+
+if ((sys.version_info.major < 3) 
+    or (sys.version_info.minor < 6)):
+    error("I need Python 3.6+.")
+
+for fn in (
+    os.path.normpath,
+    os.path.expanduser,
+    os.path.abspath,
+    ):
+    path_to_trunk = fn(path_to_trunk)
+
+if not os.path.isdir(path_to_trunk):
+    error("You must specify a directory:", path_to_trunk)
+
+
+def test_exe(path, name):
+    try:
+        s = os.stat(path)
+    except FileNotFoundError:
+        error('Path to {} doesn\'t exist:'.format(name), path)
+
+    if not (s.st_mode & stat.S_IXUSR):
+        error('{} specified isn\'t executable:'.format(name), path)
+
+test_exe(path_to_python, "python")
+
+path_to_freeze = os.path.join(os.path.dirname(path_to_python),
+    "Programs/_freeze_importlib")
+
+test_exe(path_to_freeze, "_freeze_importlib")
+
+print('Path to  trunk: "{}"'.format(path_to_trunk))
+print('Path to python: "{}"'.format(path_to_python))
+print('Path to freeze: "{}"'.format(path_to_freeze))
+print()
+
+if not os.path.isfile("Makefile"):
+    error("Makefile not found in current directory!")
+
+with open("Makefile", "rt") as f:
+    makefile = f.read().split("\n")
+
+
+for s, replacement, expected in (
+    (
+        "PYTHON_FOR_BUILD=./$(BUILDPYTHON) -E",
+        "PYTHON_FOR_BUILD={} -E".format(path_to_python),
+        1
+    ),
+    (
+        "./Programs/_freeze_importlib \\",
+        "{} \\".format(path_to_freeze),
+        2
+    ),
+    ):
+    lines = []
+    found = 0
+    for line in makefile:
+        if line.endswith(s):
+            found += 1
+            line = line.replace(s, replacement)
+        lines.append(line)
+    if found != expected:
+        error("Didn't find the number of expected substitutions for line!", s)
+    makefile = lines
+
+
+with open("Makefile", "wt") as f:
+    f.write("\n".join(makefile))
+
+print("Success!")
+sys.exit(0)
diff --git a/x.py b/x.py
new file mode 100644
index 0000000000..e0bb7d1c95
--- /dev/null
+++ b/x.py
@@ -0,0 +1,30 @@
+#!/usr/bin/env python3
+#
+# x.py by Larry Hastings
+#
+# Official test program of the Gilectomy.
+#
+# Runs a bad fib generator to 30,
+# with some number of threads, default 7.
+
+import threading
+import sys
+
+def fib(n):
+    if n < 2: return 1
+    return fib(n-1) + fib(n-2)
+
+
+def test():
+    print(fib(30))
+
+threads = 7
+
+if len(sys.argv) > 1:
+    threads = int(sys.argv[1])
+
+for i in range(threads - 1):
+    threading.Thread(target=test).start()
+
+if threads > 0:
+    test()
diff --git a/xerial.py b/xerial.py
new file mode 100644
index 0000000000..fcfa336382
--- /dev/null
+++ b/xerial.py
@@ -0,0 +1,27 @@
+#!/usr/bin/env python3
+#
+# xerial.py by Larry Hastings
+#
+# A serial version of x.py, to compare
+# against doing the same work without any
+# contention.
+#
+# Runs a bad fib generator to 30
+# some number of times, default 7.
+
+import sys
+
+def fib(n):
+    if n < 2: return 1
+    return fib(n-1) + fib(n-2)
+
+def test():
+    print(fib(30))
+
+iterations = 7
+
+if len(sys.argv) > 1:
+    iterations = int(sys.argv[1])
+
+for i in range(iterations):
+    test()
diff --git a/y.py b/y.py
new file mode 100644
index 0000000000..ce56366ae6
--- /dev/null
+++ b/y.py
@@ -0,0 +1,54 @@
+#!/usr/bin/env python3
+#
+# x.py by Larry Hastings
+#
+# Official test program of the Gilectomy.
+#
+# Runs a bad fib generator to 30,
+# with some number of threads, default 7.
+
+import threading
+import sys
+
+myset1 = set()
+myset2 = set()
+
+def fib(n):
+    if n < 2: return 1
+    res = fib(n-1) + fib(n-2)
+    if n < 15 or res % 2:
+        myset1.add(res)
+        t = myset2.issubset(myset1)
+        t = myset2.issuperset(myset1)
+        t = myset2.difference(myset1)
+        t = myset2.symmetric_difference(myset1)
+        t = 33 in myset1
+        tmp = myset2.intersection(myset1)
+        tmp = myset2.copy()
+    else:
+        myset2.add(res)
+        t = myset1.issubset(myset2)
+        t = myset1.issuperset(myset2)
+        t = myset1.difference(myset2)
+        t = myset1.symmetric_difference(myset2)
+        t = 33 in myset1
+        tmp = myset1.intersection(myset2)
+        tmp = myset1.copy()
+    return res
+
+
+def test():
+    print(fib(30))
+
+threads = 7
+
+if len(sys.argv) > 1:
+    threads = int(sys.argv[1])
+
+for i in range(threads - 1):
+    threading.Thread(target=test).start()
+
+if threads > 0:
+    test()
+
+print(myset1, myset2)
